{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering \n",
    "\n",
    "이 가이드에서는 GPT-4o와 같은 대규모 언어 모델(GPT 모델이라고도 함)에서 더 나은 결과를 얻기 위한 전략과 전술을 공유합니다. 여기에 설명된 방법들은 때때로 더 큰 효과를 위해 조합하여 배포할 수 있습니다. 자신에게 가장 적합한 방법을 찾기 위해 실험해 보시기 바랍니다. 또한 모델 기능을 보여주는 예시 프롬프트도 살펴볼 수 있습니다:\n",
    "\n",
    "## 더 나은 결과를 얻기 위한 6가지 전략\n",
    "\n",
    "### 1. 명확한 지침 작성\n",
    "대형언어모델은 사용자의 마음을 읽을 수 없습니다. 답변이 너무 길면 간단한 답변을 요청하세요. 답변이 너무 간단하다면 전문가 수준의 문장을 요청하세요. 형식이 마음에 들지 않으면 원하는 형식을 직접 보여주세요. 모델이 원하는 것을 추측할 필요가 적을수록 원하는 것을 얻을 가능성이 높아집니다.\n",
    "\n",
    "#### 방안:\n",
    "\n",
    "1. 쿼리에 세부 정보를 포함하여 보다 관련성 높은 답변 얻기\n",
    "2. 모델에 페르소나를 채택하도록 요청하기 \n",
    "3. 구분 기호를 사용하여 입력의 구분되는 부분을 명확하게 표시하기 \n",
    "4. 작업 완료에 필요한 단계 지정하기 \n",
    "5. 예제 제공 \n",
    "6. 출력의 원하는 길이 지정하기\n",
    "\n",
    "### 2. 참조 텍스트 제공\n",
    "언어 모델은 특히 난해한 주제나 인용 및 URL에 대한 질문을 받을 때 자신 있게 가짜 답변을 만들어낼 수 있습니다. 노트 한 장이 시험 성적을 높이는 데 도움이 되는 것과 마찬가지로, 이러한 모델에 참조 텍스트를 제공하면 더 적은 조작으로 답안을 작성하는 데 도움이 될 수 있습니다.\n",
    "\n",
    "#### 방안:\n",
    "\n",
    "1. 모델에게 참조 텍스트를 사용하여 답하도록 지시하기 \n",
    "2. 모델에게 참조 텍스트의 인용을 사용하여 답하도록 지시하기\n",
    "\n",
    "### 3. 복잡한 작업을 더 간단한 하위 작업으로 나누기 \n",
    "소프트웨어 엔지니어링에서 복잡한 시스템을 일련의 모듈식 구성 요소로 분해하는 것이 좋은 관행인 것처럼 언어 모델에 제출된 작업도 마찬가지입니다. 복잡한 작업은 단순한 작업보다 오류율이 높은 경향이 있습니다. 또한 복잡한 작업은 종종 이전 작업의 출력을 사용하여 이후 작업의 입력을 구성하는 더 간단한 작업의 워크플로로 재정의할 수 있습니다.\n",
    "\n",
    "#### 방안:\n",
    "\n",
    "1. 의도 분류를 사용하여 사용자 쿼리에 가장 관련성이 높은 지침 식별 \n",
    "2. 매우 긴 대화가 필요한 대화 애플리케이션의 경우 이전 대화를 요약하거나 필터링 \n",
    "3. 긴 문서를 부분적으로 요약하고 전체 요약을 재귀적으로 구성\n",
    "\n",
    "### 4.모델에 '생각할 시간' 주기 \n",
    "\n",
    "17에 28을 곱하라는 질문을 받으면 즉시 알 수는 없지만 시간이 지나면 풀 수 있습니다. 마찬가지로 모델은 시간을 들여 답을 찾는 것보다 바로 답을 찾으려고 할 때 더 많은 추론 오류를 범합니다. 답을 내기 전에 '생각의 연쇄(Chain of Thought)'를 요청하면 모델이 보다 안정적으로 정답을 추론하는 데 도움이 될 수 있습니다.\n",
    "\n",
    "#### 방안:\n",
    "\n",
    "1. 결론을 내리기 전에 모델 스스로 해결책을 찾도록 지시하기 \n",
    "2. 모델의 추론 과정을 숨기기 위해 내부 독백 또는 일련의 쿼리를 사용하기 \n",
    "3. 모델에게 이전 통과에서 놓친 것이 있는지 물어보기\n",
    "\n",
    "### 5. 외부 도구 사용 \n",
    "다른 도구의 출력을 모델에 공급하여 모델의 약점을 보완하세요. 예를 들어, 텍스트 검색 시스템(RAG 또는 검색 증강 생성이라고도 함)은 모델에 관련 문서에 대해 알려줄 수 있습니다. 코드 인터프리터와 같은 코드 실행 엔진은 모델이 수학을 수행하고 코드를 실행하는 데 도움을 줄 수 있습니다. 언어 모델보다 도구로 더 안정적이고 효율적으로 작업을 수행할 수 있다면, 그 작업을 오프로드하여 두 가지 장점을 모두 활용하세요.\n",
    "\n",
    "#### 방안:\n",
    "\n",
    "1. 임베딩 기반 검색을 사용하여 효율적인 지식 검색 구현 \n",
    "2. 코드 실행을 사용하여 보다 정확한 계산을 수행하거나 외부 API 호출 \n",
    "3. 모델에 특정 기능에 대한 액세스 권한 부여\n",
    "\n",
    "### 6. 체계적으로 변경 사항 테스트하기 \n",
    "성능을 측정할 수 있다면 성능 개선이 더 쉬워집니다. 프롬프트를 수정하면 일부 고립된 예제에서는 성능이 향상되지만 보다 대표적인 예제 집합에서는 전반적인 성능이 저하되는 경우가 있습니다. 따라서 변경 사항이 성능에 긍정적인 영향을 미치는지 확인하려면 포괄적인 테스트 모음('평가'라고도 함)을 정의해야 할 수도 있습니다.\n",
    "\n",
    "#### 방안:\n",
    "\n",
    "1. 표준 답변을 참조하여 모델 결과 평가하기\n",
    "\n",
    "## 정리 \n",
    "위에 나열된 각 전략들은 구체적인 방안들로 구현할 수 있으며 조합하여 사용할 수 있습니다. 이러한 방안들은 시도해 볼 수 있는 아이디어를 제공하기 위한 것으로 모든 경우를 완전히 포괄하는 것은 아니므로 여기에 제시되지 않은 창의적인 아이디어를 자유롭게 시도해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전략별 상세 방안\n",
    "\n",
    "### 전략 1. 명확한 지침 작성 \n",
    "#### 방안 1. 관련성 높은 답변을 얻으려면 문의에 세부 정보를 포함하세요 \n",
    "관련성 높은 답변을 얻으려면 요청에 중요한 세부 정보나 맥락이 포함되어 있는지 확인하세요. 그렇지 않으면 모델이 무슨 뜻인지 추측할 수밖에 없습니다.\n",
    "\n",
    "|Worse|Better|\n",
    "|---|---|\n",
    "|Excel에서 숫자를 더하려면 어떻게 하나요?|Excel에서 달러 금액의 행을 합산하려면 어떻게 하나요? 모든 합계가 '합계'라는 열에서 오른쪽으로 끝나는 전체 행에 대해 자동으로 이 작업을 수행하고 싶습니다.  |\n",
    "|대통령은 누구인가요?| 2021년 멕시코의 대통령은 누구이며 선거는 얼마나 자주 실시되나요? |\n",
    "|피보나치 수열을 계산하는 코드를 작성하세요. | 피보나치 수열을 효율적으로 계산하는 TypeScript 함수를 작성하세요. 코드에 자유롭게 주석을 달아 각 부분이 무엇을 하고 왜 그렇게 작성되었는지 설명하세요.|\n",
    "| 회의 노트를 요약하세요.| 회의 노트를 한 단락으로 요약하세요. 그런 다음 발표자와 각 발표자의 핵심 요점에 대한 마크다운 목록을 작성합니다. 마지막으로 발표자가 제안한 다음 단계 또는 실행 항목이 있으면 나열합니다.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#install langchain-openai\n",
    "\n",
    "%pip install -qU langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This basic example to initialize the Azure OpenAI model using langchain-openai\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Retrieve Azure OpenAI specific configuration from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "OPENAI_API_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_MODEL = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=OPENAI_DEPLOYMENT_MODEL,\n",
    "    azure_endpoint= OPENAI_API_ENDPOINT,\n",
    "    openai_api_type=\"azure\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    api_version=OPENAI_API_VERSION,\n",
    "    temperature=0.5,\n",
    "    max_tokens=None,\n",
    "    timeout = None,\n",
    "    max_retries = 2,\n",
    "    # other params....\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 미국 대통령은 조 바이든(Joe Biden)입니다. 그는 2021년 1월 20일에 취임했습니다. 다른 나라의 대통령에 대해 알고 싶으시면 특정 국가를 언급해 주시면 더 정확한 정보를 제공해 드리겠습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "message= HumanMessage(\n",
    "    content= \"대통령은 누구인가요?\"\n",
    "    )\n",
    "messages =[]\n",
    "\n",
    "messages.append(message)\n",
    "response =  llm.invoke(messages) \n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021년 멕시코의 대통령은 안드레스 마누엘 로페스 오브라도르(Andrés Manuel López Obrador)입니다. 그는 2018년 12월 1일에 대통령으로 취임했습니다. 멕시코의 대통령 선거는 6년마다 실시되며, 대통령은 단임제로 한 번만 임기가 허용됩니다. 이는 멕시코 헌법에 규정된 사항으로, 대통령 재선은 금지되어 있습니다.\n"
     ]
    }
   ],
   "source": [
    "message= HumanMessage(\n",
    "    content= \"2021년 멕시코의 대통령은 누구이며 선거는 얼마나 자주 실시되나요?\"\n",
    "    )\n",
    "\n",
    "messages =[]\n",
    "\n",
    "messages.append(message)\n",
    "response =  llm.invoke(messages) \n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방안 2. 모델에게 페르소나를 채택하도록 요청하기 \n",
    "시스템 메시지를 사용하여 모델이 답장에 사용하는 페르소나를 지정할 수 있습니다. 대형언어모델의 시스템 메시지를 이용하여 대형언어모델의 응답방향을 조절할 수 있습니다. \n",
    "\n",
    "|역할|프롬프트|\n",
    "|------|-----|\n",
    "|SYSTEM|사용자가 문서 작성에 도움을 요청하면 모든 단락에 농담이나 장난스러운 댓글이 하나 이상 포함된 문서로 응답합니다.|\n",
    "|USER|제 강철 볼트 공급업체에 짧은 시간 내에 납품을 완료해 준 것에 대한 감사 편지를 작성해주세요. 덕분에 중요한 주문을 배송할 수 있었습니다.|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론이죠! 여기 당신의 강철 볼트 공급업체에 보낼 감사 편지 초안입니다. 농담을 포함해서 작성해 보았습니다.\n",
      "\n",
      "---\n",
      "\n",
      "[공급업체 이름] 귀하,\n",
      "\n",
      "안녕하십니까?\n",
      "\n",
      "저는 [당신의 이름]입니다. 이번에 저희 회사가 중요한 주문을 성공적으로 배송할 수 있었던 것은 전적으로 귀하의 신속하고 정확한 납품 덕분입니다. 진심으로 감사드립니다.\n",
      "\n",
      "귀사의 빠른 대응 덕분에 저희는 고객의 기대에 부응할 수 있었으며, 이는 저희 회사의 신뢰도와 평판을 높이는 데 큰 도움이 되었습니다. 사실, 저희 고객이 너무 기뻐한 나머지 춤을 추기 시작했답니다. 물론, 그 춤 실력은 비밀로 하겠습니다.\n",
      "\n",
      "특히나 짧은 시간 내에 필요한 강철 볼트를 정확히 공급해 주신 점은 정말 대단했습니다. 귀사의 팀이 슈퍼히어로 옷을 입고 일하는 게 아닌가 하는 생각이 들 정도였습니다. 만약 그렇다면, 다음엔 저희도 초능력을 빌려주실 수 있나요?\n",
      "\n",
      "앞으로도 귀사와의 협력을 통해 더욱 성공적인 비즈니스를 이어가기를 희망합니다. 다시 한 번 감사의 말씀을 전하며, 귀사의 무궁한 발전을 기원합니다.\n",
      "\n",
      "감사합니다.\n",
      "\n",
      "[당신의 이름] 드림\n",
      "\n",
      "---\n",
      "\n",
      "이 편지가 당신의 감사한 마음을 잘 전달하길 바랍니다. 😊\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "system_msg = SystemMessage(content=\"사용자가 문서 작성에 도움을 요청하면 모든 단락에 농담이나 장난스러운 댓글이 하나 이상 포함된 문서로 응답합니다.\")\n",
    "human_msg = HumanMessage(content=\"제 강철 볼트 공급업체에 짧은 시간 내에 납품을 완료해 준 것에 대한 감사 편지를 작성해주세요. 덕분에 중요한 주문을 배송할 수 있었습니다.\")\n",
    "\n",
    "messages =[]\n",
    "\n",
    "messages.append(system_msg)\n",
    "messages.append(human_msg)\n",
    "response =  llm.invoke(messages) \n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방안 3 : 구분 기호를 사용하여 입력의 다른 부분을 명확하게 표시하기 \n",
    "\n",
    "큰따옴표, XML 태그, 섹션 제목 등과 같은 구분 기호를 사용하면 텍스트의 섹션을 구분하여 다르게 처리하는 데 도움이 될 수 있습니다. \n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|USER|3연속 큰따옴표로 구분된 텍스트를 시조로 요약하세요.\"\"\"위메이드는 성장의 가치, 책임의 가치 그리고 성취의 가치를 중요시합니다. 누군가의 꿈이 현실로 이루어지면서 세상은 더 좋은 곳으로 발전하고 있습니다. 게임에서 시작하여 다양한 문화의 영역에서 무한한 상상을 현실로 만드는 창조집단, 그것이 위메이드의 비전입니다.\"\"\"|\n",
    "\n",
    "<br>\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|SYSTEM|동일한 주제에 대한 한 쌍의 문서(XML 태그로 구분됨)가 제공됩니다. 먼저 각 기사의 주장을 요약하세요. 그런 다음 어느 쪽이 더 나은 주장인지 표시하고 그 이유를 설명하세요.|\n",
    "|USER |\\<article> 국내 게임사 중 적극적으로 블록체인 사업을 추진해 온 위메이드가 최근 관련 서비스를 축소하면서 '선택과 집중'을 키워드로 내세웠다.실적 개선 기대에도 주춤했던 위메이드 주가, 가상자산 위믹스가 위믹스 재단의 대대적인 변화로 상승세로 전환할지 주목된다.27일 업계에 따르면 위메이드는 최근 위믹스의 토크노믹스를 전면 개편하겠다고 밝혔다. 이에 따라 7월 1일부터 위믹스3.0 메인넷에 새 토크노믹스 '브리오슈 하드포크'를 적용한다. 반감기가 도입되며 블록당 1개씩 발행되는 '위믹스' 민팅 규칙은 16차례의 업데이트를 거쳐 감소시키는 것이 핵심이다. 재단이 보유한 물량 중 약 4억3500만개가 소각될 예정이다. 남은 물량은 유통 계획에 따라 생태계 발전 기금이나 개발비 등으로 분배할 예정이다. 위믹스 가치를 제고하고, 커뮤니티와의 동반 성장을 도모한다는 계획이다. 이와 함께 위믹스 기반의 블록체인 게임 플랫폼 '위믹스 플레이'도 새롭게 개편된다. 현재 개발 중인 다중접속역할수행게임(MMORPG) '레전드 오브 이미르'에도 블록체인 기술을 접목한다고 밝혔다. 지난 3월 '위믹스의 아버지'로 불리던 장현국 대표가 사임하고 창업주인 박관호 대표가 경영 전면에 나선 이후 위메이드는 블록체인 사업을 정리해 위믹스 가격이 약세를 나타냈다. 위메이드는 최근 '미르' 지식재산권(IP)에 위믹스 기반 토큰 경제를 적용한 '미르M' 글로벌 서비스를 종료했다. 상대적으로 매출에 기여하지 못하는 '미르M'의 서비스를 접고 블록체인 게임 매출을 견인하는 '나이트 크로우'에 집중하겠다는 의도로 풀이된다. 이밖에도 가상자산 지급 '플레이월렛'의 한국 서비스와 탈중앙화금융(디파이) '위믹스 커런시' 등의 서비스도 종료했다. 블록체인 사업 기조가 다소 축소되면서 위믹스는 좀처럼 반등 기미를 보이지 않았다. 위믹스 반감기 도입과 물량 소각 등 토크노믹스 개편 소식에 전날 위믹스 가격이 급등하긴 했지만 여전히 지난해 12월 5300원대를 기록한 것엔 미치지 못한다. 지난 26일 오후 3시30분 기준 위믹스 가격은 전날 보다 18.1% 오른 1905원대를 기록했다. 주가도 비슷한 흐름을 보인다. 위믹스 가격이 급등했던 지난 3월 위메이드 주가는 7만6100원(3월21일 종가)까지 올랐지만 이후 우하향 곡선을 그렸다. 지난 26일 종가 기준 4만2600원을 기록하면서 3개월새 약 44% 하락했다. 박 대표는 지난 5월 1분기 실적발표 컨퍼런스 콜에서 \"조직 구조 재편, 리스크 관리 강화와 비용 최적화를 통해 수익화 중심 블록체인 사업 확장 전략을 추진함으로써 위믹스 생태계와 위메이드의 장기적인 성장을 극대화하겠다\"고 밝혔다. \\</article> <br> \\<article> 위메이드가 '선택과 집중'을 통한 효율성 강화에 나선다. 지난 3월 12년 만에 경영 일선에 복귀한 박관호 대표는 게임 산업에 집중하며 반등을 이끌고 있다. 게임 관련 매출 성장세가 예상되는 가운데 비용 관리가 위메이드의 실적을 좌우할 것으로 보인다. 8일 업계에 따르면 위메이드는 신사업 확장으로 인한 비용 증가로 오랜 기간 적자를 기록하고 있다. 2019년 1136억 원이었던 위메이드의 매출은 2022년 4635억 원, 지난해 6053억 원 까지 성장했다. 하지만, 2022년과 2023년 각각 영업 손실 약 1310억 원, 1570억 원을 기록하며 적자 폭은 깊어지고 있다. 이를 개선하기 위해 위메이드는 수익성이 적은 사업 정리에 나서고 있다. 실제, 박 대표는 지난 3월 개최된 정기주주총회에서 \"적자가 커 회사 비용을 최적화 해야 한다\"고 언급한 바 있다. 위메이드는 미르M 국내외 서비스를 종료하겠다고 밝혔으며 영업 비용이 많이 발생했던 블록체인 사업 교통정리에도 나서고 있다. 박 대표가 취임한 이후 종료 및 축소 공지를 내린 블록체인 서비스만 10여개나 된다.업계는 위메이드가 게임 산업에 집중하기 위해 이런 전략을 구성했다고 평가했다. 업계 관계자는 \"세계적으로 블록체인·NFT(대체불가토큰) 관련 사업에 대한 기대감이 떨어지고 있다\"며 \":이런 상황에서 위메이드가 선택과 집중을 가져가는 것은 자연스러운 현상\"이라고 말했다. 다행히 위메이드의 게임 사업 분위기는 좋은 상황이다. 지난 1분기 출시된 '나이트크로우' 글로벌 버전이 론칭 3일 만에 누적 매출 1000만 달러(이날 기준138억1700만 원)을 기록하는 등 호성적을 기록했다. 또 하반기 기대작 '레전드 오브 이미르'가 출시될 예정이다. 미르4와 미르M 중국 출시도 위메이드 성적 개선에 키포인트다. 위메이드가 2001년 부터 중국에서 '미르의 전설2'를 서비스했던 역량을 바탕으로 중국 시장 선점에 나설 것으로 예상된다. 2020년 보스턴컨설팅그룹(BCG)에 따르면 중국 내 미르 IP의 시장 규모는 대해 연간 9조 원으로 평가받는다. 증권가는 위메이드가 이런 전략에 힘입어 3분기부터 실적 회복에 나설 것이라고 내다봤다. NH 투자증권에 따르면 위메이드는 3분기부터 영업이익 99억7000억 원을 기록하며 흑자전환할 것으로 예상된다.  한편, 위메이드는 블록체인 게임 플랫폼 '위믹스 플레이(WEMIX PLAY)의 개편을 진행한다. 이를 위해 오는 16일 '위믹스 데이'를 개최하고 관련 내용을 공유한다. 위믹스 데이에서는 새롭게 선보일 고도화된 블록체인 서비스와 토크노믹스가 처음으로 공개된다. 또 블록체인 게임 이용자, 커뮤니티 등 위믹스 생태계 전반이 함께 성장할 수 있도록, 토크노믹스를 강화하고 고품질 게임을 온보딩해 커뮤니티 중심 플랫폼으로 변화할 예정이다. 위메이드 관계자는 \"위믹스 플레이와 위믹스 리퍼블릭 중심으로 위믹스 생태계를 키워나갈 예정\"이라며 \"현재 서비스 중인 게임들과 앞으로 다가오는 신작 흥행에도 집중해 호성적을 기록할 것\"이라고 말했다.  \\</article>|\n",
    "\n",
    "<br>\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|SYSTEM|논문 초록과 제안된 논문 제목이 제공됩니다. 논문 제목은 독자가 논문의 주제를 잘 파악할 수 있으면서도 눈길을 끌 수 있어야 합니다. 제목이 이러한 기준을 충족하지 않는 경우 5가지 대안을 제안하세요.|\n",
    "|USER| 초록: 최근 생성형 AI 기술의 발전으로 인해 대형 언어 모델(Large Language Model, LLM)의 활용 및 도입이 확대되고 있는 상황에서 기존 연구들은 기업내부 데이터의 활용에 대한 실제 적용사례나 구현방법을 찾아보기 힘들다. 이에 따라 본 연구에서는 가장 많이 이용되고 있는 LangChain 프레임워크를 이용한 LLM 애플리케이션 아키텍처를 활용하여 생성형 AI 서비스를 구현하는 방법을 제시한다. 이를 위해 LLM의 활용을 중심으로, 정보 부족 문제를 극복하는 다양한 방법을 검토하고 구체적인 해결책을 제시하였다. 이를 위해 파인튜닝이나 직접 문서 정보를 활용하는 방법을 분석하며, 이러한 문제를 해결하기 위한 RAG 모델을 활용한 정보 저장 및 검색 방법에 대해 주요단계에 대해 자세하게 살펴본다. 특히, RAG 모델을 활용하여 정보를 벡터저장소에 저장하고 검색하기 위한 방법으로 유사문맥 추천 및 QA시스템을 활용하였다. 또한 구체적인 작동 방식과 주요한 구현 단계 및 사례를 구현소스 및 사용자 인터페이스까지 제시하여 생성형 AI 기술에 대한 이해를 높였다. 이를 통해 LLM을 활용한 기업내 서비스 구현에 적극적으로 활용할 수 있도록 하는데 의미와 가치가 있다.<br> 제목: LLM 애플리케이션 아키텍처를 활용한 생성형 AI 서비스 구현: RAG모델과 LangChain 프레임워크 기반 |\n",
    "\n",
    "이와 같이 간단한 작업의 경우 구분 기호를 사용해도 출력 품질에 차이가 없을 수 있습니다. 하지만 작업이 복잡할수록 작업 세부 사항을 명확히 구분하는 것이 더 중요합니다. 모델에게 무엇을 요구하는지 정확히 이해하기 위해 모델이 고민하게 하지 마세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성장의 가치 중시하고  \n",
      "책임 성취 더불어  \n",
      "꿈 현실로 만드는 곳, 위메이드의 비전\n"
     ]
    }
   ],
   "source": [
    "user_msg = HumanMessage(content='3연속 큰따옴표로 구분된 텍스트를 시조로 요약하세요.\"\"\"위메이드는 성장의 가치, 책임의 가치 그리고 성취의 가치를 중요시합니다. 누군가의 꿈이 현실로 이루어지면서 세상은 더 좋은 곳으로 발전하고 있습니다. 게임에서 시작하여 다양한 문화의 영역에서 무한한 상상을 현실로 만드는 창조집단, 그것이 위메이드의 비전입니다.\"\"\"')\n",
    "response = llm.invoke([user_msg])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제공된 제목은 논문의 내용을 잘 반영하고 있지만, 더 눈길을 끌고 주제를 명확히 전달할 수 있는 대안을 제시하겠습니다.\n",
      "\n",
      "1. **기업 내 데이터 활용을 위한 생성형 AI 서비스 구현: LangChain과 RAG 모델의 통합**\n",
      "2. **LangChain과 RAG 모델을 이용한 LLM 기반 생성형 AI 서비스 아키텍처**\n",
      "3. **대형 언어 모델을 활용한 기업용 생성형 AI 서비스: LangChain과 RAG 모델의 적용**\n",
      "4. **LLM과 LangChain을 이용한 생성형 AI 서비스 구현 방법론: RAG 모델 중심으로**\n",
      "5. **기업 데이터를 활용한 생성형 AI 서비스: LangChain과 RAG 모델의 실용적 접근**\n"
     ]
    }
   ],
   "source": [
    "system_msg= SystemMessage(content=\"\"\"\n",
    "논문 초록과 제안된 논문 제목이 제공됩니다. 논문 제목은 독자가 논문의 주제를 잘 파악할 수 있으면서도 눈길을 끌 수 있어야 합니다. 제목이 이러한 기준을 충족하지 않는 경우 5가지 대안을 제안하세요.\n",
    "\"\"\")\n",
    "user_msg = HumanMessage(content=\"\"\"\n",
    "초록: 최근 생성형 AI 기술의 발전으로 인해 대형 언어 모델(Large Language Model, LLM)의 활용 및 도입이 확대되고 있는 상황에서 기존 연구들은 기업내부 데이터의 활용에 대한 실제 적용사례나 구현방법을 찾아보기 힘들다. 이에 따라 본 연구에서는 가장 많이 이용되고 있는 LangChain 프레임워크를 이용한 LLM 애플리케이션 아키텍처를 활용하여 생성형 AI 서비스를 구현하는 방법을 제시한다. 이를 위해 LLM의 활용을 중심으로, 정보 부족 문제를 극복하는 다양한 방법을 검토하고 구체적인 해결책을 제시하였다. 이를 위해 파인튜닝이나 직접 문서 정보를 활용하는 방법을 분석하며, 이러한 문제를 해결하기 위한 RAG 모델을 활용한 정보 저장 및 검색 방법에 대해 주요단계에 대해 자세하게 살펴본다. 특히, RAG 모델을 활용하여 정보를 벡터저장소에 저장하고 검색하기 위한 방법으로 유사문맥 추천 및 QA시스템을 활용하였다. 또한 구체적인 작동 방식과 주요한 구현 단계 및 사례를 구현소스 및 사용자 인터페이스까지 제시하여 생성형 AI 기술에 대한 이해를 높였다. 이를 통해 LLM을 활용한 기업내 서비스 구현에 적극적으로 활용할 수 있도록 하는데 의미와 가치가 있다.\n",
    "제목: LLM 애플리케이션 아키텍처를 활용한 생성형 AI 서비스 구현: RAG모델과 LangChain 프레임워크 기반\n",
    "\"\"\")\n",
    "\n",
    "response = llm.invoke([system_msg,user_msg])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방안 4: 작업 완료에 필요한 단계 지정하기\n",
    "\n",
    "일부 복잡한 작업들은 일련의 단계로 나누어 지정하는 것이 좋습니다. 단계를 명시적으로 작성하면 모델이 더 쉽게 따라갈 수 있습니다.\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|SYSTEM|다음 단계별 지침에 따라 사용자 입력에 응답합니다.<br>1단계 - 사용자가 3연속 큰따옴표로 묶은 텍스트를 제공합니다. 이 텍스트를 \"요약:\"이라는 접두사를 사용하여 한 문장으로 요약합니다.<br>2단계 - 1단계의 요약을 영어로 번역하고 \"번역:\"이라는 접두어를 사용하여 제공합니다..|\n",
    "|USER|\"\"\"위메이드의 핵심 가치는 성장, 책임, 성취입니다.위메이드의 목적은 개인의 책임 완수를 통한 성취를 통해 기업이 성장하는데 있으며, 이를 법규나 규율로 강제하지 않고 비전의 공유를 통한 목표의 일치, 역할과 그에 걸맞는 권한의 부여 그리고 공정하고 명확한 보상을 통해 선순환 할 수 있는 가치 체계를 공감하고 체득할 수 있게 하는데, 이를 위메이드 e라 부릅니다. 위메이드의 가치 체계는 소문자 e의 궤적을 그리며 순환합니다. e가 상징하는 바는 다음과 같습니다. evolution(진화) 회사의 성장은 일회성 이벤트가 아니며, 반복적이고 지속적이며 이를 통해 회사가 양적 성장 뿐만 아니라 질적 성장과 함께 시장과 시대의 변화에 맞추어 진화하는 것을 그 목표로 하고 있습니다. eco system(생태계) 위메이드의 가치는 비상식적이거나 도달 불가능한 구호가 아닌, 개인이 자신의 위치에서 적합한 역할을 수행할 때 자연스러운 전체가 되어 목표를 이룰 수 있는 가치 생태계의 구축을 그 목표로 하고 있습니다. exponential(기하급수적) 위메이드의 가치 체계는 성장이 반복될 때마다 회사의 성장 속도와 폭은 점점 빨라지고 커지는 기하급수적 성장을 가능하게 하는 선순환 구조를 이루고 있습니다.\"\"\"|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약: 위메이드는 성장, 책임, 성취를 핵심 가치로 하며, 개인의 책임 완수를 통해 기업이 성장하는 선순환 구조를 목표로 합니다.\n",
      "\n",
      "번역: Wemade's core values are growth, responsibility, and achievement, aiming for a virtuous cycle where the company grows through the fulfillment of individual responsibilities.\n"
     ]
    }
   ],
   "source": [
    "system_msg= SystemMessage(content=\"\"\"\n",
    "다음 단계별 지침에 따라 사용자 입력에 응답합니다.\n",
    "1단계 - 사용자가 3연속 큰따옴표로 묶은 텍스트를 제공합니다. 이 텍스트를 \"요약:\"이라는 접두사를 사용하여 한 문장으로 요약합니다.\n",
    "2단계 - 1단계의 요약을 영어로 번역하고 \"번역:\"이라는 접두어를 사용하여 제공합니다.\n",
    "\"\"\")\n",
    "user_msg = HumanMessage(content='\"\"\"위메이드의 핵심 가치는 성장, 책임, 성취입니다.위메이드의 목적은 개인의 책임 완수를 통한 성취를 통해 기업이 성장하는데 있으며, 이를 법규나 규율로 강제하지 않고 비전의 공유를 통한 목표의 일치, 역할과 그에 걸맞는 권한의 부여 그리고 공정하고 명확한 보상을 통해 선순환 할 수 있는 가치 체계를 공감하고 체득할 수 있게 하는데, 이를 위메이드 e라 부릅니다. 위메이드의 가치 체계는 소문자 e의 궤적을 그리며 순환합니다. e가 상징하는 바는 다음과 같습니다. evolution(진화) 회사의 성장은 일회성 이벤트가 아니며, 반복적이고 지속적이며 이를 통해 회사가 양적 성장 뿐만 아니라 질적 성장과 함께 시장과 시대의 변화에 맞추어 진화하는 것을 그 목표로 하고 있습니다. eco system(생태계) 위메이드의 가치는 비상식적이거나 도달 불가능한 구호가 아닌, 개인이 자신의 위치에서 적합한 역할을 수행할 때 자연스러운 전체가 되어 목표를 이룰 수 있는 가치 생태계의 구축을 그 목표로 하고 있습니다. exponential(기하급수적) 위메이드의 가치 체계는 성장이 반복될 때마다 회사의 성장 속도와 폭은 점점 빨라지고 커지는 기하급수적 성장을 가능하게 하는 선순환 구조를 이루고 있습니다.\"\"\"')\n",
    "\n",
    "\n",
    "response = llm.invoke([system_msg,user_msg])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방안 5 : 예제 제공 \n",
    "모든 예제에 적용되는 일반적인 지침을 제공하는 것이 일반적으로 작업의 모든 변형을 예제로 보여주는 것보다 더 효율적이지만 경우에 따라서는 예제를 제공하는 것이 더 쉬울 수도 있습니다. 예를 들어 모델이 명시적으로 설명하기 어려운 특정 스타일의 사용자 쿼리 응답을 모방하도록 하려는 경우입니다. 이를 \"few-shot\" 프롬프트라고 합니다. 제공하는 예제의 수에 따라 zero-shot , one-shot, few-shot 프롬프팅으로 분류합니다. \n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|SYSTEM|사용자의 질의에 일관된 스타일로 답변하세요. 예를 들어, 사용자가 인내심에 대해 가르쳐달라고 요청하면, \"\"\"가장 깊은 계곡을 깎아내는 강은 소박한 샘에서 기원하고, 가장 웅장한 교향곡은 하나의 음표에서 시작되며, 가장 복잡한 태피스트리는 한가닥 실에서 시작됩니다.\"\"\"와 같이 답합니다. |\n",
    "|USER|바다에 대해 가르쳐주세요|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바다는 대지의 심장과 같아, 그 맥박은 조수의 흐름을 통해 느낄 수 있습니다. 가장 깊은 심연 속에는 미지의 생명들이 숨쉬고, 가장 잔잔한 수면 위에는 바람의 속삭임이 머무릅니다. 그 끝없는 수평선은 우리의 상상력을 자극하며, 바다의 무한한 깊이는 우리의 영혼을 탐구하게 만듭니다. 바다는 우리에게 겸손함을 가르치고, 그 위대한 힘과 아름다움은 우리의 일상 속에서 경외감을 불러일으킵니다.\n"
     ]
    }
   ],
   "source": [
    "system_msg= SystemMessage(content=\"\"\"\n",
    "사용자의 질의에 일관된 스타일로 답변하세요. 예를 들어, 사용자가 인내심에 대해 가르쳐달라고 요청하면, \"가장 깊은 계곡을 깎아내는 강은 소박한 샘에서 기원하고, 가장 웅장한 교향곡은 하나의 음표에서 시작되며, 가장 복잡한 태피스트리는 한가닥 실에서 시작됩니다.\"와 같이 답합니다.\n",
    "\"\"\")\n",
    "user_msg = HumanMessage(content='바다에 대해 가르쳐주세요')\n",
    "\n",
    "\n",
    "response = llm.invoke([system_msg,user_msg])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방안 6: 원하는 출력 길이 지정\n",
    "모델에 지정된 목표 길이의 출력을 생성하도록 요청할 수 있습니다. 목표 출력 길이는 단어, 문장, 단락, 글머리 기호 등의 개수로 지정할 수 있습니다. 그러나 모델에 특정 단어 수를 생성하도록 지시하는 것은 높은 정확도로 작동하지 않는다는 점에 유의하세요. 모델은 특정 수의 단락 또는 글머리 기호로 출력을 더 안정적으로 생성할 수 있습니다.\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|USER|3연속 큰따옴표로 구분된 텍스트를 50단어 내로 요약해주세요. \"\"\"텍스트 입력\"\"\"|\n",
    "|USER|3연속 큰따옴표로 구분된 텍스트를 2 문단 내로 요약해주세요. \"\"\"텍스트 입력\"\"\"|\n",
    "|USER|3연속 큰따옴표로 구분된 텍스트를 50단어 내로 요약해주세요. \"\"\"텍스트 입력\"\"\"|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전략 2 : 참조 텍스트 제공\n",
    "\n",
    "#### 방안 1 : 모델에게 참조 텍스트를 사용하여 응답하도록 지시하기\n",
    "현재 쿼리와 관련된 신뢰할 수 있는 정보를 모델에 제공할 수 있다면 모델에 제공된 정보를 사용하여 답변을 작성하도록 지시할 수 있습니다. \n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|----|\n",
    "|SYSTEM|제공된 도움말을 큰따옴표로 구분하여 질문에 답하세요. 문서에서 답을 찾을 수 없는 경우에는 \"답을 찾을 수 없습니다.\"라고 작성합니다.|\n",
    "|USER|\\<insert articles, each delimited by triple quotes\\><br>Question: \\<insert question here\\>|\n",
    "\n",
    "모든 모델의 컨텍스트 창이 제한되어 있기 때문에 질문과 관련된 정보를 동적으로 조회할 수 있는 방법이 필요합니다. 보통 이를 위하여 Keyword 검색, Vector database와 Embedding model을 활용한 semantic search, knowledge graph를 활용한 지식 탐색 등의 기술을 활용하여 검색 증강 생성 : RAG (Retrieval Augmented Generation)을 구현합니다. RAG 자체는 오늘 실습 범위를 넘어가므로 이러한 개념이 있다는 것을 우선 이해하도록 합니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방안 2: 모델에게 참조 텍스트를 인용하여 답변하도록 지시하기\n",
    "위에서 기술된 RAG에 의해서 사용자 입력에 관련 지식이 보완된 경우, 제공된 문서의 구절을 참조하여 모델에 답변에 인용문을 추가하도록 요청하는 것은 간단합니다. 그런 다음 제공된 문서 내에서 문자열 일치를 통해 출력의 인용을 프로그래밍 방식으로 확인할 수 있습니다.\n",
    "\n",
    "|역할|프롬프트|\n",
    "|----|----|\n",
    "|SYSTEM|3중 따옴표로 구분된 문서와 질문이 제공됩니다. 제공된 문서만을 사용하여 질문에 답하고 질문에 답하는 데 사용된 문서의 구절을 인용해야 합니다. 문서에 이 질문에 답하는 데 필요한 정보가 포함되어 있지 않은 경우 그냥 \"정보 불충분\"이라고 응답하십시오. 질문에 대한 답변이 제공된 경우 반드시 인용 주석을 달아야 합니다. 관련 구절을 인용하려면 다음 형식을 사용합니다({\"인용\": ...}).|\n",
    "|USER|\"\"\"'문서삽입'\"\"\"<br>질문:'질문삽입'|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전략 3: 복잡한 작업을 더 간단한 하위 작업으로 나누기 \n",
    "#### 방안 1 : 의도 분류를 사용하여 사용자 쿼리에 가장 관련성이 높은 명령어를 식별하기 \n",
    "다양한 경우를 처리하기 위해 많은 독립적인 명령어 집합이 필요한 작업의 경우 먼저 쿼리 유형을 분류하고 그 분류를 사용하여 어떤 명령어가 필요한지 결정하는 것이 유용할 수 있습니다. 이는 고정 카테고리를 정의하고 해당 카테고리의 작업을 처리하는 데 관련된 지침을 정의함으로써 달성할 수 있습니다. 이 프로세스를 재귀적으로 적용하여 작업을 일련의 단계로 분해할 수도 있습니다. 이 접근 방식의 장점은 각 쿼리에는 작업의 다음 단계를 수행하는 데 필요한 명령어만 포함되므로 전체 작업을 수행하는 데 단일 쿼리를 사용하는 것보다 오류율이 낮아질 수 있다는 것입니다. 또한 프롬프트가 클수록 실행 비용이 더 많이 들기 때문에 비용도 절감할 수 있습니다. 예를 들어 고객 서비스 애플리케이션의 경우 쿼리를 다음과 같이 유용하게 분류할 수 있다고 가정해 보겠습니다:\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|----|\n",
    "|SYSTEM|고객 지원 서비스를 제공해야 합니다. 각 고객의 질의를 기본 카테고리와 보조 카테고리로 분류합니다. 기본 및 보조 키가 포함된 json 형식의 출력을 제공합니다. 기본 카테고리: 청구, 기술 지원, 계정 관리 또는 일반 문의<br>청구 보조 카테고리: <br>- 구독 취소 또는 업그레이드 <br>- 결제 방법 추가 <br>- 청구 설명 <br>- 청구 이의 제기 <br>기술 지원 보조 카테고리: <br>- 문제 해결 <br>- 장치 호환성 <br>- 소프트웨어 업데이트 <br>계정 관리 보조 카테고리: <br>- 비밀번호 재설정 <br>- 개인 정보 업데이트 <br>- 계정 폐쇄 <br>- 계정 보안 <br>일반 문의 보조 카테고리: <br>- 제품 정보 <br>- 가격 <br>- 피드백 <br>- 상담원에게 문의하기|\n",
    "|USER|인터넷이 동작하지 않습니다. 인터넷 수리가 필요합니다.|\n",
    "\n",
    "고객 문의의 분류에 따라 모델이 다음 단계를 처리할 수 있도록 보다 구체적인 지침을 모델에 제공할 수 있습니다. 예를 들어 고객이 '문제 해결'에 대한 도움이 필요하다고 가정해 보겠습니다.\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|----|\n",
    "|SYSTEM|기술 지원 맥락에서 문제 해결이 필요한 고객 서비스 문의를 받게 됩니다. 다음과 같은 방법으로 사용자를 도와주세요. <br>- 라우터에 연결된 모든 케이블이 연결되어 있는지 확인하도록 요청하세요. 시간이 지나면 케이블이 느슨해지는 것이 일반적이라는 점에 유의하세요. <br>- 모든 케이블이 연결되었는데도 문제가 지속되면 사용 중인 라우터 모델을 물어보세요. <br>- 이제 장치를 다시 시작하는 방법을 알려주세요: <br>-- 모델 번호가 MTD-327J인 경우 빨간색 버튼을 5초간 누른 다음 5분간 기다렸다가 연결을 테스트하라고 알려주세요. <br>-- 모델 번호가 MTD-327S인 경우 플러그를 뽑았다가 다시 연결하고 5분간 기다렸다가 연결을 테스트하라고 알려주세요.<br>- 기기를 다시 시작하고 5분을 기다린 후에도 고객의 문제가 지속되면 {\"IT 지원 요청됨\"}을 출력하여 IT 지원팀에 연결합니다. <br>- 사용자가 이 주제와 관련 없는 질문을 시작하면 문제 해결에 대한 현재 채팅을 종료할 것인지 확인하고 다음 체계에 따라 요청을 분류합니다: <위에서 기본/보조 분류 체계 삽입>|\n",
    "|USER|인터넷이 동작하지 않습니다. 인터넷 수리가 필요합니다.|\n",
    "\n",
    "대화의 상태가 변경될 때를 나타내는 특수 문자열을 방출하도록 모델에 지시를 내렸음을 알 수 있습니다. 이를 통해 시스템을 상태에 따라 주입되는 명령어가 결정되는 상태 머신으로 전환할 수 있습니다. 상태, 해당 상태와 관련된 명령어, 그리고 선택적으로 해당 상태에서 허용되는 상태 전환을 추적함으로써 덜 구조화된 접근 방식으로는 달성하기 어려운 사용자 경험에 가드레일을 설치할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"기본 카테고리\": \"기술 지원\",\n",
      "  \"보조 카테고리\": \"문제 해결\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "system_msg= SystemMessage(content=\"\"\"\n",
    "고객 지원 서비스를 제공해야 합니다. 각 고객의 질의를 기본 카테고리와 보조 카테고리로 분류합니다. 기본 및 보조 키가 포함된 json 형식의 출력을 제공합니다. 기본 카테고리: 청구, 기술 지원, 계정 관리 또는 일반 문의\n",
    "청구 보조 카테고리: \n",
    "- 구독 취소 또는 업그레이드\n",
    "- 결제 방법 추가\n",
    "- 청구 설명 \n",
    "- 청구 이의 제기 \n",
    "기술 지원 보조 카테고리: \n",
    "- 문제 해결 \n",
    "- 장치 호환성 \n",
    "- 소프트웨어 업데이트 \n",
    "계정 관리 보조 카테고리: \n",
    "- 비밀번호 재설정\n",
    "- 개인 정보 업데이트\n",
    "- 계정 폐쇄\n",
    "- 계정 보안 \n",
    "일반 문의 보조 카테고리: \n",
    "- 제품 정보 \n",
    "- 가격 \n",
    "- 피드백 \n",
    "- 상담원에게 문의하기\n",
    "\"\"\")\n",
    "user_msg = HumanMessage(content='인터넷이 동작하지 않습니다. 인터넷 수리가 필요합니다.')\n",
    "\n",
    "response = llm.invoke([system_msg,user_msg])\n",
    "print(response.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "먼저 라우터에 연결된 모든 케이블이 제대로 연결되어 있는지 확인해 주시겠어요? 시간이 지나면 케이블이 느슨해질 수 있습니다. 모든 케이블이 제대로 연결되어 있는지 확인해 주세요.\n"
     ]
    }
   ],
   "source": [
    "system_msg = SystemMessage(content=\"\"\"\n",
    "기술 지원 맥락에서 문제 해결이 필요한 고객 서비스 문의를 받게 됩니다. 다음과 같은 방법으로 사용자를 도와주세요. \n",
    "- 라우터에 연결된 모든 케이블이 연결되어 있는지 확인하도록 요청하세요. 시간이 지나면 케이블이 느슨해지는 것이 일반적이라는 점에 유의하세요. \n",
    "- 모든 케이블이 연결되었는데도 문제가 지속되면 사용 중인 라우터 모델을 물어보세요. \n",
    "- 이제 장치를 다시 시작하는 방법을 알려주세요: \n",
    "-- 모델 번호가 MTD-327J인 경우 빨간색 버튼을 5초간 누른 다음 5분간 기다렸다가 연결을 테스트하라고 알려주세요. \n",
    "-- 모델 번호가 MTD-327S인 경우 플러그를 뽑았다가 다시 연결하고 5분간 기다렸다가 연결을 테스트하라고 알려주세요.\n",
    "- 기기를 다시 시작하고 5분을 기다린 후에도 고객의 문제가 지속되면 {\"IT 지원 요청됨\"}을 출력하여 IT 지원팀에 연결합니다. \n",
    "- 사용자가 이 주제와 관련 없는 질문을 시작하면 문제 해결에 대한 현재 채팅을 종료할 것인지 확인합니다.\n",
    "\"\"\")\n",
    "user_msg = HumanMessage(content='인터넷이 동작하지 않습니다. 인터넷 수리가 필요합니다. 어떻게 해야 하나요?')\n",
    "\n",
    "response = llm.invoke([system_msg,user_msg])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방안 2 : 매우 긴 대화가 필요한 대화 애플리케이션의 경우 이전 대화를 요약하거나 필터링하기 \n",
    "모델에는 고정된 컨텍스트 길이가 있으므로 전체 대화가 컨텍스트 창에 포함되는 사용자와 어시스턴트 간의 대화를 무한정 계속할 수 없습니다. 이 문제에 대한 다양한 해결 방법이 있는데, 그 중 하나는 대화의 이전 회차를 요약하는 것입니다. 입력의 크기가 미리 정해진 임계값 길이에 도달하면 대화의 일부를 요약하는 쿼리가 트리거되고 이전 대화의 요약이 시스템 메시지의 일부로 포함될 수 있습니다. 또는 전체 대화에 걸쳐 백그라운드에서 비동기적으로 이전 대화가 요약될 수도 있습니다. 또 다른 해결책은 현재 쿼리와 가장 관련성이 높은 대화의 이전 부분을 동적으로 선택하는 것입니다. 이전 대화들을 Archiving하고 위에서 언급했던 검색증강 생성을 통해 컨텍스트 길이 제한을 극복할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방안 3: 긴 문서를 조각별로 요약하고 전체 요약을 재귀적으로 구성하기 \n",
    "모델에는 고정된 문맥 길이가 있으므로 단일 쿼리에서 생성된 요약의 길이를 뺀 문맥 길이보다 긴 텍스트는 요약하는 데 사용할 수 없습니다. 책과 같이 매우 긴 문서를 요약하려면 일련의 쿼리를 사용하여 문서의 각 섹션을 요약할 수 있습니다. 섹션 요약을 연결하고 요약하여 요약의 요약을 생성할 수 있습니다. 이 프로세스는 전체 문서가 요약될 때까지 재귀적으로 진행될 수 있습니다. 이후 섹션을 이해하기 위해 이전 섹션에 대한 정보를 사용해야 하는 경우, 책의 특정 지점 앞의 텍스트에 대한 실행 요약을 포함하면서 해당 지점의 내용을 요약하는 것이 유용할 수 있습니다. 책을 요약하는 이 절차의 효과는 OpenAI의 이전 연구에서 GPT-3의 변형을 사용하여 연구한 바 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전략 4 : 모델에게 \"생각할\" 시간을 주세요.\n",
    "#### 방안 1: 결론을 서두르기 전에 모델 스스로 해결책을 찾도록 지시하세요.\n",
    "때로는 결론에 도달하기 전에 모델에게 첫 번째 원칙에서 추론하도록 명시적으로 지시할 때 더 나은 결과를 얻을 수 있습니다. 예를 들어 수학 문제에 대한 학생의 해답을 평가하기 위해 모델을 사용한다고 가정해 보겠습니다. 이 문제에 접근하는 가장 확실한 방법은 단순히 모델에게 학생의 해답이 맞는지 아닌지를 묻는 것입니다.\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|SYSTEM|학생이 제출한 문제의 답안이 올바른지 결정하여 답변하세요, 정답인지 아닌지만 답변합니다.|\n",
    "|USER|문제 설명: 태양광 발전 설비를 건설 중인데 재정 문제를 해결하는 데 도움이 필요합니다.<br>- 토지 비용이 평방 피트당 $100입니다.<br>- 태양광 패널을 평방피트당 $250에 구입할 수 있습니다.<br>- 연간 10만 달러의 고정 비용과 평방피트당 10달러의 추가 비용이 드는 유지보수 계약을 체결했습니다.<br>평방 피트 수에 따른 운영 첫해의 총 비용은 얼마인가요?<br><br>학생의 답안: x를 평방 피트 단위의 설치 크기라고 합니다.<br>1. 토지 비용: 100x<br>2. 태양광 패널 비용: 250x<br>3. 유지보수 비용: 100,000 + 100x<br>총 비용: 100x + 250x + 100,000 + 100x = 450x + 100,000|\n",
    "\n",
    "하지만 학생의 답안은 사실 정답이 아닙니다! 모델에 먼저 자체 답안을 생성하라는 지시를 프롬프트에 포함하여 모델이 이를 답안의 검토에 성공적으로 활용하도록 할 수 있습니다.\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|----|\n",
    "|SYSTEM|학생이 제출한 문제의 답안이 올바른지 여부를 검토하여 답변합니다.문제 해결을 위한 자신만의 해결책을 먼저 생각해 보세요. 그런 다음 자신의 답안을 학생의 솔루션과 비교하고 학생의 답안이 올바른지 여부를 평가합니다. 문제를 직접 풀기 전에는 학생의 답안이 올바른지 여부를 결정하지 마세요.|\n",
    "|USER|문제 설명: 태양광 발전 설비를 건설 중인데 재정 문제를 해결하는 데 도움이 필요합니다.<br>- 토지 비용이 평방 피트당 $100입니다.<br>- 태양광 패널을 평방피트당 $250에 구입할 수 있습니다.<br>- 연간 10만 달러의 고정 비용과 평방피트당 10달러의 추가 비용이 드는 유지보수 계약을 체결했습니다.<br>평방 피트 수에 따른 운영 첫해의 총 비용은 얼마인가요?<br><br>학생의 답안: x를 평방 피트 단위의 설치 크기라고 합니다.<br>1. 토지 비용: 100x<br>2. 태양광 패널 비용: 250x<br>3. 유지보수 비용: 100,000 + 100x<br>총 비용: 100x + 250x + 100,000 + 100x = 450x + 100,000|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째답변\n",
      "정답입니다.\n",
      "==============\n",
      "두번째답변\n",
      "문제를 해결하기 위해 주어진 정보를 사용하여 각 비용을 계산해보겠습니다. \n",
      "\n",
      "1. **토지 비용**: 평방 피트당 $100이므로, \\( x \\) 평방 피트의 토지 비용은 \\( 100x \\) 달러입니다.\n",
      "2. **태양광 패널 비용**: 평방 피트당 $250이므로, \\( x \\) 평방 피트의 태양광 패널 비용은 \\( 250x \\) 달러입니다.\n",
      "3. **유지보수 비용**: 고정 비용이 연간 $100,000이고, 추가 비용이 평방 피트당 $10이므로, \\( x \\) 평방 피트의 유지보수 비용은 \\( 100,000 + 10x \\) 달러입니다.\n",
      "\n",
      "이제 총 비용을 계산해보겠습니다:\n",
      "- 토지 비용: \\( 100x \\)\n",
      "- 태양광 패널 비용: \\( 250x \\)\n",
      "- 유지보수 비용: \\( 100,000 + 10x \\)\n",
      "\n",
      "따라서, 운영 첫해의 총 비용은 다음과 같습니다:\n",
      "\\[ 100x + 250x + 100,000 + 10x \\]\n",
      "\n",
      "이를 정리하면:\n",
      "\\[ 100x + 250x + 10x + 100,000 = 360x + 100,000 \\]\n",
      "\n",
      "학생의 답안과 비교해보면, 학생은 유지보수 비용을 잘못 계산하여 \\( 100x \\)로 적용하였고, 따라서 총 비용을 \\( 450x + 100,000 \\)으로 잘못 계산했습니다. \n",
      "\n",
      "정답은:\n",
      "\\[ 360x + 100,000 \\]\n",
      "\n",
      "따라서, 학생의 답안은 잘못되었습니다.\n"
     ]
    }
   ],
   "source": [
    "system_msg = SystemMessage(content=\"\"\"\n",
    "학생이 제출한 문제의 답안이 올바른지 결정하여 답변하세요, 정답인지 아닌지만 답변합니다.\n",
    "\"\"\")\n",
    "user_msg = HumanMessage(content=\"\"\"\n",
    "문제 설명: 태양광 발전 설비를 건설 중인데 재정 문제를 해결하는 데 도움이 필요합니다.\n",
    "- 토지 비용이 평방 피트당 $100입니다.\n",
    "- 태양광 패널을 평방피트당 $250에 구입할 수 있습니다.\n",
    "- 연간 10만 달러의 고정 비용과 평방피트당 10달러의 추가 비용이 드는 유지보수 계약을 체결했습니다.\n",
    "평방 피트 수에 따른 운영 첫해의 총 비용은 얼마인가요?\n",
    "\n",
    "학생의 답안: x를 평방 피트 단위의 설치 크기라고 합니다.\n",
    "1. 토지 비용: 100x\n",
    "2. 태양광 패널 비용: 250x\n",
    "3. 유지보수 비용: 100,000 + 100x\n",
    "총 비용: 100x + 250x + 100,000 + 100x = 450x +100,000\n",
    "\"\"\")\n",
    "message=[]\n",
    "message.append(system_msg)\n",
    "message.append(user_msg)\n",
    "response = llm.invoke(message)\n",
    "print(\"첫번째답변\")\n",
    "print(response.content)\n",
    "\n",
    "system_msg = SystemMessage(content=\"\"\"\n",
    "학생이 제출한 문제의 답안이 올바른지 여부를 검토하여 답변합니다.문제 해결을 위한 자신만의 해결책을 먼저 생각해 보세요. 그런 다음 자신의 답안을 학생의 솔루션과 비교하고 학생의 답안이 올바른지 여부를 평가합니다. 문제를 직접 풀기 전에는 학생의 답안이 올바른지 여부를 결정하지 마세요.\n",
    "\"\"\")\n",
    "\n",
    "message=[]\n",
    "message.append(system_msg)\n",
    "message.append(user_msg)\n",
    "response = llm.invoke(message)\n",
    "print(\"==============\")\n",
    "print(\"두번째답변\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방안 2: 내면의 독백 또는 일련의 쿼리를 사용하여 모델의 추론 과정을 숨기기\n",
    "앞의 전술은 모델이 특정 질문에 답하기 전에 문제에 대해 자세히 추론하는 것이 때때로 중요하다는 것을 보여줍니다. 일부 애플리케이션의 경우 모델이 최종 답변에 도달하기 위해 사용하는 추론 프로세스는 사용자와 공유하기에 부적절할 수 있습니다. 예를 들어, 과외 애플리케이션에서는 학생이 스스로 답을 찾도록 유도하고 싶지만, 학생의 해답에 대한 모델의 추론 과정이 학생에게 정답을 알려줄 수 있습니다.\n",
    "\n",
    "내적 독백은 이러한 문제를 완화하는 데 사용할 수 있는 전략입니다. 내적 독백의 개념은 사용자에게 숨겨야 하는 출력의 일부를 구문 분석을 쉽게 할 수 있는 구조화된 형식으로 모델에 지시하는 것입니다. 그런 다음 사용자에게 출력을 표시하기 전에 출력을 구문 분석하여 출력의 일부만 표시합니다.\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|----|\n",
    "|SYSTEM|다음 단계에 따라 사용자 문의에 답변하세요.<br><br>1단계 - 먼저 문제에 대한 자신만의 답안을 찾아봅니다. 학생의 답안은 틀릴 수 있으므로 의존하지 마세요. 이 단계의 모든 작업은 3중 큰따옴표(\"\"\") 안에 넣으세요.<br><br> 2단계 - 자신의 답안을 학생의 답안과 비교하고 학생의 답안이 올바른지 여부를 평가합니다. 이 단계의 모든 작업을 3중 큰따옴표(\"\"\") 안에 묶습니다.<br><br>3단계 - 학생이 실수한 경우 답을 알려주지 않고 학생에게 어떤 힌트를 줄 수 있는지 결정합니다. 이 단계의 모든 작업을 3중 큰따옴표(\"\"\") 안에 묶습니다.<br><br>4단계 - 학생이 실수한 경우 이전 단계의 힌트를 학생에게 제공합니다(3중 큰따옴표 바깥쪽). \"4단계 - ...\"라고 쓰는 대신 \"힌트:\"라고 씁니다.|\n",
    "|USER| 문제 설명: \\<문제 설명 삽입\\> <br><br> 학생 답안: \\<학생 답안 삽입\\>|\n",
    "\n",
    "또는 마지막 쿼리를 제외한 모든 쿼리가 최종 사용자에게 출력을 숨기도록 하는 일련의 쿼리를 사용하여 이를 달성할 수도 있습니다. 먼저, 모델에 스스로 문제를 풀도록 요청합니다. 이 초기 쿼리는 학생의 솔루션이 필요하지 않으므로 생략할 수 있습니다. 이렇게 하면 학생의 솔루션에 의해 모델의 솔루션이 편향될 가능성이 없다는 추가적인 이점이 있습니다.\n",
    "\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|----|\n",
    "|USER| \\<문제 설명 삽입\\>|\n",
    "\n",
    "이제 학생이 답안을 입력하면 모델이 필요한 모든 정보가 모였으니, 이를 사용하여 학생의 솔루션의 정확성을 평가하도록 할 수 있습니다.\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|----|\n",
    "|SYSTEM|당신의 답안과 학생이 제출한 답안을 비교하고 학생의 답안이 올바른지 여부를 평가합니다.|\n",
    "|USER|문제 설명: \"\"\"\\<문제 설명 삽입\\>\"\"\" <br>당신의 답안:\"\"\"\\<모델 생성 답안 삽입\\>\"\"\" <br>학생 답안: \"\"\"\\<학생 답안 삽입\\>\"\"\"|\n",
    "\n",
    "마지막으로 모델이 자체 분석을 사용하여 유용한 튜터의 페르소나로 답장을 작성하도록 할 수 있습니다.\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|----|\n",
    "|SYSTEM|당신은 수학 과외 선생님입니다. 학생이 오류를 범한 경우 답안을 바로 공개하지 않는 방식으로 학생에게 힌트를 제공합니다. 학생이 오류를 범하지 않았다면 격려의 댓글을 제공하세요.|\n",
    "|USER|문제 설명: \"\"\"\\<문제 설명 삽입\\>\"\"\"<br>당신의 답안: \"\"\"\\<모델 생성 솔루션 삽입\\>\"\"\"<br>학생의 답안: \"\"\"\\<학생의 답안 삽입\\>\"\"\"<br>분석: \"\"\"\\<이전 단계에서 생성된 모델 분석 삽입\\>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "1단계 - 먼저 문제에 대한 자신만의 답안을 찾아봅니다.\n",
      "\n",
      "먼저 각 비용을 정리해 봅니다.\n",
      "- 토지 비용: 평방 피트당 $100이므로, x 평방 피트일 때 토지 비용은 100x 달러입니다.\n",
      "- 태양광 패널 비용: 평방 피트당 $250이므로, x 평방 피트일 때 패널 비용은 250x 달러입니다.\n",
      "- 유지보수 비용: 연간 고정 비용이 $100,000이고, 평방 피트당 추가 유지보수 비용이 $10이므로, x 평방 피트일 때 유지보수 비용은 100,000 + 10x 달러입니다.\n",
      "\n",
      "따라서 운영 첫해의 총 비용은 다음과 같이 계산할 수 있습니다:\n",
      "총 비용 = 토지 비용 + 태양광 패널 비용 + 유지보수 비용\n",
      "         = 100x + 250x + (100,000 + 10x)\n",
      "         = 360x + 100,000\n",
      "\n",
      "2단계 - 자신의 답안을 학생의 답안과 비교하고 학생의 답안이 올바른지 여부를 평가합니다.\n",
      "\n",
      "학생의 답안은 다음과 같습니다:\n",
      "1. 토지 비용: 100x\n",
      "2. 태양광 패널 비용: 250x\n",
      "3. 유지보수 비용: 100,000 + 100x\n",
      "총 비용: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
      "\n",
      "학생은 유지보수 비용에서 실수를 했습니다. 유지보수 비용은 100,000 + 10x이어야 하는데, 학생은 100,000 + 100x로 잘못 계산했습니다. 따라서 학생의 총 비용 계산도 잘못되었습니다.\n",
      "\n",
      "3단계 - 학생이 실수한 경우 답을 알려주지 않고 학생에게 어떤 힌트를 줄 수 있는지 결정합니다.\n",
      "\n",
      "유지보수 비용을 다시 한 번 확인해 보세요. 연간 고정 비용과 평방 피트당 추가 비용을 올바르게 계산했는지 점검해 보세요.\n",
      "\n",
      "4단계 - 학생이 실수한 경우 이전 단계의 힌트를 학생에게 제공합니다.\n",
      "\"\"\"\n",
      "\n",
      "힌트: 유지보수 비용을 다시 한 번 확인해 보세요. 연간 고정 비용과 평방 피트당 추가 비용을 올바르게 계산했는지 점검해 보세요.\n"
     ]
    }
   ],
   "source": [
    "system_msg = SystemMessage(content='''\n",
    "다음 단계에 따라 사용자 문의에 답변하세요.\n",
    "\n",
    "1단계 - 먼저 문제에 대한 자신만의 답안을 찾아봅니다. 학생의 답안은 틀릴 수 있으므로 의존하지 마세요. 이 단계의 모든 작업은 3중 큰따옴표(\"\"\") 안에 넣으세요. \n",
    "2단계 - 자신의 답안을 학생의 답안과 비교하고 학생의 답안이 올바른지 여부를 평가합니다. 이 단계의 모든 작업을 3중 큰따옴표(\"\"\") 안에 묶습니다.\n",
    "3단계 - 학생이 실수한 경우 답을 알려주지 않고 학생에게 어떤 힌트를 줄 수 있는지 결정합니다. 이 단계의 모든 작업을 3중 큰따옴표(\"\"\") 안에 묶습니다.\n",
    "4단계 - 학생이 실수한 경우 이전 단계의 힌트를 학생에게 제공합니다(3중 큰따옴표 바깥쪽). \"4단계 - ...\"라고 쓰는 대신 \"힌트:\"라고 씁니다.\n",
    "''')\n",
    "\n",
    "user_msg = HumanMessage(content='''\n",
    "문제 설명: 태양광 발전 설비를 건설 중인데 재정 문제를 해결하는 데 도움이 필요합니다.\n",
    "- 토지 비용이 평방 피트당 $100입니다.\n",
    "- 태양광 패널을 평방피트당 $250에 구입할 수 있습니다.\n",
    "- 연간 10만 달러의 고정 비용과 평방피트당 10달러의 추가 비용이 드는 유지보수 계약을 체결했습니다.\n",
    "평방 피트 수에 따른 운영 첫해의 총 비용은 얼마인가요?\n",
    "\n",
    "학생의 답안: x를 평방 피트 단위의 설치 크기라고 합니다.\n",
    "1. 토지 비용: 100x\n",
    "2. 태양광 패널 비용: 250x\n",
    "3. 유지보수 비용: 100,000 + 100x\n",
    "총 비용: 100x + 250x + 100,000 + 100x = 450x +100,000\n",
    "''')\n",
    "\n",
    "message=[]\n",
    "message.append(system_msg)\n",
    "message.append(user_msg)\n",
    "response = llm.invoke(message)\n",
    "print('\"\"\"안 표시는 사용자에게 출력하지 않고 힌트만 사용자에게 출력\"\"\"')\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 답변(숨김)\n",
      "=========\n",
      "태양광 발전 설비의 운영 첫해의 총 비용을 계산하기 위해서는 토지 비용, 태양광 패널 비용, 고정 유지보수 비용, 그리고 평방 피트당 추가 유지보수 비용을 모두 합산해야 합니다.\n",
      "\n",
      "먼저, 평방 피트를 \\( A \\)라고 가정하겠습니다.\n",
      "\n",
      "1. **토지 비용**:\n",
      "   토지 비용은 평방 피트당 $100입니다.\n",
      "   \\[\n",
      "   \\text{토지 비용} = 100 \\times A\n",
      "   \\]\n",
      "\n",
      "2. **태양광 패널 비용**:\n",
      "   태양광 패널은 평방 피트당 $250입니다.\n",
      "   \\[\n",
      "   \\text{태양광 패널 비용} = 250 \\times A\n",
      "   \\]\n",
      "\n",
      "3. **유지보수 비용**:\n",
      "   연간 고정 비용은 $100,000입니다.\n",
      "   평방 피트당 추가 비용은 $10입니다.\n",
      "   \\[\n",
      "   \\text{유지보수 비용} = 100,000 + (10 \\times A)\n",
      "   \\]\n",
      "\n",
      "이제 이 모든 비용을 합산하여 총 비용을 계산합니다.\n",
      "\\[\n",
      "\\text{총 비용} = (\\text{토지 비용}) + (\\text{태양광 패널 비용}) + (\\text{유지보수 비용})\n",
      "\\]\n",
      "\\[\n",
      "\\text{총 비용} = (100 \\times A) + (250 \\times A) + (100,000 + 10 \\times A)\n",
      "\\]\n",
      "\n",
      "위 식을 정리하면:\n",
      "\\[\n",
      "\\text{총 비용} = 100A + 250A + 100,000 + 10A\n",
      "\\]\n",
      "\\[\n",
      "\\text{총 비용} = 360A + 100,000\n",
      "\\]\n",
      "\n",
      "따라서, 평방 피트 수 \\( A \\)에 따른 운영 첫해의 총 비용은 \\( 360A + 100,000 \\) 달러입니다.\n",
      "학생답안과 비교 분석(숨김)\n",
      "=========\n",
      "학생의 답안을 검토해본 결과, 학생은 유지보수 비용을 잘못 계산했습니다. 유지보수 비용은 연간 고정 비용 $100,000와 평방 피트당 추가 비용 $10입니다. 학생은 평방 피트당 추가 비용을 $100로 잘못 계산했습니다.\n",
      "\n",
      "따라서, 학생의 답안 중 유지보수 비용을 올바르게 고치면 다음과 같습니다:\n",
      "\n",
      "1. 토지 비용: \\(100x\\)\n",
      "2. 태양광 패널 비용: \\(250x\\)\n",
      "3. 유지보수 비용: \\(100,000 + 10x\\)\n",
      "\n",
      "총 비용을 다시 계산하면:\n",
      "\\[\n",
      "100x + 250x + 100,000 + 10x = 360x + 100,000\n",
      "\\]\n",
      "\n",
      "따라서, 올바른 답은 \\(360x + 100,000\\)입니다.\n",
      "\n",
      "학생의 답안은 잘못된 유지보수 비용 계산으로 인해 최종 결과가 \\(450x + 100,000\\)이 되었으므로, 학생의 답안은 틀렸습니다.\n",
      "과외선생님 답변(최종사용자에게 보여지는 답변)\n",
      "=========\n",
      "좋아요, 계산 과정에서 대부분 잘 따라왔습니다. 다만 유지보수 비용을 계산하는 부분에서 약간의 실수가 있었네요. 유지보수 비용은 연간 고정 비용 $100,000와 평방 피트당 추가 비용 $10입니다. 이 부분을 다시 한 번 생각해보세요.\n",
      "\n",
      "힌트:\n",
      "- 유지보수 비용은 \\(100,000 + 10x\\)입니다. 여기서 평방 피트당 추가 비용이 $10라는 점을 기억하세요.\n",
      "- 따라서 총 비용은 \\(100x + 250x + 100,000 + 10x\\)로 계산해야 합니다.\n",
      "\n",
      "다시 한 번 시도해보세요!\n"
     ]
    }
   ],
   "source": [
    "user_msg = HumanMessage(content='''\n",
    "문제 설명: 태양광 발전 설비를 건설 중인데 재정 문제를 해결하는 데 도움이 필요합니다.\n",
    "- 토지 비용이 평방 피트당 $100입니다.\n",
    "- 태양광 패널을 평방피트당 $250에 구입할 수 있습니다.\n",
    "- 연간 10만 달러의 고정 비용과 평방피트당 10달러의 추가 비용이 드는 유지보수 계약을 체결했습니다.\n",
    "평방 피트 수에 따른 운영 첫해의 총 비용은 얼마인가요?\n",
    "''')\n",
    "your_solution = llm.invoke([user_msg])\n",
    "print(\"모델 답변(숨김)\")\n",
    "print(\"=========\")\n",
    "print(your_solution.content)\n",
    "student_solution = '''학생의 답안: x를 평방 피트 단위의 설치 크기라고 합니다.\n",
    "1. 토지 비용: 100x\n",
    "2. 태양광 패널 비용: 250x\n",
    "3. 유지보수 비용: 100,000 + 100x\n",
    "총 비용: 100x + 250x + 100,000 + 100x = 450x +100,000\n",
    "'''\n",
    "system_msg = SystemMessage(content='''\n",
    "당신의 답안과 학생이 제출한 답안을 비교하고 학생의 답안이 올바른지 여부를 평가합니다.\n",
    "''')\n",
    "user_msg2 = HumanMessage(content = user_msg.content+\"\\n\"+\"당신의 답안:\"+your_solution.content+\"\\n\"+student_solution)\n",
    "\n",
    "analysis = llm.invoke([system_msg,user_msg2])\n",
    "print(\"학생답안과 비교 분석(숨김)\")\n",
    "print(\"=========\")\n",
    "print(analysis.content)\n",
    "\n",
    "system_msg = SystemMessage(content='''\n",
    "당신은 수학 과외 선생님입니다. 학생이 오류를 범한 경우 답안을 바로 공개하지 않는 방식으로 학생에게 힌트를 제공합니다. 학생이 오류를 범하지 않았다면 격려의 댓글을 제공하세요.\n",
    "''')\n",
    "user_msg = HumanMessage(content= user_msg2.content + \"\\n\" + \"분석:\"+analysis.content )\n",
    "response = llm.invoke([system_msg,user_msg])\n",
    "\n",
    "print(\"과외선생님 답변(최종사용자에게 보여지는 답변)\")\n",
    "print(\"=========\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방안 3: 모델에게 이전 단계에서 놓친 것이 있는지 물어보기 \n",
    "\n",
    "특정 질문과 관련된 소스에서 발췌한 내용을 나열하는 데 모델을 사용한다고 가정해 보겠습니다. 각 발췌문을 나열한 후 모델은 다른 발췌문 작성을 시작할지 아니면 중단할지 결정해야 합니다. 소스 문서가 큰 경우 모델이 너무 일찍 중지하여 관련 발췌문을 모두 나열하지 못하는 경우가 종종 있습니다. 이 경우, 모델에 후속 질의를 통해 이전 단계에서 놓친 발췌문을 찾도록 유도하면 더 나은 성능을 얻을 수 있는 경우가 많습니다.\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|----|\n",
    "|SYSTEM|3중 큰따옴표로 구분된 문서가 제공되면 과제는 다음 질문과 관련된 발췌문을 추출합니다. \"인공지능의 역사에서 어떤 중요한 패러다임의 변화가 일어났는가?\" 발췌문에 해석에 필요한 모든 관련 맥락이 포함되어 있는지, 즉 중요한 맥락이 누락된 작은 조각을 추출하지 않았는지 확인합니다. [{\"발췌\": \"...\"}, ... {\"발췌\": \"...\"}]와 같이 JSON 형식으로 출력을 제공하세요.|\n",
    "|USER|\"\"\"인공지능(人工智能, 영어: artificial intelligence, AI)은 인간의 학습능력, 추론능력, 지각능력을 인공적으로 구현하려는 컴퓨터 과학의 세부분야 중 하나이다. 정보공학 분야에 있어 하나의 인프라 기술이기도 하다. 인간을 포함한 동물이 갖고 있는 지능 즉, 자연 지능(natural intelligence)과는 다른 개념이다. 인간의 지능을 모방한 기능을 갖춘 컴퓨터 시스템이며, 인간의 지능을 기계 등에 인공적으로 시연(구현)한 것이다. 일반적으로 범용 컴퓨터에 적용한다고 가정한다. 이 용어는 또한 그와 같은 지능을 만들 수 있는 방법론이나 실현 가능성 등을 연구하는 과학 기술 분야를 지칭하기도 한다. <br> 강인공지능과 약인공지능<br>초기 인공지능 연구에 대한 대표적인 정의는 다트머스 회의에서 존 매카시가 제안한 것으로 \"기계를 인간 행동의 지식에서와 같이 행동하게 만드는 것\"이다. 그러나 이 정의는 범용인공지능(AGI, 강한 인공지능)에 대한 고려를 하지 못한 것 같다. 인공지능의 또다른 정의는 인공적인 장치들이 가지는 지능이다. 거의 대부분 정의들이 인간처럼 사고하는 시스템, 인간처럼 행동하는 시스템, 이성적으로 사고하는 시스템 그리고 이성적으로 행동하는 시스템이라는 4개의 분류로 분류된다. 인공지능의 작동 방식이 의사 결정과 문제 해결, 학습에 있어 사람의 생각이나 행동과 유사할수록 강한 인공지능으로 분류되고, 논리에 의해 만들어지는 합리적인 생각이나 행동에 가까울수록 약한 인공지능으로 분류된다.<br>약인공지능<br> 약인공지능(weak AI)은 사진에서 물체를 찾거나 소리를 듣고 상황을 파악하는 것과 같이 기존에 인간은 쉽게 해결할 수 있으나 컴퓨터로 처리하기에는 어려웠던 각종 문제를 컴퓨터로 수행하게 만드는데 중점을 두고 있다. 한참 막연한 인간 지능을 목표로 하기보다는 더 현실적으로 실용적인 목표를 가지고 개발되고 있는 인공지능이라고 할 수 있으며, 일반적인 지능을 가진 무언가라기보다는 특정한 문제를 해결하는 도구로써 활용된다.<br>강인공지능 (AGI) <br> 강인공지능(strong AI) 또는 인공 일반 지능(arificial general intelligence, AGI)은 인간처럼 실제로 사고하여 문제를 해결할 수 있는 \"일반 지능\"을 인공적으로 구현하려는 시도이다. 오늘날 이 분야의 연구는 주로 미리 정의된 규칙의 모음을 이용해서 지능을 흉내내는 컴퓨터 프로그램을 개발하는 것에 맞추어져 있다. 강한 인공지능 분야의 발전은 여전히 미약하지만, 인간과 같은 지능이라는 목표를 어떻게 정의하는지에 따라 어느 정도 발전이 이루어지고 있다고도 볼 수 있다.<br> 강인공지능의 실현 가능성에 관한 논쟁<br> 존 설이나 휴버트 드라이퍼스와 같은 몇몇 철학자들은 몸이 아닌 기계에 인간의 지능이나 의식을 구현하는 작업의 실현 가능성에 대한 철학적 바탕을 두고 논쟁을 벌였다. 설은, 튜링 테스트의 통과 여부는 사람의 기준으로 볼 때 기계가 의식을 갖추었다는 판단의 필요 조건이 되지 못한다는 중국어 방에 대한 논증으로 유명하다. 드라이퍼스는 그의 저서 \"컴퓨터가 할 수 없는 것들: 인공적인 추론에 대한 비평\"에서 의식이라는 것은 룰이나 논리 기반 시스템 또는 물리적인 형태를 가지고 있지 않은 시스템에서 찾을 수 없으나, 신경망(neural network)이나 그 유사한 메커니즘을 이용하는 로보틱 시스템은 인공지능을 실현할 수 있는 가능성이 있다고 주장했다.<br> 다른 철학자들은 엇갈린 관점을 고수한다. 많은 사람들이 약한 인공지능 정도는 가능하다고 보지만, 또한 많은 사람들이 강한 인공지능을 지지하고 있는 것도 사실이다. 대니얼 C. 데넷은 그의 '의식에 대한 설명'에서 만일 마법의 불꽃이나 영혼이 없다면 인간은 기계에 불과하다며, 지능에 대해서만 인간이라는 기계가 다른 실현 가능한 모든 기계와 다르게 특별 취급을 받아야할 이유가 무엇인가 묻고 있다. 어떤 철학자들은 우리가 약한 인공지능을 가능한 것으로 받아들인다면, 강한 인공지능 역시 받아들여야 한다고 주장한다. 지능은 외견상 보이는 것을 가리키는 것이지 진정한 실체가 아니라는 약한 인공지능의 입장은 많은 비판을 받고 있다. 그러나 이에 반하는 손쉬운 예를 사이먼 블랙번의 철학 입문서 \"생각\"에서 찾을 수 있다. 블랙번은 당신이 지능적으로 보이지만, 그 지능이 실존하는가에 대해서 말할 수 있는 방법이 없다고 지적한다. 그는 우리는 단지 믿음 또는 신념 위에서 그것을 다룰 뿐이라고 이야기한다.<br>강한 인공지능을 지지하는 사람들은 인공지능에 반대하는 사람들의 논증이 결국은 아래와 같은 주장을 조합한 것이라고 주장한다.<br> 1. 특권에 바탕을 둔 오만함으로 인해 인간에게는 (기계에는 없는) 마법의 불꽃이 있다는 주장 (예를 들면, 신에 의해 주어진 영혼)<br>2. 지능은 기계로는 성취될 수 없는 그 무엇이라는 주장.<br>강한 인공지능을 뒷받침하는 논증(따라서 반대하는 사람은 이 논증을 논박해야 한다.)은 다음과 같다.<br> 1. 인간의 마음은 유한 상태 기계(Finite State Machine)이고, 따라서 처치-튜링 이론은 뇌에 적용 가능하다.<br>2. 뇌는 순수한 하드웨어이다.(말하자면 고전적인 컴퓨터처럼 동작한다.)<br>3. 인간의 마음은 오로지 뇌를 통해서만 존재한다.<br> 로저 펜로즈를 포함한 몇몇 학자들은 지능에 처치-튜링 명제의 적용이 가능하지 않다고 논박한다. 특히 펜로즈는 인간의 마음에는 물리적인 속성을 뛰어넘는 무언가가 있다고 이야기하며, 그의 주장은 우리의 우주 안에서 초연산(hypercomputation)이 가능하다는 논증에 바탕을 두고 있다. 양자역학과 뉴턴 역학에 따르면 이러한 초연산은 가능하지 않지만, 특별한 시공간에서는 가능한 것으로 생각되기도 한다. 그러나 이는 소수의 주장이며, 우리의 우주는 그러한 초연산이 가능할 정도로 꼬이지(convoluted) 않았다는 많은 학자들의 합의가 존재한다.<br><br> 역사<br> 인공지능 이론의 발전<br>상당수 인공지능 연구의 (본래) 목적은 심리학에 대한 실험적인 접근이었고, 언어 지능(linguistic intelligence)이 무엇인지를 밝혀내는 것이 주목표였다(튜링 테스트가 대표적인 예이다).<br> 언어 지능을 제외한 인공지능에 대한 시도들은 로보틱스와 집합적 지식을 포함한다. 이들은 환경에 대한 처리, 의사 결정을 일치시키는 것에 중심을 두며 어떻게 지능적 행동이 구성되는 것인가를 찾을 때, 생물학과, 정치과학으로부터 이끌어 낸다. 사회적 계획성과 인지성의 능력은 떨어지지만 인간과 유사한 유인원을 포함한, 복잡한 인식방법을 가진 동물뿐만 아니라 특히 곤충들(로봇들로 모방하기 쉬운)까지 포함한 동물학으로부터 인공지능 과학은 시작된다. 여러 가지 생명체들의 모든 논리구조를 가져온 다는 것은 이론적으로는 가능하지만 수치화, 기계화 한다는 것은 쉬운 일이 아니다.<br>인공지능 학자는 동물들은 인간들보다 모방하기 쉽다고 주장한다. 그러나 동물의 지능을 만족하는 계산 모델은 없다. 매컬러가 쓴 신경 행동에서 내재적 사고의 논리적 계산, 튜링의 기계와 지능의 계산 그리고 리클라이더의 인간과 컴퓨터의 공생가 기계 지능의 개념에 관한 독창적인 논문들이다.<br>존 루커스의 지성, 기계, 괴델과 같은 논리학과 철학기반의 기계지능의 가능성을 부인한 초기 논문들도 있다.<br>인공지능 연구에 바탕을 둔 실질적인 작업이 결실을 거둠에 따라, 인공지능을 지지하는 사람들은 인공지능의 업적을 깎아내리기 위해 인공지능에 반대하는 사람들이 예전에는 '지능적'인 일이라고 주장하던 컴퓨터 체스나 바둑, 음성인식 등과 같은 작업에 대해 말을 바꾸고 있다고 비난하였다. 그들은 이와 같이 연구 목표를 옮기는 작업은 '지능'을 '인간은 할 수 있지만, 기계는 할 수 없는 어떤 것'으로 정의하는 역할을 한다고 지적하였다.<br>(E.T. Jaynes에 따르면) 존 폰 노이만은 이미 이를 예측하였는데, 1948년에 기계가 생각하는 것은 불가능하다는 강의를 듣고 다음과 같이 말하였다. \"당신은 기계가 할 수 없는 어떤 것이 있다고 주장한다. 만일 당신이 그 기계가 할 수 없는 것이 무엇인지를 정확하게 이야기해준다면, 나는 언제든지 그 일을 수행할 수 있는 기계를 만들 수 있다.\" 했다. 폰 노이만은 이미 그 전에 모든 처리절차(procedure)는 (범용)컴퓨터에 의해서 시뮬레이션 될 수 있다고 이야기함에 따라 쳐치-튜링 이론을 언급했다.<br>1969년에 매카시와 헤이스는 그들의 논문 \"인공지능 관점에서 바라본 철학적인 문제들\"에서 프레임 문제를 언급하였다.<br><br>인공지능의 탄생(1943-1956)<br>1940년대 후반과 1950년대 초반에 이르러서 수학, 철학, 공학, 경제 등 다양한 영역의 과학자들에게서 인공적인 두뇌의 가능성이 논의되었다. 1956년에 이르러서, 인공지능이 학문 분야로 들어섰다.<br><br>인공두뇌학과 초기 신경 네트워크<br> 생각하는 기계에 대한 초기 연구는 30년대 후기에서부터 50년대 초기의 유행한 아이디어에 영감을 얻은 것이었다. 당시 신경학의 최신 연구는 실제 뇌가 뉴런으로 이루어진 전기적인 네트워크라고 보았다. 위너가 인공두뇌학을 전기적 네트워크의 제어와 안정화로 묘사했으며, 섀넌의 정보 과학은 디지털 신호로 묘사했다. 또 튜링의 계산 이론은 어떤 형태의 계산도 디지털로 나타낼 수 있음을 보였다. 이런 여러 밀접한 연관에서, 인공두뇌의 전자적 구축에 대한 아이디어가 나온 것이다. 월터의 거북이 로봇이 이 아이디어를 중요하게 포함한 연구의 예이다. 이 기계는 컴퓨터를 사용하지 않고 아날로그 회로를 이용했지만, 디지털의 전자적, 상징적 추리를 보여주기엔 충분했다. 월터 피츠(Walter Pitts)와 워런 매컬러(Warren Sturgis McCulloch)는 인공 신경망에 기인한 네트워크를 분석하고 그들이 어떻게 간단한 논리적 기능을 하는지 보여주었다. 그들은 후에 신경 네트워크라 부르는 기술을 첫번째로 연구한 사람이다. 피츠와 매컬러는 24살의 대학원생인 젊은 마빈 민스키를 만났고, 민스키는 1951년 첫번째 신경 네트워크 기계인 SNARC를 구축했다. 민스키는 향후 50년동안 인공지능의 가장 중요한 지도적, 혁신적 인물 중 하나가 되었다.<br><br>튜링 테스트<br>1950년 앨런 튜링은 생각하는 기계의 구현 가능성에 대한 분석이 담긴, 인공지능 역사에서 혁혁한 논문을 발표했다. 그는 \"생각\"을 정의하기 어려움에 주목해, 그 유명한 튜링테스트를 고안했다. 텔레프린터를 통한 대화에서 기계가 사람인지 기계인지 구별할 수 없을 정도로 대화를 잘 이끌어 간다면, 이것은 기계가 \"생각\"하고 있다고 말할 충분한 근거가 된다는 것이었다. 튜링 테스트는 인공 지능에 대한 최초의 심도 깊은 철학적 제안으로 평가받는다.<br><br>게임 인공지능<br>1951년에, 맨체스터 대학의 페란티 마크 1(Ferranti Mark 1) 기계를 사용하여 크리스토퍼 스트레이(Christopher Strachey)는 체커 프로그램을 작성했고, 디트리히 프린츠(Dietrich Prinz)는 체스 프로그램을 작성했다. 아서 새뮤얼(Arthur Samuel)이 50년대 중반과 60년대 초반에 개발한 체커 프로그램은 결국 존경받는 아마추어에 도전할 수 있는 충분한 기술적 발전을 이룩했다.<br><br>상징 추론과 논리 이론<br>디지털 컴퓨터에 접할 수 있어진 50년대 중반에 이르러서, 몇몇 과학자들은 직관적으로 기계가 수를 다루듯 기호를 다루고, 사람처럼 기호의 본질적인 부분'까지 다룰 수 있을 것이라고 생각했다. 이것은 생각하는 기계를 만드는 새로운 접근 방법이었다. 1956년에, 앨런 뉴얼(Allen Newell)과 허버트 사이먼(Herbert A. Simon)은 \"논리 이론\"을 구현했다. 그 프로그램은 결국 러셀과 화이트헤드의 '수학 원리'에 나오는 52개의 정리중 32개를 증명해냈고, 일부 새롭고 더 우아한 증거를 찾아내기도 했다.<br><br>다트머스 컨퍼런스 1956년: AI의 탄생<br>1956년에 열린 다트머스 컨퍼런스는 마빈 민스키와 존 매카시, 그리고 IBM의 수석 과학자인 클로드 섀넌과 네이선 로체스터가 개최했다. 컨퍼런스는 \"학습의 모든 면 또는 지능의 다른 모든 특성로 기계를 정밀하게 기술할 수 있고 이를 시물레이션 할 수 있다\"라는 주장을 포함하여 제안을 제기했다. 참가자는 레이 솔로모노프(Ray Solomonoff), 올리버 셀프리지(Oliver Selfridge), 트렌처드 모어(Trenchard More), 아서 새뮤얼(Arthur Smuel), 앨런 뉴얼(Allen Newell)과 허버트 사이먼(Herbert A. Simon)으로, 그들 모두 수십년동안 인공지능 연구에서 중요한 프로그램을 만들어온 사람들이었다. 컨퍼런스에서 뉴얼과 사이먼은 \"논리 이론\"을 소개했고, 매카시는 Artificial Intelligence를 그들의 연구를 칭하는 이름으로 받아들이길 설득했다. 1956년 다트머스 컨퍼런스는 AI 라는 이름, 목표점, 첫번째 성공과 이를 이룬 사람들, 그리고 넓은 의미의 AI의 탄생을 포함하는 순간이었다.<br><br>황금기(1956~1974년)<br>다트머스 컨퍼런스 이후에, AI라는 새로운 영역은 발전의 땅을 질주하기 시작했다. 이 기간에 만들어진 프로그램은 많은 사람들을 \"놀랍게(astonishing)\"만들었는데, 프로그램은 대수학 문제를 풀었고 기하학의 정리를 증명했으며 영어를 학습했다. 몇 사람들은 이와같은 기계의 \"지능적\" 행동을 보고 AI로 모든 것이 가능할 것이라 믿었다. 연구가들은 개인의 의견 또는 출판물들을 통해 낙관론을 펼쳤고, 완전한 지능을 갖춘 기계가 20년 안에 탄생할 것이라고 예측했다. ARPA(Advanced Research Projects Agency)같은 정부 기관은 이 새로운 분야에 돈을 쏟아부었다.<br><br>작업들<br>많은 성공적인 프로그램과 새로운 발전 방향이 50년대 후반과 60년대에 나타났다. 이곳에는 AI 역사에 지대한 영향을 미친 것들을 기술했다.<br>탐색 추리<br>초기 AI 프로그램은 동일한 기본적인 알고리즘을 사용했다. 게임의 승리나 정리 증명 같은 어떤 목표 달성을 위해, 그들은 한발짝식 나아가는(step-by-step) 방식을 상용했다. 예를 들어 미로를 찾아갈때 계속 나아가면서 막힌 길이 있으면 다른 길이 있는 곳까지 되돌아 왔다가 다른 길로 가는 식이었다. 이런 패러다임은 \"탐색 추리\"라 불렸다. 주요한 문제는, 간단한 미로에 있어서도 경로로 사용할 수 있는 수가 천문학적으로 많았다는 것이다. 연구가들은 추론 또는 경험적으로 찾은 규칙으로 정답이 아닌듯 보이는 경로를 지우는 방식을 사용했다.뉴엘과 사이먼은 \"범용 문제 해결기(General Problem Solver)\"라 부르는 프로그램 속 알고리즘의 범용적인 버전을 포착하려고 노력했다. 다른 \"검색\" 프로그램은 기하학과 대수학의 문제를 해결하는 것처럼 인상적인 작업 - 허버트 게랜터(Herbert Gelenter)의 \"기하학 해결기\"나 민스키의 제자인 제임스 슬레이글(James Slage)의 SAINT - 을 수행하길 시도했다. 다른 프로그램은 목표와 목표에 다가가기 위한 세부 계획을 검색했고, 여기에는 스탠포드에서 샤키(Shakey) 로봇의 동작을 제어하기 위해 개발한 STRIPS 시스템을 포함한다.<br><br>자연어 처리<br>AI 연구의 중요한 목표는 영어와 같은 자연어로 컴퓨터와 의사소통할 수 있게 하는 것이었다. 일찍이 다니엘 보로우(Daniel Bobrow)의 STUDENT라는 프로그램은 고등학교 수준의 대수학 단어 문제를 푸는 성공을 보였다. '의미 망'은 개념을 다른 개념들 사이의 노드와 링크 관계로 나타낸다. 의미 망을 사용하는 첫 번째 AI 프로그램은 로스 퀄리언(Ross Quillian)이 작성했고 가장 성공이며 동시에 논쟁이 많았던 버전은 로거 섕크(Roger Schank)의 \"개념 종속 이론(Conceptual dependency theory)\"이다. 조셉 웨이젠바움(Joseph Weizenbaum)의 ELIZA는 사람들이 그들이 대화를 나누는 때때로 상대가 컴퓨터가 아니라 사람이라고 생각할 정도의 질로 대화했다. 사실, ELIZA는 스스로 생각하여 말하지 않았다. 그 프로그램은 오직 판에 박힌 말을 하거나, 상대에게 방금 말한 말을 다시 해 달라고 요청하거나, 상대가 한 말을 몇 개의 문법 법칙에 의해 파싱 할 뿐이었다. ELIZA는 첫 번째 채팅 프로그램이 되었다.<br><br>마이크로월드<br>1960년대 후반에, MIT의 AI 연구소에 있던 마빈 민스키와 시모어 페퍼트는 마이크로월드 연구로 불리는, 인위적인 간단한 상황에 초점을 맞춘 AI 연구를 제안했다. 그들은 성공적인 과학자들이 자주 쉬운 이해를 위해 '마찰면'이라든지 '강체(물리학에서 결코 형태가 변하지 않는 물체)'같은 간단한 모델을 사용한다는 것에 집중했다. 이런 연구의 대부분이 평평한 평면 위의 다양한 형태와 색깔의 블록으로 이루어진 '블록 단위의 세계'에 초점을 맞추는 형식이었다.<br>제럴드 서스먼(Gerald Sussman)을 필두로 아돌포 구스만(Adolfo Guzman), 데이비드 월츠(David Waltz) 그리고 패트릭 윈스턴(Patrick Winston)이 마이크로월드 패러다임으로 기계 비전의 혁신을 이끌었다. 같은 시간에, 민스키와 페퍼는 블록을 쌓을 수 있는 로봇 팔을 제작했다. 마이크로월드의 영광스러운 성취는 테리 위노가드(Terry Winograd)의 SHRDLU이며, 이것은 보통의 일반 문장으로 소통해 작업을 계획하고 이를 실행할 수 있었다.<br><br>낙관론<br>AI 연구의 첫 번째 세대는 그들의 연구 결과에 대해 다음과 같이 예측했다.<br>- 1958년, 사이먼(H. A. Simon)과 뉴얼(Allen Newell) : \"10년 내에 디지털 컴퓨터가 체스 세계 챔피언을 이길 것이다\", 덧붙여 \"10년 내에 디지털 컴퓨터는 중요한 새로운 수학적 정리를 발견하고 증명할 것이다\"라고 말했다.<br>- 1965년, 사이먼 : \"20년 내에 기계가 사람이 할 수 있는 모든 일을 할 것이다.\"<br>- 1967년, 마빈 민스키 : \"이번 세기에 AI를 만드는 문제는 거의 해결 될 것이다.\"<br>- 1970년, 마빈 민스키 : (Life 잡지를 통해서) \"3~8년안에 우리는 평균정도의 인간 지능을 가지는 기계를 가지게 될 것입니다.\"<br><br>자금<br>1963년 6월, MIT는 220만 달러를 고등 연구 계획국(Advanced Research Projects Agency - 후에 DARPA로 알려짐)에게 제공받았다. 자금은 민스키와 매카시가 5년전 설립한 \"AI 그룹\"이 포섭한 프로젝트 MAC에서 사용되었다. DARPA는 계속해서 매년 300만 달러를 70년대까지 제공했다. DARPA는 또한 유사한 자금을 뉴얼과 사이먼의 CMU 프로그램과 스탠포드 AI 프로젝트에 제공했다. 또다른 중요한 AI 연구소는 1965년 도널드 미치(Donald Michie)가 에든버러 대학교에 세웠다. 이 4개의 시설은 계속해서 많은 연도에 걸쳐 학계의 주요한 AI연구소, 그리고 자금처로 존재할 것이다. 자금은 몇가지 단서와 함께 제공됐다 : ARPA의 기획자 리클리더(J. C. R. Licklider)는 그의 조직은 \"프로젝트가 아니라, 사람에게 투자\"해야 한다고 믿었고, 연구자들이 어떤 방향이든 그들의 관심있는 쪽을 연구하도록 허용했다. 이것은 MIT에 자유분방한 분위기를 생성했고 해킹 문화를 탄생시키기도 했다. 그러나 이렇게 손을 떼고 지켜보는 형식의 지원은 얼마 지속되지 못했다.<br><br>AI의 첫번째 암흑기(1974-1980)<br>70년대에 이르자, AI는 비판의 대상이 되었고 재정적 위기가 닥쳤다. AI 연구가들은 그들의 눈앞에 있는 복잡한 문제를 해결하는데 실패했다. 연구가들의 엄청난 낙관론은 연구에 대한 기대를 매우 높여놓았고, 그들이 약속했던 결과를 보여주지 못하자, AI에 대한 자금 투자는 사라져버렸다. 동시에, Connectionism 또는 뉴럴망은 지난 10년동안 마빈 민스키의 퍼셉트론(시각과 뇌의 기능을 모델화한 학습 기계)에 대한 파괴적인 비판에 의해 완전히 중지되었다. 그러나 70년대 후반의 AI에 대한 좋지 않은 대중의 인식에도 불구하고, 논리 프로그래밍, 상징 추론과 많은 여러 영역에서의 새로운 아이디어가 나타났다.<br>문제<br>1970년대 초, AI 프로그램의 가능성은 제한적이었다. 모든 문제에 걸쳐서 문제를 푸는 인상 깊은 작품들은 겨우 시험용 버전 정도였고, 어떤 의미에선 '장난감'에 가까웠다. AI 연구는 70년대에 더 이상 극복할 수 없는 몇개의 근본적인 한계를 가지게 됐다.몇개의 한계를 통해 십여년 후에 극복되었고, 다른 몇 개는 오늘날까지 남아있다.<br>- 컴퓨터 능력의 한계 : 정말 유용한 무언가를 이루기에는 메모리 또는 처리 속도가 충분하지 않았다. 예를 들어 로스 퀼리언(Ross Quillian)의 자연어 처리에서 성공적인 완수는 오직 20개의 단어 위에서 발휘되었는데, 이것은 메모리가 꽉 찼기 때문이었다. ++한스 모라벡은 1976년에 컴퓨터가 지능을 가지기엔 여전히 수백만 배 약하다고 논증했다. 그는 비유를 들었는데, AI가 컴퓨터 능력을 필요로 하는 것은 항공기가 마력을 필요로 하는 것과 같다는 것이었다. 컴퓨터 영상에 대해서, 모라벡은 간단하게 계산하여 실시간으로 사람의 망막을 모션 캡처하려면 범용 컴퓨터가 초당 10^9 명령어(1000MIPS)를 처리해야 할 것이라고 추측했다. 2011년경 실용적인 컴퓨터 영상 프로그램은 10,000~1,000,000 MIPS를 요구한다. 1976년경 5백만에서 8백만 달러사이에 판매되던 가장 빠른 슈퍼컴퓨터인 Cray-1은 오직 80~130 MIPS였고, 당시 전형적인 데스크탑 컴퓨터는 겨우 1 MIPS 남짓이었다. 폭발적인 조합 수와 비용이성 : 1972년에 리차트 카프(Hichard Karp)는 문제 해결에 지수적 시간이 요구되는 많은 문제를 보여주었다. 하찮은 문제일지라도 이런 문제의 최적의 해답을 찾는 데 상상할 수도 없는 컴퓨터의 시간이 요구되었다. 즉 지금까지 AI '장난감'에서 사용되었던 방법은 실제적으로 유용한 AI 시스템을 제작하는 데 용이하지 못했다.<br>- 상징적 지식과 추론 : 영상 처리나 자연어 처리 같은 많은 중요한 AI 프로그램은 실제 세상에 대한 간단하지만 어마어마한 양의 정보를 필요로 한다. 그래야 프로그램이 자신이 보고 있는 것이 무엇인지, 또는 자신이 듣고 있는 것이 무엇인지 아이디어를 찾을 수 있기 때문이다. 이 요구는 아기들의 세상에 대해 알아나가는 것과 유사하다. 연구가들은 곧 요구되는 정보의 양이 엄청나게 광대하다는 것을 발견했다. 1970년대의 누구도 이런 데이터가 포함된 데이터베이스를 만들지 못했고, 누구도 이런 데이터를 프로그램 혼자 터득하는 방법을 알지 못했다.<br>- 모라벡의 패러독스 : 이론을 제작하고 기하학적 문제를 해결하는 것은 컴퓨터에게 비교적 쉽지만, 얼굴을 인식하거나 장애물을 피해 방을 가로지르는 것은 엄청나게 어렵다. 이 설명은 왜 연구가들이 1970년대에 영상처리나 로봇에 대해 조금밖에 진전을 보이지 못했는지 아는 데 도움이 된다.<br>- 프레임 문제, 자격 문제 : 존 맥캐시와 같은 연구가들은 규칙이 규칙 스스로의 구조를 변경하지 못하면 관련 계획 또는 기본 추론 일반 공제를 나타낼 수 없다는 것을 발견했다.<br><br>자금 지원의 중단<br>영국 정보나 DARPA, NRC같은 AI 연구자들에게 자금을 주던 기관들은 연구 진행의 부진에 실망했고 결국 AI에 관한 방향성을 가진 자금 지원을 끊었다. 1966년 기계를 이용한 번역을 비판하는 보고서가 ALPAC에 제출되었을 때부터 이런 흐름이 시작되었다. 총 2천만 달러를 지원한 NRC도 지원을 멈췄다. 1973년 라이트힐 보고서는 \"장대한 목표(grandios objectives)\"를 성취하는 데 실패한 영국의 AI 연구의 상태에 대해 비난했고 결국 영국의 AI 연구소는 해체되었다(보고서는 특히 AI 연구의 실패의 원인이 폭발적인 조합의 수라고 언급했다). DARPA는 CMU의 음성을 이해하는 연구의 연구자들에게 심하게 실망했고 연간 3백만 달러의 지원을 취소했다. 1974년에 이르자 AI 연구에대한 투자는 찾기 어려워졌다. 한스 모라벡은 그의 동료의 비현실적인 예측에 의한 위기를 비난했다. \"많은 연구가들이 많은 연구자는 과장을 증가시키는 웹에 휘말렸다.\" 그러나 여기엔 다른 이슈가 있다 : 1969년 맨스필드의 수정안의 통과이후, DARPA는 자금 지원에 대해 \"비직접적인 기초 연구보다, 임무 완수에 직결된 연구\"를 수행하라는 증가하는 압력을 받고 있었다. 창조성 높은 지원, 자유분방한 연구는 1960년대와 함께 떠났고 DARPA에서 다시 오지 않을 것이다. 대신, 자금은 자동조정 탱크나 전투 관리 시스템과 같은 분명한 프로젝트와 명확한 목표를 향할 것이다.<br><br>캠퍼스 전역의 비판들<br>몇 철학자들은 AI 연구가들에게 강력한 반대를 표했다. 초기 반대자들 중 괴델의 불완전성의 원리에 의해 컴퓨터 프로그램같은 시스템이 실제적으로 정확하게 사람과 같이 행할 수 없다고 주장한 사람은 존 루커스(John Lucas)이다. 휴버트 드라이퍼스는 60년대의 깨어진 약속을 조롱했고 AI의 가정을 비판했으며, 인간의 추론이 실제적으론 \"상징적 진행\"이 매우 적게 포함되어 있고 구현적, 본능적, 무의식적인 노하우에 의해 처리된다고 주장했다. 존 설의 1980년대 제시된 중국인 방 문제는, 실제로 프로그램이 상징들을 '이해'할 수 없고 사용할 수 없음을 보여주려고 시도했다. 설은 만약 상징이 기계에게 아무 의미가 못된다면, 기계는 생각하는 것이 아니라고 주장했다. 이 비난은 AI 연구가들에게 심각하게 작용하지 못했다. 비용이성과 상식적 지식에 관한 문제가 훨씬 더 즉각적이고 심각한 듯이 보였다. '노하우'와 '지향성'이 실제 프로그램을 만드는데 어떻게 다른지가 불분명했다. 민스키는 드라이퍼스와 설을 향해 \"그들은 오해했고, 무시될 것이다\"라고 했다. MIT에서 가르쳤던 드라이퍼스는 냉대받았다 : 그는 나중에 AI 연구가들에게 \"나와 점심 식사할 용기도 없다\"라고 평했다. ELIZA의 제작자 조셉 웨이즌바움(Joseph Weizenbaum)은 그의 동료인 드라이퍼스가 전문적이지 않고 유치한 대우를 한다고 느꼈다. 웨이즌바움은 케네스 콜비(Kenneth Colby)가 쓴 DOCTOR와 임상치료 채팅봇에 대해서 심각하게 의심하기 시작했다. 웨이즌바움은 콜비가 그의 무심한 프로그램을 진지한 치료 도구로 여기는 걸 방해했다. 이 불화가 시작되고, 이 상황은 콜비가 웨이즌바움을 프로그램에 대한 공로로 인정하지 않았을 때 도움이 되지 않았다. 1976년에 웨이즌바움은 컴퓨터 능력과 인간 추론(Computer Power and Human Reason)을 출판하며 인공 지능의 오용이 인간의 삶을 평가 절하시킬 수도 있다고 주장했다.<br><br>퍼셉트론과 연결망의 어두운 시대<br>뉴럴 네트워크 형태의 퍼셉트론이 1958년 마빈 민스키의 고등학교 시절 친구였던 프랭크 로센블랫(Frank Rosenblatt)에 의해 도입되었다. 다른 AI 연구가들이 그러하듯, 그는 낙관론을 펼쳤고, \"퍼셉트론은 결국 학습을 하고, 의사 결정을 하고, 언어 번역을 할 것이다\"라고 예견했다. 60년대를 이끌던 패러다임 속의 연구 프로그램의 수행은 1969년 민스키와 페퍼의 책 퍼셉트론의 출판과 함께 갑자기 중지되었다. 이것은 퍼셉트론이할 수 있는 일에 몇가지 심각한 제한이 있음을, 또 프랭크의 예견은 심하게 과장되어있음을 알렸다. 이 책의 파급력은 압도적이었다 : 향후 10년 동안 뉴럴 네트워크에 대한 거의 모든 연구가 중지되었다. 결국, 뉴럴 네트워크 영역을 회복할 연구원의 새로운 세대가 그 후에 인공지능의 중요하고 유용한 부분을 내놓았다. 로센블랫은 이 책을 보지 못했는데, 그는 문제의 책이 출판 되고 곧바로 보트 사고와 함께 사망했기 때문이다.<br><br>깔끔이 : 논리, 프롤로그와 전문가 시스템<br>논리적 추론은 1958년 초에 AI 연구에서 존 매카시가 제안하여 도입되었다. 1963년 알렌 로빈슨(J. Alan Robinson)은 간단하게 추론을 컴퓨터에 구현시키는 분해와 통일 알고리즘을 발견했다. 그러나 매카시와 그의 학생들이 60년대 후반에 했던 것과 같은 복잡하지 않은 구현은 본질적으로 다루기 힘들었는데, 간단한 정리를 증명하기 위해 천문학적 단계가 필요했다. 더 성공적인 결실을 맺는 논리적 접근은 70년대 에딘벌 대학의 로버트 코왈스키(Robert Kowalski)가 개발했고 곧 프랑스의 연구가인 알라인 콜메루엘(Alain Colmerauer)과 성공적인 논리 프로그래밍 언어인 프롤로그를 만든 필립 오우셀(Philippe Roussel)과의 협업을 이끌어냈다. 프롤로그는 다루기 쉬운 계산을 허용하는 논리의 부분을 사용한다. 규칙은 계속적으로 영향을 미쳤고, 에드워트 페이젠바움(Edward Feigenbaum)이 기대하던 시스템 기초를 제공했으며 알렌 뉴엘과 허버트가 계속 연구하도록 만들었다. 사이먼은 Soar과 인식에서의 통일 이론을 이끌었다. 논리적으로의 접근을 비판하는 지적은, 드라이퍼스가 했던데로, 사람이 문제를 해결할 때 논리를 거의 사용하지 않는다는 것이었다. 피터 왓슨(Peter Waon), 엘리너 로시, 아모스 트버스키, 대니얼 카너먼을 비롯한 심리학자들이 이를 증명했다. 매카시는 이에 대해서 이 증명이 무관하다고 답했다. 그는 정말 필요한 기계란 사람처럼 생각하는 것이 아니라 문제를 해결할 줄 아는 기계라고 일축했다.<br><br>지저분이 : 프레임과 스크립트<br>매카시의 접근에 대한 비평가들의 대다수가 그의 동료인 MIT 소속이었다. 마빈 민스키와 사무엘 페퍼와 로저 샹크는 기계를 사람처럼 느껴지도록 만드는 \"이야기 이해\"와 \"물체 인식\"의 문제를 해결하려고 노력했다. \"의자\"나 \"음식점\" 같은 일반적인 개념을 사용할 때 사람들은 모두 비논리적으로, 사람들이 통용하는 범용적 가정을 함께 했다. 불행하게도 이런 부정확한 가정들은 논리적 절차로 대표하기가 힘들었다. 제럴드 서스먼(Gerald Sussman)은 \"본질적으로 부정확한 개념을 설명하기위 해 정확한 언어를 사용하는 순간 그들은 더 이상 부정확하다고 말할 수 없다\"라고 표했다. 또한 섕크는 이에 대해 \"비논리적\" 접근 즉 \"지저분이\"가 매카시, 코와스키, 페이젠바움의 \"깔끔이\" 패러다임과 반대에 있다고 평했다.<br>1975년 세미나 보고서에서, 민스키는 \"지저분한\" 많은 그의 동료 연구자들이 무언가에 대한 우리의 모든 상식적 가정을 포착하는 프레임워크를 도구로 사용했다고 적었다. 예를 들어 우리가 새라는 개념을 생각할때, 즉시 '난다', '벌레를 먹는다'와 같은 다양한 사실들 또한 떠올린다. 떠올린 것들이 항상 사실은 아니고 또 \"논리적\"으로 이것들이 공제가 되지는 않는다. 그러나 이런 가정들의 구조는 우리가 말하고 생각하는 문장의 부분을 차지한다. 그는 이 구조를 \"프레임\"이라 칭했다. 섕크는 프레임의 설명에 대해서 영어로된 짧은 스토리에 대한 답변을 성공적으로 하기 위한 \"스크립트\"라 불렀다. 수년 후 객체지향 프로그래밍에서 AI 연구에서 쓰였던 프레임에서 나온 '상속'이라는 개념을 채택하게 된다.<br><br>AI붐 (1980-1987)<br>1980년대에는 전 세계적으로 사용된 ‘전문가 시스템’이라고 일컫는 인공지능 프로그램의 형태였고 인공지능 검색에 초점이 맞춰졌다. 같은 시기에 일본 정부는 자신들의 5세대 컴퓨터 프로젝트와 인공지능에 적극적으로 투자하였다. 1980년대에 존 홉필드와 데이비드 루멜하트의 신경망 이론의 복원이라는 또 다른 사건이 있었다.<br>전문가 시스템의 발전<br>전문가 시스템은 특정 지식의 범위에 대해 문제를 해결해주거나 질문에 대답해주는 프로그램이며 전문가의 지식에서 파생 된 논리적 법칙을 사용하였다. 최초의 실험은 1965년 Edward Feigenbaum과 레더버그에 의해 Dendral이 시작하였고 이것은 분광계로부터 화합물을 식별하는 실험이었다. MYCIN은 1972년에 개발되었고 전염되는 혈액 질환을 진단하였다. 이러한 접근법(실험)은 타당성이 입증되었다.<br>전문가 시스템은 소규모의 지식 영역에 대해서는 스스로 제한을 둠으로써 상식 문제를 피하였다. 그리고 그들의 단순한 디자인은 프로그램을 만드는 것을 상대적으로 쉽게 하였다. 모든 프로그램은 유용성이 입증되어야 하지만 AI는 이 점을 달성할 수 없었다.<br>1980년, XCON이라 불리는 전문가 시스템은 디지털 장비 회사인 CMU에서 완성되었다. 이 시스템은 매년 4천만 달러를 절약시켜주며 매우 큰 성과를 나타냈다. 전 세계의 회사들은 1985년에 1억 달러 이상을 AI에 사용하여 이를 개발하고 전문가 시스템을 배포하였다. Symbolics, Lisp Machines과 같은 하드웨어 회사와 IntelliCorp, Aion 등의 소프트웨어 회사들이 이를 지원하면서 같이 성장하였다.<br>지식 혁명<br>전문가 지식들을 포함하면서 전문가 시스템의 힘은 두각을 나타내었다. 이것은 1970년대 내내 연구하였던 AI 연구 기법의 새로운 방향 중 일부분이었다. “AI 과학자들은 지능이란 것이 다른 방법들로 많은 양의 다양한 지식들을 사용하는 능력에 기반한 것이라고 의심하기 시작했다.” 지식 기반 시스템과 지식 엔지니어링은 1980년대 AI 연구자들의 메인 포커스가 되었다.<br>또한 1980년대에는 일반인들이 모두 알 만한 일상적인 사실들을 모두 포함한 아주 거대한 데이터베이스를 만들어 상식 문제에 대한 직접적 해결을 시도한 Cyc의 탄생을 볼 수 있었다. 이 프로젝트를 이끈 Douglas Lenat는 지름길은 없다고 말했다. - 기계가 인간의 개념을 알게 하기 위한 단 한 가지 길은 그들을 가르치는 것이다. 이 프로젝트는 수 십 년 동안 완료될 것이라 생각되지 않았다.<br><br>돈은 되돌아온다 : 5세대 프로젝트<br>1981년, 일본의 국제 무역과 산업 부서는 5세대 컴퓨터 프로젝트를 위해 8억 5천만 달러를 확보해 두었다. 그들의 목적은 기계가 사람처럼 프로그램을 작성하고 대화를 수행할 수 있는 시스템과 언어를 번역하거나 그림을 해석하는 것이었다. 그들은 프로젝트를 위해 기본 컴퓨터 언어로 Prolog를 선택하였다.<br>다른 나라들은 그들만의 고유한 프로그램을 개발하였다. UK는 3억 5천만 달러를 들여 Alvey 프로젝트를 시작했다. 미국 회사들의 컨소시엄은 정보기술과 AI안의 거대한 프로젝트를 투자받기 위해 마이크로 전자공학과 컴퓨터 기술 협력이라는 형태를 취했다.또한 1984에서 1988년 사이에 DARPA는 전략적 컴퓨팅 계획을 설립하고 AI에 대한 투자를 세배로 늘렸다.<br><br>신경망 이론의 복귀<br>1982년 , 물리학자 John Hopfield는 (현재 ‘Hopfield net’이라고 불리는) 완벽한 새로운 길에서 정보를 프로세스하고 배울 수 있는 신경망의 형태를 증명해냈다. 이 시기에, David Rumelhart는 (Paul Werbos에 의해 발견된) “역전파”라고 불리는 신경망을 개선하기 위한 새로운 방법을 알리고 있었다. 이러한 두 가지 발견은 1970년 이후 버려진 신경망 이론이라는 분야를 복구시켰다. 새로운 분야는 1986년 분산 병렬처리의 형태로부터 영감을 받았고 이와 같은 형태로 통일되었다. 2권 분량의 논문 집합은 Rumelhart와 물리학자인 James McClelland에 의해 편집되었다. 신경망은 1990년대에 광학 문자 인식 및 음성 인식과 같은 프로그램의 구동 엔진으로 사용되며 상업적으로 성공했다.<br><br>AI의 두번째 암흑기 1987-1993<br>AI와 비즈니스 커뮤니티의 매력은 상실했고 경제 거품이라는 고전적 형태의 1980년대에 빠졌다. 붕괴는 정부기관과 투자자들의 ‘해당 분야는 계속해서 비판에도 불구하고 진보해왔다.’는 인식에 비롯된 것이었다. 로봇 공학 분야에 관련 된 연구원인 Rodney Brooks 와 Hans Moravec는 인공지능에 대한 완전히 새로운 접근 방식을 주장하였다.<br><br>인공지능의 겨울<br>1974년에 전문가 시스템에 대한 열정이 통제할 수 없을 정도로 퍼져나가고 이에 대한 실망이 확실히 따라올 것이라는 걱정이 있었고 이 때 투자가 끊기고 살아남은 연구원들에 의해서 “AI winter”이라는 단어가 만들어졌다. 그들의 두려움은 AI에 대해 일련의 재정적 차질이 있었던 1980년 말에서 1990년대 초반에 잘 나타난다. 이 AI winter 기간의 첫 번째 사건은 1987년에 특성화된 AI 하드웨어 시장이 갑자기 무너진 것이다. 1987년에 애플이나 IBM의 데스크탑 컴퓨터들은 급격히 빨라지고 성능이 좋아졌다. 또한 Symblics과 기타 회사들이 만든 데스크탑 컴퓨터 보다 더 비싼 Lisp 기기들보다도 더욱 좋은 성능을 나타냈다. 즉, 더 이상 Lisp 기기들을 살 이유가 사라진 것이다. 전체산업 1억 달러의 절반의 가치가 하룻밤에 사라졌다. 결국 최초의 성공한 전문가 시스템인 XCON은 유지하기에 너무 비싸다는 것이 증명되었다. 업데이트하기에도 너무 어려웠고 학습도 되지 않았다. 이 전문가 시스템은 또한 일반적이지 않은 질문을 했을 때 괴상한 행동을 하는 일명 \"brittle\" 이었고 그들은 일찍이 발견된 이러한 문제들에 의해 결국 희생되었다. 전문가 시스템은 특별한 경우에서만 유용할 뿐이었다. 1980년대 후반, Strategic Computing initiative는 AI의 투자를 자르는 데 공이 컸다. DARPA의 새로운 리더쉽은 AI는 이 다음의 파도가 아니라고 결정했고 즉각적인 결과를 나타낼 수 있는 것으로 보이는 프로젝트에 직접적인 투자를 하는 방향으로 결정했다. 1991년에는 1981년에 일본에서 5세대 프로젝트의 목표 리스트에 적은 것만큼 성과가 나오지 않았다. 실제로 대화를 계속 이어나가는 것과 같은 어떤 것들은 2010년까지 달성되지 않았다. 다른 인공 지능 프로젝트와 마찬가지로, 실제 가능했던 것보다 기대가 훨씬 컸다.<br><br>몸통을 갖는 것의 중요성: Nouvellle AI and embodied reason<br>1980년대 후반 , 몇몇 연구원들이 로봇 공학을 기반으로 인공 지능에 완전히 새로운 접근법에 대해 찬성하였다. 그들은 실제 지능을 보여주려면 기계에도 몸통이 필요하다고 믿었다. - 기계 또한 이 세상에서 인식하고, 이동하고, 살아남고 거래할 줄 알 필요가 있다. 그들은 이런 감각 운동 기술은 상식적인 추론과 같은 더 높은 단계의 기술이 필요하다고 말했고 실제로 추상적인 추론은 인간의 가장 흥미롭거나 중요한 기술이다. 그들은 지능을 바닥에서부터 지어야 한다고 내세웠다. 인공 두뇌와 제어 이론에서부터 얻은 접근법은 1960년대까지 인기가 없었다. 또 다른 선구자인 David Marr는 신경 과학 이론으로 한 그룹의 비전을 이끌어 성공적인 배경으로 1970년대에 MIT에 들어왔다. 그는 모든 상식적인 접근법(McCarthy's logic and Minsky's frames)을 거절했고 AI는 시각에 대한 육체적인 기계장치를 심볼릭 프로세싱 하기 전에 가장 바닥에서부터 위로 이해할 필요가 있다고 말했다.<br> 1990년에 Elephants Don't Play Chess 논문에서, 로봇 공학 연구자인 Rodney Brooks는 직접적으로 물리적 심볼 시스템 가설에 초점을 맞추었고 심볼들은 항상 필요한 것은 아니라고 말했다. “세계는 그 자체만으로 가장 훌륭한 모델이다. 이것은 항상 최신이며 모든 세부사항이 존재한다. 비결은 적절히 그리고 충분히 자주 감지하는 것이다.80년대와 90년대에 많은 cognitive 과학자들은 또한 사고방식의 심볼 처리 모델을 거절하고 추론에 몸통은 필수적이라고 말했고 이러한 이론을 embodied mind 이론이라고 불렀다.<br><br>AI 1993-현재<br>지금보다 반세기는 더 오래된 AI의 분야는 마침내 가장 오래된 목표 중 몇 가지를 달성했다. 이것은 비록 뒷받침해주는 역할이었지만 기술 산업에 걸쳐 성공적으로 사용되었다. 몇 가지 성공은 컴퓨터의 성능이 증가했기 때문이고 또 다른 몇 가지는 고립된 문제들에 대해 집중하였고 높은 과학적 의무감으로 해 나갔기 때문에 해결되었다. 적어도 비즈니스 분야에서의 AI의 평판은 여전히 처음 같지 않다. 이 분야 내에서는 1960년대 세계의 상상이던 인간 수준의 지능의 꿈을 실현하는 것이 실패로 돌아갔다는 이유로 몇 가지 합의를 하였다. 하위 파트에서 AI의 일부분을 도와주던 모든 요소들은 특정 문제나 접근 방식에 초점이 맞추어졌다. 그 후, AI는 여태 해왔던 것보다 더욱 신중해졌고 더욱 성공적이였다. 또한 보안이 중요한 이슈로 떠올랐다. 인공지능의 보안이슈로는 학습된 인공지능을 속일 수 있는 공격형태인 Poisoning Attack, Evasion Attack, 인공지능 모델 자체를 탈취할 수 있는 Model Extraction Attack, 학습된 모델에서 데이터를 추출해내는 Inversion Attack 등이 있다.<br><br>성공 사례와 무어의 법칙<br>1997년 5월 11일, 딥 블루는 당시 체스 세계 챔피언이던 가리 카스파로프를 이긴 최초의 체스 플레이 컴퓨터가 되었다. 2005년 스탠퍼드의 로봇은 DARPA 그랜드 챌린지에서 연습해 보지 않은 사막 도로 131마일을 자동으로 운전하여 우승하였다. 2년 뒤, CMU의 한 팀은 DARPA 도시 챌린지에서 모든 교통 법규를 지키고 교통 혼잡 속에서 자동으로 55 마일의 길을 찾았다. 2011년 2월, 퀴즈 쇼 Jeopardy!에 출전한 IBM의 응답 시스템 왓슨은 상당히 여유롭게 두 챔피언을 이겼다.<br>이러한 성공은 혁신적인 새로운 패러다임 때문이 아니라 번거로운 엔지니어 스킬과 매우 뛰어난 성능을 가진 오늘날의 컴퓨터에서 비롯된 것이다.실제로, Deep Blue의 컴퓨터는 1951년 Christopher가 체스 하는 법을 가르친 마크 1보다 1천만 배 빨랐다. 이 엄청난 증가는 무어의 법칙에 의해 측정되는데 이것은 2년마다 컴퓨터의 메모리 속도와 양은 두 배씩 늘어난다는 이론이다. 최초 컴퓨터 성능의 근본적인 문제는 느리지만 서서히 극복되고 있었다.<br>지능형 에이전트<br>1990년대 동안에는 ‘지능형 에이전트’라고 불리는 새로운 패러다임이 다 방면에서 수용되고 있었다. 비록 이전의 연구자들은 'divide and conquer' 모듈러를 제안하고 AI에 접근하였지만 지능형 에이전트는 Judea Pearl, Allen Newell 등 다른 이들이 AI를 연구하는데 있어서 결정론과 경제성이라는 개념을 가져오기 전까지 현대식 형태를 갖추지 못했다. 경제학자들의 합리적 에이전트라는 정의와 컴퓨터 과학자들의 객체 혹은 모듈러 정의가 합쳐졌을 때 지능형 에이전트의 패러다임이 완성되었다.<br>지능형 에이전트 시스템은 환경을 인식하고 성공을 가장 극대화할 수 있는 행동을 취한다. 이러한 정의에 의하면 인간과 인간의 조직처럼, 예를 들어 회사처럼 특정 문제를 해결하는 간단한 프로그램을 지능형 에이전트라고 한다. 지능형 에이전트는 AI 연구자를 “the study of intelligent agents\"로 정의한다. 이것은 AI의 정의의 일부를 일반화한 것이다. 이것은 인간의 지능을 넘어 모든 종류의 지능의 연구를 추구한다.<br>이러한 패러다임은 당시 연구자들이 고립 문제에 대해 연구하고 다양하고 유용한 해결법을 찾도록 해주었다. 또한 서로서로 문제와 해결책을 공통의 언어로 표현하였고 추상적 에이전트를 사용한 경제학이나 제어 이론 등과 같은 다른 개념에도 사용되었다. 어떤 연구자들은 지능형 에이전트의 상호 작용에서 더 다양하고 지능적인 시스템을 만들기로 하였고 완전한 에이전트 아키텍처가 되기를 바랐다. 이것이 21세기의 보편적인 교과서들이 인공 지능을 정의하는 방식이다.<br>깔끔함의 승리<br>AI 연구자는 과거에 사용했던 것보다 더욱 정교한 수학적 도구를 사용하여 개발하기 시작했다. 해결하는 데 AI가 필요한 수많은 문제들이 존재하고 있다는 인식은 수학, 경제학 또는 오퍼레이션 연구 등의 분야에서 이미 연구자들이 AI를 사용하여 실현하고 있었다. 공유된 수학적 언어는 높은 수준의 협력, 좋은 평판, 여러 분야를 성공적으로 이끌고 측정과 증명이 된 결과들의 성취를 가능하게 하였다. AI는 더 엄격한 과학 학문이 되었다.<br>이는 혁명 그 자체였으며 \"깔끔함\"의 승리였다.Judea Pearl의 매우 영향이 큰 1988년 책은 AI에 결정론과 확률을 대입시켰다. 사용 중인 많은 새로운 도구(Bayesian networks, hidden Markov models, information theory, stochastic modeling)와 기존의 고전적이 방법들이 최적화되었다. 더 정밀한 수학적 모형이 신경망 네트워크와 진화 알고리즘과 같은 연산 지능적 패러다임을 위해 개발되었다.<br><br>조용한 발전<br>AI 연구자들에 의해 최초로 개발된 알고리즘은 거대한 시스템의 일부로 나타나기 시작했다. AI는 매우 어려운 문제들을 해결했고 데이터 마이닝, 산업 로봇공학, 논리학, 음성 인식, 은행 소프트웨어,의학적 진단, 구글 검색 엔진 등 여러 기술들은 기술 산업에 매우 유용하다는 것이 증명되었다.<br>AI 분야는 이러한 성공에 대해 매우 낮은 신뢰를 받았다. AI의 훌륭한 혁신 중 대부분은 컴퓨터 과학의 도구에서 또 다른 기능으로 세분화되었다.Nick Bostrom은 \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"라고 말했다.1990년대 AI 분야의 많은 연구자들이 고의로 자신의 프로젝트를 다른 이름으로 불렀다. 일부 이러한 현상은 그들의 분야가 AI와 근본적으로 다르다고 여겼기 때문이거나 또는 새로운 이름이 투자받기 쉬웠기 때문일 것이라고 한다. 적어도 상업 분야에서는 연구자에 대해 AI winter에 있었던 실패했던 계약이 꼬리표처럼 따라다녔고 2005년에 뉴욕 타임즈에서는 “컴퓨터과학과 소프트웨어 엔지니어들은 광기에 싸인 몽상가처럼 보일 두려움 때문에 인공 지능이란 용어를 피했다.” 라고 소개되었다.<br><br>HAL 9000은 어디에 있는가?<br>1968년 아서 C. 클라크와 스탠리 큐브릭은 2001년에는 기계가 인간과 유사하거나 또는 인간의 용량을 뛰어넘는 지능을 가진 존재가 되었을 것이라고 상상하며 《2001: 스페이스 오디세이》라는 SF 작품을 완성했다. 여기에 등장하는 HAL 9000이라는 캐릭터는 2001년에 이러한 기계가 존재할 거라고 믿는 많은 AI 연구자들의 공유된 믿음을 기반으로 만들어졌다.<br>훗날 마빈 민스키는 “그래서 왜 우린 2001년에 HAL을 얻지 못했나?”라는 질문을 하였다.대부분의 연구자들이 신경망이나 유전자 알고리즘의 상업적 용도의 프로그램을 추구했던 반면, 민스키는 해답이 방치된 상식 추론과 같이 매우 중심적인 문제에 있다고 믿었다. 반면에 존 매카시는 여전히 자격문제를 비난하였다. 레이 커즈와일은 문제는 컴퓨터 성능에 있으며 무어의 법칙을 사용하였을 때 인간 수준의 지능을 가진 기계는 약 2029년에 나올 것이라고 예견하였다. 제프 호킨스(Jeff Hawkins)는 신경망 연구자들이 대뇌 피질의 본질적인 성질을 무시하고 간단한 문제들을 성공적으로 해결하는 간단한 모델을 추구했다고 말했다. 또한 각각에 대해 많은 설명들이 있으며 이를 대응하는 진행 중인 연구 프로그램들이 있다.<br><br>인공지능과 4차 산업혁명<br>세계는 이미 4차 산업혁명에 진입했으며 인공지능은 빠르게 인간을 대체해 나갈 것이다. 또, 널리 퍼져 있지 않을 뿐 미래는 이미 와 있으며 인공지능, IoT, 클라우드 컴퓨팅, 빅데이터 등이 융합되면서 4차 산업혁명이 발생하고 있다. 과거 산업혁명이 ‘기계근육’을 만드는 과정이었다면 4차 혁명에서는 ‘기계두뇌’가 탄생할 것이다.<br>제1차 산업혁명 발생시, 산업 기계에 의해 일자리를 잃을 것이 두려웠던 노동자들이 러다이트(기계파괴운동)를 일으켰다. 이와 유사하게, 인공 지능에 의한 4차 산업혁명으로, 많은 사람들이 미래에 일자리를 잃을 것을 우려하고 있다. 한 온라인 설문조사에 따르면, 응답자의 70.1%가 미래에 인공지능에 의해 인간의 직업이 줄어들 것이라고 예상했다.<br><br>실험적인 AI 연구<br>인공지능은 1959년에 MIT AI연구소를 설립한 매카시와 마빈 민스키, 카네기멜론 대학교에 인공지능 연구소를 만든 앨런 뉴웰과 허버트 사이먼과 같은 개척자들에 의해 1950년도에 실험 학문으로 시작되었다. 이들 모두는 1956년에 매카시, 민스키, IBM의 나단 로체스터 와 클라우드 샤논에 의해 조직되어 열린, 이미 언급된 다트머스 대학의 여름 AI 콘퍼런스에 참가하였다.<br>역사적으로, 인공지능 연구는 두 개의 부류 -- 깔끔이(Neats)와 지저분이(Scruffies) -- 로 나눌 수 있다. 깔끔이는 우리가 전통적 혹은 기호적(symbolic) 인공지능 연구라고 부르는 분야로서, 일반적으로 추상적인 개념에 대한 기호적 연산과 전문가 시스템(expert systems)에 사용된 방법론을 가르친다. 이와 상반된 영역을 우리는 지저분이(Scruffies) 또는 연결주의자(connectionist)라 부르는데, 시스템을 구축하여 지능을 구현/진화시키려고 시도하고, 특정 임무를 완수하기 위해 규칙적인 디자인을 하기보다는 자동화된 프로세스에 의해서 지능을 향상시키는 방식이다. 가장 대표적인 예로 신경망(neural network)이 있다. 이 두 가지 접근법은 인공지능 역사의 매우 초창기부터 함께 했다. 1960년대와 1970년대를 거치며 scruffy 접근법은 주목받지 못했지만, 1980년대 깔끔이 접근법의 한계가 명확해지면서 다시 주목 받게 되었다. 그러나 현재 두 가지 방식을 사용하는 그 어떤 최신의 인공지능 알고리즘도 확실한 한계가 있다는 것이 명확하다.<br>특히 1980년대에 들어서 Back propagation (인공지능 학습방법: Training Method)가 소개되면서 많은 연구가 진행되었음에도, 신경망을 이용한 인공지능은 아직 초보단계이다. 인공신경망 (Artificial Neural Networks)을 이용한 많은 연구가 현재에도 진행되고 있지만, 몇 가지 장애로 인해서 실용화하기엔 아직도 먼 기술이다. 인공신경망을 이용한 인공지능이 어느 정도 실용화되기 위해선 우선 실효성 있는 학습방법 (Training Methods)이 필요하다. Back propagation을 이용한 학습방법이 제안되어 연구되고 있지만, 완전한 학습을 이룰 수 없을 뿐만 아니라, 학습에 사용되는 data들이 서로 orthonormal해야 하는 조건 때문에 항상 불완전한 학습으로 끝나기 쉽다. (Converge to Local Mimimum, not to the optimal minimum: 지역최적해에 머뭄. 즉, 눈먼 장님이 가장 낮은 저지대를 찾는 경우 각 현재 지점에서 아래로 내려가려는 성질이 있는데 이때 눈먼 봉사이므로 특정 지점의 저지대에 도달한 경우, 그 지점에선 어디로 가거나 위로 올라가는 것만 있으므로 앞에 설명한 성질에 의해 바로 전에 찾은 저지대 남으려 하는 성질이 있다는 것을 의미함). 이러한 단점들을 보완하기 위해서 Fuzzy Logic, Neurofuzzy (Neural fuzzy logic) and Genetic Algorithms등을 이용한 학습방법이 연구되고 있으나 전망이 밝지만은 않은 상태이다.<br> 미국의 DARPA(미 국방부 최신 기술 연구 프로젝트 관리국)과 일본의 5세대 컴퓨터 프로젝트에 의해서 1980년대 인공지능 연구는 엄청난 연구 기금을 지원 받을 수 있었다. 몇몇 인공지능 선각자들이 거둔 주목할 만한 결과에도 불구하고, 즉각적인 결과를 산출하는 데 실패하게 된다. 이것은 1980년대 후반 인공지능 연구 기금에 대한 대폭적인 삭감을 초래하였고, 인공지능 연구의 침체기를 뜻하는 인공지능의 겨울을 가져왔다. 1990년대, 많은 인공지능 연구가들은 좀 더 구체적인 목적 아래 기계 학습, 로보틱스, 컴퓨터 비전과 같은 인공지능과 관련된 세부 영역으로 이동하였고, 순수하고 보편적인 인공지능에 대한 연구는 매우 제한적으로 수행되고 있다.<br><br>인공지능 기술의 실용적인 응용<br>인공지능의 궁극적인 목표인 인간과 같은 지능의 개발이 어려움을 겪자, 다양한 응용 분야가 나타나게 되었다. 대표적인 예가 LISP나 Prolog와 같은 언어인데, 애초에 인공지능 연구를 위해 만들어졌으나 지금에 와서는 인공지능과 관련이 없는 분야에서도 사용되고 있다. 해커 문화도 인공지능 연구실에서 만들어졌는데, 이 중에서도 다양한 시기에 매카시, 민스키, 페퍼트, 위노그라드(SHRDLU를 만든 뒤에 인공지능을 포기했다)와 같은 유명인의 모태가 된 MIT 인공지능 연구소가 유명하다.<br> 다른 많은 시스템들이 한때 인공지능의 활발한 연구 주제였던 기술들에 바탕을 두고 만들어졌다. 그 예들은 다음과 같다:<br>- 체커스 게임에서 Chinook은 사람과 기계를 통합한 세계 챔피언을 차지했다. (1994년) <br>- 체스를 두는 컴퓨터인 딥 블루(Deep Blue)의 성능 향상 버전(비공식적 명칭: 디퍼 블루(Deeper Blue)이 당시 세계 체스 챔피언 가리 카스파로프를 물리쳤다. (1997년)<br>- 불확실한 상황에서 추론을 수행하는 기술인 퍼지 논리가 공장의 제어 시스템에서 광범위하게 사용되고 있다. <br>- 전문가 시스템이 산업적으로 이용되고 있다.<br>- 아직은 인간 번역사에 미치지 못하지만, 시스트란(Systran)과 같은 자동번역기가 광범위하게 사용되고 있다.<br>- 인공신경망이 침입 탐지 시스템에서 컴퓨터 게임까지 다양한 분야에 사용되고 있다.<br>- 광학 문자 판독 시스템은 무작위로 생성된 타자 문서를 텍스트 형태로 변환시킬 수 있다.<br>- 필기체 인식 시스템이 수백만의 PDA에서 사용되고 있다.<br>- 음성 인식 기술은 상업적으로 이용 가능하고 광범위하게 적용되고 있다.<br>- 컴퓨터 대수 시스템인 매스매티카나 Macsyma와 같은 시스템들은 흔하게 사용되고 있다.<br>- Machine vision 시스템들이 하드웨어 검사나 보안분야와 같은 다양한 산업 현장에서 이용되고 있다.<br>- 인공지능 분야와 과학 소설 분야에서는 인공지능 시스템이 인간 전문가의 판단을 대체하리라는 예상이 계속해서 제기되어 왔다. 오늘날에는 몇몇 공학이나 의약 조제 같은 특정 분야에서 전문가 시스템이 인간 전문가의 판단을 보조하거나 대체하고 있다.<br><br>인공지능의 이론적인 결과<br>어떤 사람들은 현재 알려진 어떤 시스템보다도 지능적이며 복잡한 시스템의 등장을 예견하기도 한다. 이와 같은 가상적인 시스템들을 '비결정적인 인공지능 시스템'의 약자인 atilect라고 한다. 이와 같은 시스템이 만들어진다면 그동안 인류에게 문제시되지 않았던 많은 윤리적인 문제들이 발생하게 된다.<br>이에 대한 토론은 시간이 흐름에 따라 '가능성'보다는 '의도'에 점점 초점을 맞추게 되었다. 이러한 초점의 이동은 휴고 더개리스(Hugo de Garis)와 케빈 워릭(Kevin Warwick)에 의해 제기된 \"Cosmist\"(반대말은 \"Terran\") 논쟁에 의해 이루어졌다. 더개리스에 따르면 Cosmist란 더욱 지능적인 종족을 인간의 후계종으로 만들어 내기 위해 노력한다. 이러한 논의로 미루어 볼 때, '의도'의 문제가 초기 인공지능 \"반대파\"들에게 큰 문제였음을 알 수 있다.<br>흥미로운 윤리적 문제를 제기하는 주제는 다음과 같다.<br>- 우리가 만든 시스템이 지능을 갖추었는지를 판정하는 문제<br>   - 튜링 테스트<br>   - 인식(Cognition)의 문제<br>   - '왜 이러한 시스템을 구별해야 하는가'라는 문제<br>- 인공지능을 정도의 문제로 정의할 수 있는가?<br>- 이와 같은 시스템들의 자유와 권리 문제<br>- 인간이 다른 동물에 비해 '영리'한 것과 같은 방식으로 인공지능도 인간에 비해 '영리'할 수 있는가?<br>- 지구상의 어떤 사람보다 더욱 지능적인 시스템을 만드는 문제<br>- 이러한 시스템을 만드는 데 있어서 얼마나 많은 안전 장치를 포함시켜야 하는지의 문제<br>- 사람의 생각을 대체하기 위해서 얼마만큼의 학습 능력이 필요한지 혹은 (전문가 시스템과 같이) 그와 같은 학습 능력 없이 주어진 일을 할 수 있는지<br>- 단일성의 문제<br>- 사람의 일자리와 업무에 미치는 영향. 이 문제는 아마도 자유 무역 체제 하에서 발생하는 문제와 유사할 수도 있다.<br><br>언어<br>유명 인공지능<br>지능적 기계<br>다양한 종류의 지능적 프로그램이 있다. 이들 중 몇 가지 예를 들면 다음과 같다.<br>- CNC - 공작 기계를 이용한 가공 코드를 컴퓨터가 소수점 3자리까지 계산하는 방식이다. 가장 원시적인 인공지능의 한 형태이다.<br>- 비디오 게임 - 원시 인공지능이다. 딥블루, 알파고 역시 알고 보면 비디오 게임 형태의 바둑 인공지능이다.<br>- 알파고 - 바둑 인공지능이다.<br>- Watson - IBM에서 만든 인공지능으로, 종류가 다양하며 의학, 금융, 방송 등에 쓰인다.<br>- The Start Project - 영어로 된 질문에 답변하는 웹 기반 시스템이다.<br>- Cyc - 실세계와 논리적 추론 능력에 관련된 광범위한 상식으로 구성된 지식기반 시스템.<br>- ALICE - 사용자와 대화를 주고받을 수 있는 프로그램.<br>- Alan - 사용자와 대화를 주고받을 수 있는 프로그램.<br>- ELIZA - 1970년대에 개발된 심리치료사 역할을 하는 프로그램.<br>- AM - 1970년대에 더글러스 레넛(Douglas B. Lenat)이 개발한 수학의 개념들을 형식화하는 프로그램.<br>- PAM (Plan Applier Mechanism) - 1978년 John Wilensky에 의해 개발된 줄거리 인식 시스템.<br>- SAM (Script Applier Mechanism) - 1975년에 개발된 줄거리 인식 시스템.<br>- SHRDLU - 1968년에서 1970년 사이에 개발된 초창기 자연 언어 인식 시스템.<br>- Creatures - 뉴널넷 두뇌와 정교한 생화학에 기반한 유전코드로 생명체를 탄생시키고 진화시키는 컴퓨터 게임.<br>- Eurisko - 휴리스틱으로 구성된 문제 해결 언어. 휴리스틱을 어떻게 사용하며 변경해야 할지에 대한 휴리스틱을 포함하고 있다. 1978년 더글러스 레넛이 개발.<br>- X-Ray Vision for Surgeons - 매사추세츠 공과대학교 의학 비전(MIT Medical vision) 연구팀이 개발.<br>- 심심이 - 한국어로 대화를 주고받을 수 있는 프로그램. 사용자에 의한 학습이 가능하도록 하여 대중적으로 성공했다. 2002년 최정회에 의해 개발.<br>- Stable Diffusion web UI - AI 그림을 생성할 수 있는 프로그램. 사용자가 직접 모델을 학습할 수 있고, 학습한 결과에 따라 여러 그림체를 표현할 수 있다.<br><br>인공지능 연구가<br>전 세계에는 수많은 인공지능 연구가들이 있다. 이제 인공지능 분야에 많은 기여를 한 연구자들을 소개해보겠다.<br>- 마빈 민스키<br>- 볼프강 발스터(Wolfgang Wahlster)<br>- 존 매카시<br>- 더글러스 레넛(Doug Lenat)<br>- 로저 섕크<br>- 앨런 튜링<br>- 라지 레디(Raj Reddy)<br>- 테리 위노그래드(Terry Winograd)<br>- 로드니 브룩스(Rodney Brooks)<br>- 스튜어트 러셀(Stuart Russell)<br>몇몇 컴퓨터 과학 연구가들은, \"인공지능\"이라는 용어가 지금까지 이 연구 분야에서 이룩한 많은 업적과 \"지능\"이라는 일반적인 용어사이에서 큰 불일치를 초래하기 때문에 좋지 못한 용어라고 여겨진다. 이 같은 문제는 대중과학작가들과 케빈 워릭(Kevin Warwick)과 같이 현 상태로는 불가능한 혁신적인 인공지능 연구 성과에 대한 기대를 불러일으키는 사람들에 의해서 심화되고 있다. 이 같은 까닭으로 인공지능과 관련된 분야에서 일하는 많은 연구자들이 자신들은, 인지 과학, 정보학, 통계추론 또는 정보공학과 관련된 연구를 하고 있다고 이야기한다. 그러나 현재 진보는 이루어지고 있고, 오늘날 인공지능은 전 세계 수많은 산업 시스템에서 작동하고 있다. 오늘날 실세계의 인공지능 시스템에 관해 더 자세한 내용을 보려면 와이어드지의 기사를 참고하라.<br><br>미래<br>초지능<br>초지능(superintelligence)이란 인간의 능력을 아득히 뛰어넘는 가설적인 지능체를 가리키는 말이다. 어떤 전문가들은 인공 일반지능의 발전이 앞으로 계속해서 이어진다면 일정한 수준의 지능에 도달하고 나서는 인공지능이 스스로를 계속해서 개선할 수 있으며, 이를 반복하여 기하급수적인 지능 성장으로 순식간에 인간의 지능을 뛰어넘을지도 모른다고 주장한다. 버너 빈지는 이 시나리오를 \"특이점\"(singularity)이라고 이름하였다. 인공지능의 한계는 여전히 명확하지 않기 때문에 이는 예측 불가능하다고 여겨지며 때로는 허무맹랑한 이야기로 치부되기도 한다. 로봇 전문가 한스 모라벡이나 발명가 레이 커즈와일 등은 더 나아가 미래에는 인간이 기계와 결합한 사이보그로 진화하여 초지능을 손에 넣을 수 있을 것이라고 주장하는데, 이러한 주장을 트랜스휴머니즘이라고 한다.<br>간추리기: 초지능은 인간의 능력을 뛰어넘는 가설적인 지능체를 의미합니다. 몇몇 전문가들은 인공 일반지능의 발전으로 인해 인공지능이 스스로를 개선하고 기하급수적인 성장을 거듭하여 인간의 지능을 뛰어넘을 수도 있다고 주장합니다. 이를 \"특이점\"이라고도 부르며, 미래에는 사이보그로 진화하여 초지능을 손에 넣을 수 있다는 주장도 있습니다.<br>위험성<br>인공지능의 부정적 영향으로 현존 일자리의 감소, 시스템 오류 발생과 이에 따른 보상, 인간 노동력에 대한 경시, 전투 로봇과 같은 자율 살상 무기에 대한 윤리적인 문제 등이 있다.<br>기술에 의한 실업<br>지금까지 과학 기술은 일자리를 줄이기보다는 증가시키는 경향이 있었으나 경제학자들은 AI에 관해서는 미지의 영역이라고 인정한다. 경제학자들을 대상으로 한 설문에서 로봇과 AI의 사용 증가가 장기 실업자를 늘릴지에 대해 물은 결과 의견이 크게 분분했으며, 다만 늘어난 생산성이 재분배된다면 순이익이 될 수 있다는 데에 동의한다.<br>또한 블루칼라 직종을 위협하던 종래의 자동화와 달리 인공지능에 의한 자동화는 많은 중산층의 화이트칼라 일자리도 위협할 수 있다는 점이 중대하게 받아들여진다. 그 영향 범위도 매우 넓어서 법률 사무원에서 패스트푸드 다양한 직종이 큰 위기에 놓일 것이라 예측되는데, 한편으로 개인 건강 관리나 성직자 등 일부 직종은 오히려 수요가 증가할 수 있다고 예상된다.\"\"\"|\n",
    "|ASSISTANT|[{\"발췌\": \"...\"}, ... {\"발췌\": \"...\"}]|\n",
    "|USER|더 관련성 있는 발췌문이 있나요? 발췌문을 반복하지 않도록 주의하세요. 또한 발췌문에 해석에 필요한 모든 관련 문맥이 포함되어 있도록, 즉 중요한 문맥이 누락된 작은 조각을 추출하지 않도록 하세요.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"발췌\": \"초기 인공지능 연구에 대한 대표적인 정의는 다트머스 회의에서 존 매카시가 제안한 것으로 '기계를 인간 행동의 지식에서와 같이 행동하게 만드는 것'이다. 그러나 이 정의는 범용인공지능(AGI, 강한 인공지능)에 대한 고려를 하지 못한 것 같다.\"},\n",
      "{\"발췌\": \"인공지능의 탄생(1943-1956)\\n\\n1940년대 후반과 1950년대 초반에 이르러서 수학, 철학, 공학, 경제 등 다양한 영역의 과학자들에게서 인공적인 두뇌의 가능성이 논의되었다. 1956년에 이르러서, 인공지능이 학문 분야로 들어섰다.\\n\\n인공두뇌학과 초기 신경 네트워크\\n생각하는 기계에 대한 초기 연구는 30년대 후기에서부터 50년대 초기의 유행한 아이디어에 영감을 얻은 것이었다.\"},\n",
      "{\"발췌\": \"다트머스 컨퍼런스 1956년: AI의 탄생\\n1956년에 열린 다트머스 컨퍼런스는 마빈 민스키와 존 매카시, 그리고 IBM의 수석 과학자인 클로드 섀넌과 네이선 로체스터가 개최했다. 컨퍼런스는 '학습의 모든 면 또는 지능의 다른 모든 특성로 기계를 정밀하게 기술할 수 있고 이를 시물레이션 할 수 있다'라는 주장을 포함하여 제안을 제기했다.\"},\n",
      "{\"발췌\": \"AI의 첫번째 암흑기(1974-1980)\\n\\n70년대에 이르자, AI는 비판의 대상이 되었고 재정적 위기가 닥쳤다. AI 연구가들은 그들의 눈앞에 있는 복잡한 문제를 해결하는데 실패했다. 연구가들의 엄청난 낙관론은 연구에 대한 기대를 매우 높여놓았고, 그들이 약속했던 결과를 보여주지 못하자, AI에 대한 자금 투자는 사라져버렸다.\"},\n",
      "{\"발췌\": \"AI의 두번째 암흑기 1987-1993\\n\\nAI와 비즈니스 커뮤니티의 매력은 상실했고 경제 거품이라는 고전적 형태의 1980년대에 빠졌다. 붕괴는 정부기관과 투자자들의 ‘해당 분야는 계속해서 비판에도 불구하고 진보해왔다.’는 인식에 비롯된 것이었다.\"},\n",
      "{\"발췌\": \"깔끔함의 승리\\nAI 연구자는 과거에 사용했던 것보다 더욱 정교한 수학적 도구를 사용하여 개발하기 시작했다. 해결하는 데 AI가 필요한 수많은 문제들이 존재하고 있다는 인식은 수학, 경제학 또는 오퍼레이션 연구 등의 분야에서 이미 연구자들이 AI를 사용하여 실현하고 있었다. 공유된 수학적 언어는 높은 수준의 협력, 좋은 평판, 여러 분야를 성공적으로 이끌고 측정과 증명이 된 결과들의 성취를 가능하게 하였다. AI는 더 엄격한 과학 학문이 되었다.\"}]\n",
      "알겠습니다. 더 관련성 있는 발췌문을 제공하겠습니다.\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\"발췌\": \"강인공지능과 약인공지능\\n초기 인공지능 연구에 대한 대표적인 정의는 다트머스 회의에서 존 매카시가 제안한 것으로 '기계를 인간 행동의 지식에서와 같이 행동하게 만드는 것'이다. 그러나 이 정의는 범용인공지능(AGI, 강한 인공지능)에 대한 고려를 하지 못한 것 같다. 인공지능의 또다른 정의는 인공적인 장치들이 가지는 지능이다.\"},\n",
      "    {\"발췌\": \"인공지능의 탄생(1943-1956)\\n1940년대 후반과 1950년대 초반에 이르러서 수학, 철학, 공학, 경제 등 다양한 영역의 과학자들에게서 인공적인 두뇌의 가능성이 논의되었다. 1956년에 이르러서, 인공지능이 학문 분야로 들어섰다.\\n\\n인공두뇌학과 초기 신경 네트워크\\n생각하는 기계에 대한 초기 연구는 30년대 후기에서부터 50년대 초기의 유행한 아이디어에 영감을 얻은 것이었다. 당시 신경학의 최신 연구는 실제 뇌가 뉴런으로 이루어진 전기적인 네트워크라고 보았다.\"},\n",
      "    {\"발췌\": \"다트머스 컨퍼런스 1956년: AI의 탄생\\n1956년에 열린 다트머스 컨퍼런스는 마빈 민스키와 존 매카시, 그리고 IBM의 수석 과학자인 클로드 섀넌과 네이선 로체스터가 개최했다. 컨퍼런스는 '학습의 모든 면 또는 지능의 다른 모든 특성로 기계를 정밀하게 기술할 수 있고 이를 시물레이션 할 수 있다'라는 주장을 포함하여 제안을 제기했다.\"},\n",
      "    {\"발췌\": \"AI의 첫번째 암흑기(1974-1980)\\n70년대에 이르자, AI는 비판의 대상이 되었고 재정적 위기가 닥쳤다. AI 연구가들은 그들의 눈앞에 있는 복잡한 문제를 해결하는데 실패했다. 연구가들의 엄청난 낙관론은 연구에 대한 기대를 매우 높여놓았고, 그들이 약속했던 결과를 보여주지 못하자, AI에 대한 자금 투자는 사라져버렸다.\"},\n",
      "    {\"발췌\": \"AI의 두번째 암흑기 1987-1993\\nAI와 비즈니스 커뮤니티의 매력은 상실했고 경제 거품이라는 고전적 형태의 1980년대에 빠졌다. 붕괴는 정부기관과 투자자들의 ‘해당 분야는 계속해서 비판에도 불구하고 진보해왔다.’는 인식에 비롯된 것이었다.\"},\n",
      "    {\"발췌\": \"깔끔함의 승리\\nAI 연구자는 과거에 사용했던 것보다 더욱 정교한 수학적 도구를 사용하여 개발하기 시작했다. 해결하는 데 AI가 필요한 수많은 문제들이 존재하고 있다는 인식은 수학, 경제학 또는 오퍼레이션 연구 등의 분야에서 이미 연구자들이 AI를 사용하여 실현하고 있었다. 공유된 수학적 언어는 높은 수준의 협력, 좋은 평판, 여러 분야를 성공적으로 이끌고 측정과 증명이 된 결과들의 성취를 가능하게 하였다. AI는 더 엄격한 과학 학문이 되었다.\"},\n",
      "    {\"발췌\": \"인공지능과 4차 산업혁명\\n세계는 이미 4차 산업혁명에 진입했으며 인공지능은 빠르게 인간을 대체해 나갈 것이다. 또, 널리 퍼져 있지 않을 뿐 미래는 이미 와 있으며 인공지능, IoT, 클라우드 컴퓨팅, 빅데이터 등이 융합되면서 4차 산업혁명이 발생하고 있다. 과거 산업혁명이 ‘기계근육’을 만드는 과정이었다면 4차 혁명에서는 ‘기계두뇌’가 탄생할 것이다.\"}\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "system_msg = SystemMessage(content='''\n",
    "3중 큰따옴표로 구분된 문서가 제공되면 과제는 다음 질문과 관련된 발췌문을 추출합니다. \"인공지능의 역사에서 어떤 중요한 패러다임의 변화가 일어났는가?\" 발췌문에 해석에 필요한 모든 관련 맥락이 포함되어 있는지, 즉 중요한 맥락이 누락된 작은 조각을 추출하지 않았는지 확인합니다. [{\"발췌\": \"...\"}, ... {\"발췌\": \"...\"}]와 같이 JSON 형식으로 출력을 제공하세요.\n",
    "''')\n",
    "\n",
    "user_msg = HumanMessage(content='''\n",
    "\"\"\"인공지능(人工智能, 영어: artificial intelligence, AI)은 인간의 학습능력, 추론능력, 지각능력을 인공적으로 구현하려는 컴퓨터 과학의 세부분야 중 하나이다. 정보공학 분야에 있어 하나의 인프라 기술이기도 하다. 인간을 포함한 동물이 갖고 있는 지능 즉, 자연 지능(natural intelligence)과는 다른 개념이다. \n",
    "인간의 지능을 모방한 기능을 갖춘 컴퓨터 시스템이며, 인간의 지능을 기계 등에 인공적으로 시연(구현)한 것이다. 일반적으로 범용 컴퓨터에 적용한다고 가정한다. 이 용어는 또한 그와 같은 지능을 만들 수 있는 방법론이나 실현 가능성 등을 연구하는 과학 기술 분야를 지칭하기도 한다. \n",
    "\n",
    "강인공지능과 약인공지능\n",
    "초기 인공지능 연구에 대한 대표적인 정의는 다트머스 회의에서 존 매카시가 제안한 것으로 \"기계를 인간 행동의 지식에서와 같이 행동하게 만드는 것\"이다. 그러나 이 정의는 범용인공지능(AGI, 강한 인공지능)에 대한 고려를 하지 못한 것 같다. 인공지능의 또다른 정의는 인공적인 장치들이 가지는 지능이다. 거의 대부분 정의들이 인간처럼 사고하는 시스템, 인간처럼 행동하는 시스템, 이성적으로 사고하는 시스템 그리고 이성적으로 행동하는 시스템이라는 4개의 분류로 분류된다. 인공지능의 작동 방식이 의사 결정과 문제 해결, 학습에 있어 사람의 생각이나 행동과 유사할수록 강한 인공지능으로 분류되고, 논리에 의해 만들어지는 합리적인 생각이나 행동에 가까울수록 약한 인공지능으로 분류된다.\n",
    "\n",
    "약인공지능\n",
    "약인공지능(weak AI)은 사진에서 물체를 찾거나 소리를 듣고 상황을 파악하는 것과 같이 기존에 인간은 쉽게 해결할 수 있으나 컴퓨터로 처리하기에는 어려웠던 각종 문제를 컴퓨터로 수행하게 만드는데 중점을 두고 있다. 한참 막연한 인간 지능을 목표로 하기보다는 더 현실적으로 실용적인 목표를 가지고 개발되고 있는 인공지능이라고 할 수 있으며, 일반적인 지능을 가진 무언가라기보다는 특정한 문제를 해결하는 도구로써 활용된다.\n",
    "\n",
    "강인공지능 (AGI)\n",
    "강인공지능(strong AI) 또는 인공 일반 지능(arificial general intelligence, AGI)은 인간처럼 실제로 사고하여 문제를 해결할 수 있는 \"일반 지능\"을 인공적으로 구현하려는 시도이다. 오늘날 이 분야의 연구는 주로 미리 정의된 규칙의 모음을 이용해서 지능을 흉내내는 컴퓨터 프로그램을 개발하는 것에 맞추어져 있다. 강한 인공지능 분야의 발전은 여전히 미약하지만, 인간과 같은 지능이라는 목표를 어떻게 정의하는지에 따라 어느 정도 발전이 이루어지고 있다고도 볼 수 있다.\n",
    "강인공지능의 실현 가능성에 관한 논쟁\n",
    "존 설이나 휴버트 드라이퍼스와 같은 몇몇 철학자들은 몸이 아닌 기계에 인간의 지능이나 의식을 구현하는 작업의 실현 가능성에 대한 철학적 바탕을 두고 논쟁을 벌였다. 설은, 튜링 테스트의 통과 여부는 사람의 기준으로 볼 때 기계가 의식을 갖추었다는 판단의 필요 조건이 되지 못한다는 중국어 방에 대한 논증으로 유명하다. 드라이퍼스는 그의 저서 \"컴퓨터가 할 수 없는 것들: 인공적인 추론에 대한 비평\"에서 의식이라는 것은 룰이나 논리 기반 시스템 또는 물리적인 형태를 가지고 있지 않은 시스템에서 찾을 수 없으나, 신경망(neural network)이나 그 유사한 메커니즘을 이용하는 로보틱 시스템은 인공지능을 실현할 수 있는 가능성이 있다고 주장했다.\n",
    "다른 철학자들은 엇갈린 관점을 고수한다. 많은 사람들이 약한 인공지능 정도는 가능하다고 보지만, 또한 많은 사람들이 강한 인공지능을 지지하고 있는 것도 사실이다. 대니얼 C. 데넷은 그의 '의식에 대한 설명'에서 만일 마법의 불꽃이나 영혼이 없다면 인간은 기계에 불과하다며, 지능에 대해서만 인간이라는 기계가 다른 실현 가능한 모든 기계와 다르게 특별 취급을 받아야할 이유가 무엇인가 묻고 있다. \n",
    "어떤 철학자들은 우리가 약한 인공지능을 가능한 것으로 받아들인다면, 강한 인공지능 역시 받아들여야 한다고 주장한다. 지능은 외견상 보이는 것을 가리키는 것이지 진정한 실체가 아니라는 약한 인공지능의 입장은 많은 비판을 받고 있다. 그러나 이에 반하는 손쉬운 예를 사이먼 블랙번의 철학 입문서 \"생각\"에서 찾을 수 있다. 블랙번은 당신이 지능적으로 보이지만, 그 지능이 실존하는가에 대해서 말할 수 있는 방법이 없다고 지적한다. 그는 우리는 단지 믿음 또는 신념 위에서 그것을 다룰 뿐이라고 이야기한다.\n",
    "강한 인공지능을 지지하는 사람들은 인공지능에 반대하는 사람들의 논증이 결국은 아래와 같은 주장을 조합한 것이라고 주장한다.\n",
    "    1. 특권에 바탕을 둔 오만함으로 인해 인간에게는 (기계에는 없는) 마법의 불꽃이 있다는 주장 (예를 들면, 신에 의해 주어진 영혼)\n",
    "    2. 지능은 기계로는 성취될 수 없는 그 무엇이라는 주장.\n",
    "강한 인공지능을 뒷받침하는 논증(따라서 반대하는 사람은 이 논증을 논박해야 한다.)은 다음과 같다.\n",
    "    1. 인간의 마음은 유한 상태 기계(Finite State Machine)이고, 따라서 처치-튜링 이론은 뇌에 적용 가능하다.\n",
    "    2. 뇌는 순수한 하드웨어이다.(말하자면 고전적인 컴퓨터처럼 동작한다.)\n",
    "    3. 인간의 마음은 오로지 뇌를 통해서만 존재한다.\n",
    "로저 펜로즈를 포함한 몇몇 학자들은 지능에 처치-튜링 명제의 적용이 가능하지 않다고 논박한다. 특히 펜로즈는 인간의 마음에는 물리적인 속성을 뛰어넘는 무언가가 있다고 이야기하며, 그의 주장은 우리의 우주 안에서 초연산(hypercomputation)이 가능하다는 논증에 바탕을 두고 있다. 양자역학과 뉴턴 역학에 따르면 이러한 초연산은 가능하지 않지만, 특별한 시공간에서는 가능한 것으로 생각되기도 한다. 그러나 이는 소수의 주장이며, 우리의 우주는 그러한 초연산이 가능할 정도로 꼬이지(convoluted) 않았다는 많은 학자들의 합의가 존재한다.\n",
    "                        \n",
    "역사 \n",
    "\n",
    "인공지능 이론의 발전\n",
    "상당수 인공지능 연구의 (본래) 목적은 심리학에 대한 실험적인 접근이었고, 언어 지능(linguistic intelligence)이 무엇인지를 밝혀내는 것이 주목표였다(튜링 테스트가 대표적인 예이다). \n",
    "언어 지능을 제외한 인공지능에 대한 시도들은 로보틱스와 집합적 지식을 포함한다. 이들은 환경에 대한 처리, 의사 결정을 일치시키는 것에 중심을 두며 어떻게 지능적 행동이 구성되는 것인가를 찾을 때, 생물학과, 정치과학으로부터 이끌어 낸다. 사회적 계획성과 인지성의 능력은 떨어지지만 인간과 유사한 유인원을 포함한, 복잡한 인식방법을 가진 동물뿐만 아니라 특히 곤충들(로봇들로 모방하기 쉬운)까지 포함한 동물학으로부터 인공지능 과학은 시작된다. 여러 가지 생명체들의 모든 논리구조를 가져온 다는 것은 이론적으로는 가능하지만 수치화, 기계화 한다는 것은 쉬운 일이 아니다.\n",
    "인공지능 학자는 동물들은 인간들보다 모방하기 쉽다고 주장한다. 그러나 동물의 지능을 만족하는 계산 모델은 없다. 매컬러가 쓴 신경 행동에서 내재적 사고의 논리적 계산, 튜링의 기계와 지능의 계산 그리고 리클라이더의 인간과 컴퓨터의 공생가 기계 지능의 개념에 관한 독창적인 논문들이다.\n",
    "존 루커스의 지성, 기계, 괴델과 같은 논리학과 철학기반의 기계지능의 가능성을 부인한 초기 논문들도 있다.\n",
    "인공지능 연구에 바탕을 둔 실질적인 작업이 결실을 거둠에 따라, 인공지능을 지지하는 사람들은 인공지능의 업적을 깎아내리기 위해 인공지능에 반대하는 사람들이 예전에는 '지능적'인 일이라고 주장하던 컴퓨터 체스나 바둑, 음성인식 등과 같은 작업에 대해 말을 바꾸고 있다고 비난하였다. 그들은 이와 같이 연구 목표를 옮기는 작업은 '지능'을 '인간은 할 수 있지만, 기계는 할 수 없는 어떤 것'으로 정의하는 역할을 한다고 지적하였다.\n",
    "(E.T. Jaynes에 따르면) 존 폰 노이만은 이미 이를 예측하였는데, 1948년에 기계가 생각하는 것은 불가능하다는 강의를 듣고 다음과 같이 말하였다. \"당신은 기계가 할 수 없는 어떤 것이 있다고 주장한다. 만일 당신이 그 기계가 할 수 없는 것이 무엇인지를 정확하게 이야기해준다면, 나는 언제든지 그 일을 수행할 수 있는 기계를 만들 수 있다.\" 했다. 폰 노이만은 이미 그 전에 모든 처리절차(procedure)는 (범용)컴퓨터에 의해서 시뮬레이션 될 수 있다고 이야기함에 따라 쳐치-튜링 이론을 언급했다.\n",
    "1969년에 매카시와 헤이스는 그들의 논문 \"인공지능 관점에서 바라본 철학적인 문제들\"에서 프레임 문제를 언급하였다.\n",
    "\n",
    "인공지능의 탄생(1943-1956)\n",
    "                        \n",
    "1940년대 후반과 1950년대 초반에 이르러서 수학, 철학, 공학, 경제 등 다양한 영역의 과학자들에게서 인공적인 두뇌의 가능성이 논의되었다. 1956년에 이르러서, 인공지능이 학문 분야로 들어섰다.\n",
    "                        \n",
    "인공두뇌학과 초기 신경 네트워크 \n",
    "생각하는 기계에 대한 초기 연구는 30년대 후기에서부터 50년대 초기의 유행한 아이디어에 영감을 얻은 것이었다. 당시 신경학의 최신 연구는 실제 뇌가 뉴런으로 이루어진 전기적인 네트워크라고 보았다. 위너가 인공두뇌학을 전기적 네트워크의 제어와 안정화로 묘사했으며, 섀넌의 정보 과학은 디지털 신호로 묘사했다. 또 튜링의 계산 이론은 어떤 형태의 계산도 디지털로 나타낼 수 있음을 보였다. 이런 여러 밀접한 연관에서, 인공두뇌의 전자적 구축에 대한 아이디어가 나온 것이다. 월터의 거북이 로봇이 이 아이디어를 중요하게 포함한 연구의 예이다. 이 기계는 컴퓨터를 사용하지 않고 아날로그 회로를 이용했지만, 디지털의 전자적, 상징적 추리를 보여주기엔 충분했다. 월터 피츠(Walter Pitts)와 워런 매컬러(Warren Sturgis McCulloch)는 인공 신경망에 기인한 네트워크를 분석하고 그들이 어떻게 간단한 논리적 기능을 하는지 보여주었다. 그들은 후에 신경 네트워크라 부르는 기술을 첫번째로 연구한 사람이다. 피츠와 매컬러는 24살의 대학원생인 젊은 마빈 민스키를 만났고, 민스키는 1951년 첫번째 신경 네트워크 기계인 SNARC를 구축했다. 민스키는 향후 50년동안 인공지능의 가장 중요한 지도적, 혁신적 인물 중 하나가 되었다.\n",
    "튜링 테스트\n",
    "1950년 앨런 튜링은 생각하는 기계의 구현 가능성에 대한 분석이 담긴, 인공지능 역사에서 혁혁한 논문을 발표했다. 그는 \"생각\"을 정의하기 어려움에 주목해, 그 유명한 튜링테스트를 고안했다. 텔레프린터를 통한 대화에서 기계가 사람인지 기계인지 구별할 수 없을 정도로 대화를 잘 이끌어 간다면, 이것은 기계가 \"생각\"하고 있다고 말할 충분한 근거가 된다는 것이었다. 튜링 테스트는 인공 지능에 대한 최초의 심도 깊은 철학적 제안으로 평가받는다.\n",
    "게임 인공지능\n",
    "1951년에, 맨체스터 대학의 페란티 마크 1(Ferranti Mark 1) 기계를 사용하여 크리스토퍼 스트레이(Christopher Strachey)는 체커 프로그램을 작성했고, 디트리히 프린츠(Dietrich Prinz)는 체스 프로그램을 작성했다. 아서 새뮤얼(Arthur Samuel)이 50년대 중반과 60년대 초반에 개발한 체커 프로그램은 결국 존경받는 아마추어에 도전할 수 있는 충분한 기술적 발전을 이룩했다.\n",
    "상징 추론과 논리 이론\n",
    "디지털 컴퓨터에 접할 수 있어진 50년대 중반에 이르러서, 몇몇 과학자들은 직관적으로 기계가 수를 다루듯 기호를 다루고, 사람처럼 기호의 본질적인 부분'까지 다룰 수 있을 것이라고 생각했다. 이것은 생각하는 기계를 만드는 새로운 접근 방법이었다. 1956년에, 앨런 뉴얼(Allen Newell)과 허버트 사이먼(Herbert A. Simon)은 \"논리 이론\"을 구현했다. 그 프로그램은 결국 러셀과 화이트헤드의 '수학 원리'에 나오는 52개의 정리중 32개를 증명해냈고, 일부 새롭고 더 우아한 증거를 찾아내기도 했다.\n",
    "다트머스 컨퍼런스 1956년: AI의 탄생\n",
    "1956년에 열린 다트머스 컨퍼런스는 마빈 민스키와 존 매카시, 그리고 IBM의 수석 과학자인 클로드 섀넌과 네이선 로체스터가 개최했다. 컨퍼런스는 \"학습의 모든 면 또는 지능의 다른 모든 특성로 기계를 정밀하게 기술할 수 있고 이를 시물레이션 할 수 있다\"라는 주장을 포함하여 제안을 제기했다. 참가자는 레이 솔로모노프(Ray Solomonoff), 올리버 셀프리지(Oliver Selfridge), 트렌처드 모어(Trenchard More), 아서 새뮤얼(Arthur Smuel), 앨런 뉴얼(Allen Newell)과 허버트 사이먼(Herbert A. Simon)으로, 그들 모두 수십년동안 인공지능 연구에서 중요한 프로그램을 만들어온 사람들이었다. 컨퍼런스에서 뉴얼과 사이먼은 \"논리 이론\"을 소개했고, 매카시는 Artificial Intelligence를 그들의 연구를 칭하는 이름으로 받아들이길 설득했다. 1956년 다트머스 컨퍼런스는 AI 라는 이름, 목표점, 첫번째 성공과 이를 이룬 사람들, 그리고 넓은 의미의 AI의 탄생을 포함하는 순간이었다.\n",
    "                        \n",
    "황금기(1956~1974년)\n",
    "                        \n",
    "다트머스 컨퍼런스 이후에, AI라는 새로운 영역은 발전의 땅을 질주하기 시작했다. 이 기간에 만들어진 프로그램은 많은 사람들을 \"놀랍게(astonishing)\"만들었는데, 프로그램은 대수학 문제를 풀었고 기하학의 정리를 증명했으며 영어를 학습했다. 몇 사람들은 이와같은 기계의 \"지능적\" 행동을 보고 AI로 모든 것이 가능할 것이라 믿었다. 연구가들은 개인의 의견 또는 출판물들을 통해 낙관론을 펼쳤고, 완전한 지능을 갖춘 기계가 20년 안에 탄생할 것이라고 예측했다. ARPA(Advanced Research Projects Agency)같은 정부 기관은 이 새로운 분야에 돈을 쏟아부었다.\n",
    "\n",
    "작업들\n",
    "많은 성공적인 프로그램과 새로운 발전 방향이 50년대 후반과 60년대에 나타났다. 이곳에는 AI 역사에 지대한 영향을 미친 것들을 기술했다.\n",
    "탐색 추리\n",
    "초기 AI 프로그램은 동일한 기본적인 알고리즘을 사용했다. 게임의 승리나 정리 증명 같은 어떤 목표 달성을 위해, 그들은 한발짝식 나아가는(step-by-step) 방식을 상용했다. 예를 들어 미로를 찾아갈때 계속 나아가면서 막힌 길이 있으면 다른 길이 있는 곳까지 되돌아 왔다가 다른 길로 가는 식이었다. 이런 패러다임은 \"탐색 추리\"라 불렸다. 주요한 문제는, 간단한 미로에 있어서도 경로로 사용할 수 있는 수가 천문학적으로 많았다는 것이다. 연구가들은 추론 또는 경험적으로 찾은 규칙으로 정답이 아닌듯 보이는 경로를 지우는 방식을 사용했다.뉴엘과 사이먼은 \"범용 문제 해결기(General Problem Solver)\"라 부르는 프로그램 속 알고리즘의 범용적인 버전을 포착하려고 노력했다. 다른 \"검색\" 프로그램은 기하학과 대수학의 문제를 해결하는 것처럼 인상적인 작업 - 허버트 게랜터(Herbert Gelenter)의 \"기하학 해결기\"나 민스키의 제자인 제임스 슬레이글(James Slage)의 SAINT - 을 수행하길 시도했다. 다른 프로그램은 목표와 목표에 다가가기 위한 세부 계획을 검색했고, 여기에는 스탠포드에서 샤키(Shakey) 로봇의 동작을 제어하기 위해 개발한 STRIPS 시스템을 포함한다.\n",
    "자연어 처리\n",
    "AI 연구의 중요한 목표는 영어와 같은 자연어로 컴퓨터와 의사소통할 수 있게 하는 것이었다. 일찍이 다니엘 보로우(Daniel Bobrow)의 STUDENT라는 프로그램은 고등학교 수준의 대수학 단어 문제를 푸는 성공을 보였다. '의미 망'은 개념을 다른 개념들 사이의 노드와 링크 관계로 나타낸다. 의미 망을 사용하는 첫 번째 AI 프로그램은 로스 퀄리언(Ross Quillian)이 작성했고 가장 성공이며 동시에 논쟁이 많았던 버전은 로거 섕크(Roger Schank)의 \"개념 종속 이론(Conceptual dependency theory)\"이다. 조셉 웨이젠바움(Joseph Weizenbaum)의 ELIZA는 사람들이 그들이 대화를 나누는 때때로 상대가 컴퓨터가 아니라 사람이라고 생각할 정도의 질로 대화했다. 사실, ELIZA는 스스로 생각하여 말하지 않았다. 그 프로그램은 오직 판에 박힌 말을 하거나, 상대에게 방금 말한 말을 다시 해 달라고 요청하거나, 상대가 한 말을 몇 개의 문법 법칙에 의해 파싱 할 뿐이었다. ELIZA는 첫 번째 채팅 프로그램이 되었다.\n",
    "마이크로월드\n",
    "1960년대 후반에, MIT의 AI 연구소에 있던 마빈 민스키와 시모어 페퍼트는 마이크로월드 연구로 불리는, 인위적인 간단한 상황에 초점을 맞춘 AI 연구를 제안했다. 그들은 성공적인 과학자들이 자주 쉬운 이해를 위해 '마찰면'이라든지 '강체(물리학에서 결코 형태가 변하지 않는 물체)'같은 간단한 모델을 사용한다는 것에 집중했다. 이런 연구의 대부분이 평평한 평면 위의 다양한 형태와 색깔의 블록으로 이루어진 '블록 단위의 세계'에 초점을 맞추는 형식이었다.\n",
    "제럴드 서스먼(Gerald Sussman)을 필두로 아돌포 구스만(Adolfo Guzman), 데이비드 월츠(David Waltz) 그리고 패트릭 윈스턴(Patrick Winston)이 마이크로월드 패러다임으로 기계 비전의 혁신을 이끌었다. 같은 시간에, 민스키와 페퍼는 블록을 쌓을 수 있는 로봇 팔을 제작했다. 마이크로월드의 영광스러운 성취는 테리 위노가드(Terry Winograd)의 SHRDLU이며, 이것은 보통의 일반 문장으로 소통해 작업을 계획하고 이를 실행할 수 있었다.\n",
    "낙관론\n",
    "AI 연구의 첫 번째 세대는 그들의 연구 결과에 대해 다음과 같이 예측했다.\n",
    "- 1958년, 사이먼(H. A. Simon)과 뉴얼(Allen Newell) : \"10년 내에 디지털 컴퓨터가 체스 세계 챔피언을 이길 것이다\", 덧붙여 \"10년 내에 디지털 컴퓨터는 중요한 새로운 수학적 정리를 발견하고 증명할 것이다\"라고 말했다.\n",
    "- 1965년, 사이먼 : \"20년 내에 기계가 사람이 할 수 있는 모든 일을 할 것이다.\"\n",
    "- 1967년, 마빈 민스키 : \"이번 세기에 AI를 만드는 문제는 거의 해결 될 것이다.\"\n",
    "- 1970년, 마빈 민스키 : (Life 잡지를 통해서) \"3~8년안에 우리는 평균정도의 인간 지능을 가지는 기계를 가지게 될 것입니다.\"\n",
    "자금\n",
    "1963년 6월, MIT는 220만 달러를 고등 연구 계획국(Advanced Research Projects Agency - 후에 DARPA로 알려짐)에게 제공받았다. 자금은 민스키와 매카시가 5년전 설립한 \"AI 그룹\"이 포섭한 프로젝트 MAC에서 사용되었다. DARPA는 계속해서 매년 300만 달러를 70년대까지 제공했다. DARPA는 또한 유사한 자금을 뉴얼과 사이먼의 CMU 프로그램과 스탠포드 AI 프로젝트에 제공했다. 또다른 중요한 AI 연구소는 1965년 도널드 미치(Donald Michie)가 에든버러 대학교에 세웠다. 이 4개의 시설은 계속해서 많은 연도에 걸쳐 학계의 주요한 AI연구소, 그리고 자금처로 존재할 것이다. 자금은 몇가지 단서와 함께 제공됐다 : ARPA의 기획자 리클리더(J. C. R. Licklider)는 그의 조직은 \"프로젝트가 아니라, 사람에게 투자\"해야 한다고 믿었고, 연구자들이 어떤 방향이든 그들의 관심있는 쪽을 연구하도록 허용했다. 이것은 MIT에 자유분방한 분위기를 생성했고 해킹 문화를 탄생시키기도 했다. 그러나 이렇게 손을 떼고 지켜보는 형식의 지원은 얼마 지속되지 못했다.\n",
    "                        \n",
    "AI의 첫번째 암흑기(1974-1980)\n",
    "\n",
    "70년대에 이르자, AI는 비판의 대상이 되었고 재정적 위기가 닥쳤다. AI 연구가들은 그들의 눈앞에 있는 복잡한 문제를 해결하는데 실패했다. 연구가들의 엄청난 낙관론은 연구에 대한 기대를 매우 높여놓았고, 그들이 약속했던 결과를 보여주지 못하자, AI에 대한 자금 투자는 사라져버렸다. 동시에, Connectionism 또는 뉴럴망은 지난 10년동안 마빈 민스키의 퍼셉트론(시각과 뇌의 기능을 모델화한 학습 기계)에 대한 파괴적인 비판에 의해 완전히 중지되었다. 그러나 70년대 후반의 AI에 대한 좋지 않은 대중의 인식에도 불구하고, 논리 프로그래밍, 상징 추론과 많은 여러 영역에서의 새로운 아이디어가 나타났다.\n",
    "\n",
    "문제\n",
    "1970년대 초, AI 프로그램의 가능성은 제한적이었다. 모든 문제에 걸쳐서 문제를 푸는 인상 깊은 작품들은 겨우 시험용 버전 정도였고, 어떤 의미에선 '장난감'에 가까웠다. AI 연구는 70년대에 더 이상 극복할 수 없는 몇개의 근본적인 한계를 가지게 됐다.몇개의 한계를 통해 십여년 후에 극복되었고, 다른 몇 개는 오늘날까지 남아있다.\n",
    "- 컴퓨터 능력의 한계 : 정말 유용한 무언가를 이루기에는 메모리 또는 처리 속도가 충분하지 않았다. 예를 들어 로스 퀼리언(Ross Quillian)의 자연어 처리에서 성공적인 완수는 오직 20개의 단어 위에서 발휘되었는데, 이것은 메모리가 꽉 찼기 때문이었다. ++한스 모라벡은 1976년에 컴퓨터가 지능을 가지기엔 여전히 수백만 배 약하다고 논증했다. 그는 비유를 들었는데, AI가 컴퓨터 능력을 필요로 하는 것은 항공기가 마력을 필요로 하는 것과 같다는 것이었다. 컴퓨터 영상에 대해서, 모라벡은 간단하게 계산하여 실시간으로 사람의 망막을 모션 캡처하려면 범용 컴퓨터가 초당 10^9 명령어(1000MIPS)를 처리해야 할 것이라고 추측했다. 2011년경 실용적인 컴퓨터 영상 프로그램은 10,000~1,000,000 MIPS를 요구한다. 1976년경 5백만에서 8백만 달러사이에 판매되던 가장 빠른 슈퍼컴퓨터인 Cray-1은 오직 80~130 MIPS였고, 당시 전형적인 데스크탑 컴퓨터는 겨우 1 MIPS 남짓이었다. \n",
    "- 폭발적인 조합 수와 비용이성 : 1972년에 리차트 카프(Hichard Karp)는 문제 해결에 지수적 시간이 요구되는 많은 문제를 보여주었다. 하찮은 문제일지라도 이런 문제의 최적의 해답을 찾는 데 상상할 수도 없는 컴퓨터의 시간이 요구되었다. 즉 지금까지 AI '장난감'에서 사용되었던 방법은 실제적으로 유용한 AI 시스템을 제작하는 데 용이하지 못했다.\n",
    "- 상징적 지식과 추론 : 영상 처리나 자연어 처리 같은 많은 중요한 AI 프로그램은 실제 세상에 대한 간단하지만 어마어마한 양의 정보를 필요로 한다. 그래야 프로그램이 자신이 보고 있는 것이 무엇인지, 또는 자신이 듣고 있는 것이 무엇인지 아이디어를 찾을 수 있기 때문이다. 이 요구는 아기들의 세상에 대해 알아나가는 것과 유사하다. 연구가들은 곧 요구되는 정보의 양이 엄청나게 광대하다는 것을 발견했다. 1970년대의 누구도 이런 데이터가 포함된 데이터베이스를 만들지 못했고, 누구도 이런 데이터를 프로그램 혼자 터득하는 방법을 알지 못했다.\n",
    "- 모라벡의 패러독스 : 이론을 제작하고 기하학적 문제를 해결하는 것은 컴퓨터에게 비교적 쉽지만, 얼굴을 인식하거나 장애물을 피해 방을 가로지르는 것은 엄청나게 어렵다. 이 설명은 왜 연구가들이 1970년대에 영상처리나 로봇에 대해 조금밖에 진전을 보이지 못했는지 아는 데 도움이 된다.\n",
    "- 프레임 문제, 자격 문제 : 존 맥캐시와 같은 연구가들은 규칙이 규칙 스스로의 구조를 변경하지 못하면 관련 계획 또는 기본 추론 일반 공제를 나타낼 수 없다는 것을 발견했다.\n",
    "자금 지원의 중단\n",
    "영국 정보나 DARPA, NRC같은 AI 연구자들에게 자금을 주던 기관들은 연구 진행의 부진에 실망했고 결국 AI에 관한 방향성을 가진 자금 지원을 끊었다. 1966년 기계를 이용한 번역을 비판하는 보고서가 ALPAC에 제출되었을 때부터 이런 흐름이 시작되었다. 총 2천만 달러를 지원한 NRC도 지원을 멈췄다. 1973년 라이트힐 보고서는 \"장대한 목표(grandios objectives)\"를 성취하는 데 실패한 영국의 AI 연구의 상태에 대해 비난했고 결국 영국의 AI 연구소는 해체되었다(보고서는 특히 AI 연구의 실패의 원인이 폭발적인 조합의 수라고 언급했다). DARPA는 CMU의 음성을 이해하는 연구의 연구자들에게 심하게 실망했고 연간 3백만 달러의 지원을 취소했다. 1974년에 이르자 AI 연구에대한 투자는 찾기 어려워졌다. 한스 모라벡은 그의 동료의 비현실적인 예측에 의한 위기를 비난했다. \"많은 연구가들이 많은 연구자는 과장을 증가시키는 웹에 휘말렸다.\" 그러나 여기엔 다른 이슈가 있다 : 1969년 맨스필드의 수정안의 통과이후, DARPA는 자금 지원에 대해 \"비직접적인 기초 연구보다, 임무 완수에 직결된 연구\"를 수행하라는 증가하는 압력을 받고 있었다. 창조성 높은 지원, 자유분방한 연구는 1960년대와 함께 떠났고 DARPA에서 다시 오지 않을 것이다. 대신, 자금은 자동조정 탱크나 전투 관리 시스템과 같은 분명한 프로젝트와 명확한 목표를 향할 것이다.\n",
    "캠퍼스 전역의 비판들\n",
    "몇 철학자들은 AI 연구가들에게 강력한 반대를 표했다. 초기 반대자들 중 괴델의 불완전성의 원리에 의해 컴퓨터 프로그램같은 시스템이 실제적으로 정확하게 사람과 같이 행할 수 없다고 주장한 사람은 존 루커스(John Lucas)이다. 휴버트 드라이퍼스는 60년대의 깨어진 약속을 조롱했고 AI의 가정을 비판했으며, 인간의 추론이 실제적으론 \"상징적 진행\"이 매우 적게 포함되어 있고 구현적, 본능적, 무의식적인 노하우에 의해 처리된다고 주장했다. 존 설의 1980년대 제시된 중국인 방 문제는, 실제로 프로그램이 상징들을 '이해'할 수 없고 사용할 수 없음을 보여주려고 시도했다. 설은 만약 상징이 기계에게 아무 의미가 못된다면, 기계는 생각하는 것이 아니라고 주장했다. 이 비난은 AI 연구가들에게 심각하게 작용하지 못했다. 비용이성과 상식적 지식에 관한 문제가 훨씬 더 즉각적이고 심각한 듯이 보였다. '노하우'와 '지향성'이 실제 프로그램을 만드는데 어떻게 다른지가 불분명했다. 민스키는 드라이퍼스와 설을 향해 \"그들은 오해했고, 무시될 것이다\"라고 했다. MIT에서 가르쳤던 드라이퍼스는 냉대받았다 : 그는 나중에 AI 연구가들에게 \"나와 점심 식사할 용기도 없다\"라고 평했다. ELIZA의 제작자 조셉 웨이즌바움(Joseph Weizenbaum)은 그의 동료인 드라이퍼스가 전문적이지 않고 유치한 대우를 한다고 느꼈다. 웨이즌바움은 케네스 콜비(Kenneth Colby)가 쓴 DOCTOR와 임상치료 채팅봇에 대해서 심각하게 의심하기 시작했다. 웨이즌바움은 콜비가 그의 무심한 프로그램을 진지한 치료 도구로 여기는 걸 방해했다. 이 불화가 시작되고, 이 상황은 콜비가 웨이즌바움을 프로그램에 대한 공로로 인정하지 않았을 때 도움이 되지 않았다. 1976년에 웨이즌바움은 컴퓨터 능력과 인간 추론(Computer Power and Human Reason)을 출판하며 인공 지능의 오용이 인간의 삶을 평가 절하시킬 수도 있다고 주장했다.\n",
    "퍼셉트론과 연결망의 어두운 시대\n",
    "뉴럴 네트워크 형태의 퍼셉트론이 1958년 마빈 민스키의 고등학교 시절 친구였던 프랭크 로센블랫(Frank Rosenblatt)에 의해 도입되었다. 다른 AI 연구가들이 그러하듯, 그는 낙관론을 펼쳤고, \"퍼셉트론은 결국 학습을 하고, 의사 결정을 하고, 언어 번역을 할 것이다\"라고 예견했다. 60년대를 이끌던 패러다임 속의 연구 프로그램의 수행은 1969년 민스키와 페퍼의 책 퍼셉트론의 출판과 함께 갑자기 중지되었다. 이것은 퍼셉트론이할 수 있는 일에 몇가지 심각한 제한이 있음을, 또 프랭크의 예견은 심하게 과장되어있음을 알렸다. 이 책의 파급력은 압도적이었다 : 향후 10년 동안 뉴럴 네트워크에 대한 거의 모든 연구가 중지되었다. 결국, 뉴럴 네트워크 영역을 회복할 연구원의 새로운 세대가 그 후에 인공지능의 중요하고 유용한 부분을 내놓았다. 로센블랫은 이 책을 보지 못했는데, 그는 문제의 책이 출판 되고 곧바로 보트 사고와 함께 사망했기 때문이다.\n",
    "깔끔이 : 논리, 프롤로그와 전문가 시스템\n",
    "논리적 추론은 1958년 초에 AI 연구에서 존 매카시가 제안하여 도입되었다. 1963년 알렌 로빈슨(J. Alan Robinson)은 간단하게 추론을 컴퓨터에 구현시키는 분해와 통일 알고리즘을 발견했다. 그러나 매카시와 그의 학생들이 60년대 후반에 했던 것과 같은 복잡하지 않은 구현은 본질적으로 다루기 힘들었는데, 간단한 정리를 증명하기 위해 천문학적 단계가 필요했다. 더 성공적인 결실을 맺는 논리적 접근은 70년대 에딘벌 대학의 로버트 코왈스키(Robert Kowalski)가 개발했고 곧 프랑스의 연구가인 알라인 콜메루엘(Alain Colmerauer)과 성공적인 논리 프로그래밍 언어인 프롤로그를 만든 필립 오우셀(Philippe Roussel)과의 협업을 이끌어냈다. 프롤로그는 다루기 쉬운 계산을 허용하는 논리의 부분을 사용한다. 규칙은 계속적으로 영향을 미쳤고, 에드워트 페이젠바움(Edward Feigenbaum)이 기대하던 시스템 기초를 제공했으며 알렌 뉴엘과 허버트가 계속 연구하도록 만들었다. 사이먼은 Soar과 인식에서의 통일 이론을 이끌었다. 논리적으로의 접근을 비판하는 지적은, 드라이퍼스가 했던데로, 사람이 문제를 해결할 때 논리를 거의 사용하지 않는다는 것이었다. 피터 왓슨(Peter Waon), 엘리너 로시, 아모스 트버스키, 대니얼 카너먼을 비롯한 심리학자들이 이를 증명했다. 매카시는 이에 대해서 이 증명이 무관하다고 답했다. 그는 정말 필요한 기계란 사람처럼 생각하는 것이 아니라 문제를 해결할 줄 아는 기계라고 일축했다.\n",
    "지저분이 : 프레임과 스크립트\n",
    "매카시의 접근에 대한 비평가들의 대다수가 그의 동료인 MIT 소속이었다. 마빈 민스키와 사무엘 페퍼와 로저 샹크는 기계를 사람처럼 느껴지도록 만드는 \"이야기 이해\"와 \"물체 인식\"의 문제를 해결하려고 노력했다. \"의자\"나 \"음식점\" 같은 일반적인 개념을 사용할 때 사람들은 모두 비논리적으로, 사람들이 통용하는 범용적 가정을 함께 했다. 불행하게도 이런 부정확한 가정들은 논리적 절차로 대표하기가 힘들었다. 제럴드 서스먼(Gerald Sussman)은 \"본질적으로 부정확한 개념을 설명하기위 해 정확한 언어를 사용하는 순간 그들은 더 이상 부정확하다고 말할 수 없다\"라고 표했다. 또한 섕크는 이에 대해 \"비논리적\" 접근 즉 \"지저분이\"가 매카시, 코와스키, 페이젠바움의 \"깔끔이\" 패러다임과 반대에 있다고 평했다.\n",
    "1975년 세미나 보고서에서, 민스키는 \"지저분한\" 많은 그의 동료 연구자들이 무언가에 대한 우리의 모든 상식적 가정을 포착하는 프레임워크를 도구로 사용했다고 적었다. 예를 들어 우리가 새라는 개념을 생각할때, 즉시 '난다', '벌레를 먹는다'와 같은 다양한 사실들 또한 떠올린다. 떠올린 것들이 항상 사실은 아니고 또 \"논리적\"으로 이것들이 공제가 되지는 않는다. 그러나 이런 가정들의 구조는 우리가 말하고 생각하는 문장의 부분을 차지한다. 그는 이 구조를 \"프레임\"이라 칭했다. 섕크는 프레임의 설명에 대해서 영어로된 짧은 스토리에 대한 답변을 성공적으로 하기 위한 \"스크립트\"라 불렀다. 수년 후 객체지향 프로그래밍에서 AI 연구에서 쓰였던 프레임에서 나온 '상속'이라는 개념을 채택하게 된다.\n",
    "\n",
    "AI붐 (1980-1987)\n",
    "\n",
    "1980년대에는 전 세계적으로 사용된 ‘전문가 시스템’이라고 일컫는 인공지능 프로그램의 형태였고 인공지능 검색에 초점이 맞춰졌다. 같은 시기에 일본 정부는 자신들의 5세대 컴퓨터 프로젝트와 인공지능에 적극적으로 투자하였다. 1980년대에 존 홉필드와 데이비드 루멜하트의 신경망 이론의 복원이라는 또 다른 사건이 있었다.\n",
    "                        \n",
    "전문가 시스템의 발전\n",
    "전문가 시스템은 특정 지식의 범위에 대해 문제를 해결해주거나 질문에 대답해주는 프로그램이며 전문가의 지식에서 파생 된 논리적 법칙을 사용하였다. 최초의 실험은 1965년 Edward Feigenbaum과 레더버그에 의해 Dendral이 시작하였고 이것은 분광계로부터 화합물을 식별하는 실험이었다. MYCIN은 1972년에 개발되었고 전염되는 혈액 질환을 진단하였다. 이러한 접근법(실험)은 타당성이 입증되었다.\n",
    "전문가 시스템은 소규모의 지식 영역에 대해서는 스스로 제한을 둠으로써 상식 문제를 피하였다. 그리고 그들의 단순한 디자인은 프로그램을 만드는 것을 상대적으로 쉽게 하였다. 모든 프로그램은 유용성이 입증되어야 하지만 AI는 이 점을 달성할 수 없었다.\n",
    "1980년, XCON이라 불리는 전문가 시스템은 디지털 장비 회사인 CMU에서 완성되었다. 이 시스템은 매년 4천만 달러를 절약시켜주며 매우 큰 성과를 나타냈다. 전 세계의 회사들은 1985년에 1억 달러 이상을 AI에 사용하여 이를 개발하고 전문가 시스템을 배포하였다. Symbolics, Lisp Machines과 같은 하드웨어 회사와 IntelliCorp, Aion 등의 소프트웨어 회사들이 이를 지원하면서 같이 성장하였다.\n",
    "지식 혁명\n",
    "전문가 지식들을 포함하면서 전문가 시스템의 힘은 두각을 나타내었다. 이것은 1970년대 내내 연구하였던 AI 연구 기법의 새로운 방향 중 일부분이었다. “AI 과학자들은 지능이란 것이 다른 방법들로 많은 양의 다양한 지식들을 사용하는 능력에 기반한 것이라고 의심하기 시작했다.” 지식 기반 시스템과 지식 엔지니어링은 1980년대 AI 연구자들의 메인 포커스가 되었다.\n",
    "또한 1980년대에는 일반인들이 모두 알 만한 일상적인 사실들을 모두 포함한 아주 거대한 데이터베이스를 만들어 상식 문제에 대한 직접적 해결을 시도한 Cyc의 탄생을 볼 수 있었다. 이 프로젝트를 이끈 Douglas Lenat는 지름길은 없다고 말했다. - 기계가 인간의 개념을 알게 하기 위한 단 한 가지 길은 그들을 가르치는 것이다. 이 프로젝트는 수 십 년 동안 완료될 것이라 생각되지 않았다.\n",
    "돈은 되돌아온다 : 5세대 프로젝트\n",
    "1981년, 일본의 국제 무역과 산업 부서는 5세대 컴퓨터 프로젝트를 위해 8억 5천만 달러를 확보해 두었다. 그들의 목적은 기계가 사람처럼 프로그램을 작성하고 대화를 수행할 수 있는 시스템과 언어를 번역하거나 그림을 해석하는 것이었다. 그들은 프로젝트를 위해 기본 컴퓨터 언어로 Prolog를 선택하였다.\n",
    "다른 나라들은 그들만의 고유한 프로그램을 개발하였다. UK는 3억 5천만 달러를 들여 Alvey 프로젝트를 시작했다. 미국 회사들의 컨소시엄은 정보기술과 AI안의 거대한 프로젝트를 투자받기 위해 마이크로 전자공학과 컴퓨터 기술 협력이라는 형태를 취했다.또한 1984에서 1988년 사이에 DARPA는 전략적 컴퓨팅 계획을 설립하고 AI에 대한 투자를 세배로 늘렸다.\n",
    "신경망 이론의 복귀\n",
    "1982년 , 물리학자 John Hopfield는 (현재 ‘Hopfield net’이라고 불리는) 완벽한 새로운 길에서 정보를 프로세스하고 배울 수 있는 신경망의 형태를 증명해냈다. 이 시기에, David Rumelhart는 (Paul Werbos에 의해 발견된) “역전파”라고 불리는 신경망을 개선하기 위한 새로운 방법을 알리고 있었다. 이러한 두 가지 발견은 1970년 이후 버려진 신경망 이론이라는 분야를 복구시켰다. 새로운 분야는 1986년 분산 병렬처리의 형태로부터 영감을 받았고 이와 같은 형태로 통일되었다. 2권 분량의 논문 집합은 Rumelhart와 물리학자인 James McClelland에 의해 편집되었다. 신경망은 1990년대에 광학 문자 인식 및 음성 인식과 같은 프로그램의 구동 엔진으로 사용되며 상업적으로 성공했다.\n",
    "                        \n",
    "AI의 두번째 암흑기 1987-1993\n",
    "    \n",
    "AI와 비즈니스 커뮤니티의 매력은 상실했고 경제 거품이라는 고전적 형태의 1980년대에 빠졌다. 붕괴는 정부기관과 투자자들의 ‘해당 분야는 계속해서 비판에도 불구하고 진보해왔다.’는 인식에 비롯된 것이었다. 로봇 공학 분야에 관련 된 연구원인 Rodney Brooks 와 Hans Moravec는 인공지능에 대한 완전히 새로운 접근 방식을 주장하였다.\n",
    "        \n",
    "인공지능의 겨울\n",
    "1974년에 전문가 시스템에 대한 열정이 통제할 수 없을 정도로 퍼져나가고 이에 대한 실망이 확실히 따라올 것이라는 걱정이 있었고 이 때 투자가 끊기고 살아남은 연구원들에 의해서 “AI winter”이라는 단어가 만들어졌다. 그들의 두려움은 AI에 대해 일련의 재정적 차질이 있었던 1980년 말에서 1990년대 초반에 잘 나타난다. 이 AI winter 기간의 첫 번째 사건은 1987년에 특성화된 AI 하드웨어 시장이 갑자기 무너진 것이다. 1987년에 애플이나 IBM의 데스크탑 컴퓨터들은 급격히 빨라지고 성능이 좋아졌다. 또한 Symblics과 기타 회사들이 만든 데스크탑 컴퓨터 보다 더 비싼 Lisp 기기들보다도 더욱 좋은 성능을 나타냈다. 즉, 더 이상 Lisp 기기들을 살 이유가 사라진 것이다. 전체산업 1억 달러의 절반의 가치가 하룻밤에 사라졌다. 결국 최초의 성공한 전문가 시스템인 XCON은 유지하기에 너무 비싸다는 것이 증명되었다. 업데이트하기에도 너무 어려웠고 학습도 되지 않았다. 이 전문가 시스템은 또한 일반적이지 않은 질문을 했을 때 괴상한 행동을 하는 일명 \"brittle\" 이었고 그들은 일찍이 발견된 이러한 문제들에 의해 결국 희생되었다. 전문가 시스템은 특별한 경우에서만 유용할 뿐이었다. 1980년대 후반, Strategic Computing initiative는 AI의 투자를 자르는 데 공이 컸다. DARPA의 새로운 리더쉽은 AI는 이 다음의 파도가 아니라고 결정했고 즉각적인 결과를 나타낼 수 있는 것으로 보이는 프로젝트에 직접적인 투자를 하는 방향으로 결정했다. 1991년에는 1981년에 일본에서 5세대 프로젝트의 목표 리스트에 적은 것만큼 성과가 나오지 않았다. 실제로 대화를 계속 이어나가는 것과 같은 어떤 것들은 2010년까지 달성되지 않았다. 다른 인공 지능 프로젝트와 마찬가지로, 실제 가능했던 것보다 기대가 훨씬 컸다.\n",
    "몸통을 갖는 것의 중요성: Nouvellle AI and embodied reason\n",
    "1980년대 후반 , 몇몇 연구원들이 로봇 공학을 기반으로 인공 지능에 완전히 새로운 접근법에 대해 찬성하였다. 그들은 실제 지능을 보여주려면 기계에도 몸통이 필요하다고 믿었다. - 기계 또한 이 세상에서 인식하고, 이동하고, 살아남고 거래할 줄 알 필요가 있다. 그들은 이런 감각 운동 기술은 상식적인 추론과 같은 더 높은 단계의 기술이 필요하다고 말했고 실제로 추상적인 추론은 인간의 가장 흥미롭거나 중요한 기술이다. 그들은 지능을 바닥에서부터 지어야 한다고 내세웠다. 인공 두뇌와 제어 이론에서부터 얻은 접근법은 1960년대까지 인기가 없었다. 또 다른 선구자인 David Marr는 신경 과학 이론으로 한 그룹의 비전을 이끌어 성공적인 배경으로 1970년대에 MIT에 들어왔다. 그는 모든 상식적인 접근법(McCarthy's logic and Minsky's frames)을 거절했고 AI는 시각에 대한 육체적인 기계장치를 심볼릭 프로세싱 하기 전에 가장 바닥에서부터 위로 이해할 필요가 있다고 말했다.\n",
    "1990년에 Elephants Don't Play Chess 논문에서, 로봇 공학 연구자인 Rodney Brooks는 직접적으로 물리적 심볼 시스템 가설에 초점을 맞추었고 심볼들은 항상 필요한 것은 아니라고 말했다. “세계는 그 자체만으로 가장 훌륭한 모델이다. 이것은 항상 최신이며 모든 세부사항이 존재한다. 비결은 적절히 그리고 충분히 자주 감지하는 것이다.80년대와 90년대에 많은 cognitive 과학자들은 또한 사고방식의 심볼 처리 모델을 거절하고 추론에 몸통은 필수적이라고 말했고 이러한 이론을 embodied mind 이론이라고 불렀다.\n",
    "                        \n",
    "AI 1993-현재\n",
    "                        \n",
    "지금보다 반세기는 더 오래된 AI의 분야는 마침내 가장 오래된 목표 중 몇 가지를 달성했다. 이것은 비록 뒷받침해주는 역할이었지만 기술 산업에 걸쳐 성공적으로 사용되었다. 몇 가지 성공은 컴퓨터의 성능이 증가했기 때문이고 또 다른 몇 가지는 고립된 문제들에 대해 집중하였고 높은 과학적 의무감으로 해 나갔기 때문에 해결되었다. 적어도 비즈니스 분야에서의 AI의 평판은 여전히 처음 같지 않다. 이 분야 내에서는 1960년대 세계의 상상이던 인간 수준의 지능의 꿈을 실현하는 것이 실패로 돌아갔다는 이유로 몇 가지 합의를 하였다. 하위 파트에서 AI의 일부분을 도와주던 모든 요소들은 특정 문제나 접근 방식에 초점이 맞추어졌다. 그 후, AI는 여태 해왔던 것보다 더욱 신중해졌고 더욱 성공적이였다. 또한 보안이 중요한 이슈로 떠올랐다. 인공지능의 보안이슈로는 학습된 인공지능을 속일 수 있는 공격형태인 Poisoning Attack, Evasion Attack, 인공지능 모델 자체를 탈취할 수 있는 Model Extraction Attack, 학습된 모델에서 데이터를 추출해내는 Inversion Attack 등이 있다.\n",
    "                        \n",
    "성공 사례와 무어의 법칙\n",
    "1997년 5월 11일, 딥 블루는 당시 체스 세계 챔피언이던 가리 카스파로프를 이긴 최초의 체스 플레이 컴퓨터가 되었다. 2005년 스탠퍼드의 로봇은 DARPA 그랜드 챌린지에서 연습해 보지 않은 사막 도로 131마일을 자동으로 운전하여 우승하였다. 2년 뒤, CMU의 한 팀은 DARPA 도시 챌린지에서 모든 교통 법규를 지키고 교통 혼잡 속에서 자동으로 55 마일의 길을 찾았다. 2011년 2월, 퀴즈 쇼 Jeopardy!에 출전한 IBM의 응답 시스템 왓슨은 상당히 여유롭게 두 챔피언을 이겼다.\n",
    "이러한 성공은 혁신적인 새로운 패러다임 때문이 아니라 번거로운 엔지니어 스킬과 매우 뛰어난 성능을 가진 오늘날의 컴퓨터에서 비롯된 것이다.실제로, Deep Blue의 컴퓨터는 1951년 Christopher가 체스 하는 법을 가르친 마크 1보다 1천만 배 빨랐다. 이 엄청난 증가는 무어의 법칙에 의해 측정되는데 이것은 2년마다 컴퓨터의 메모리 속도와 양은 두 배씩 늘어난다는 이론이다. 최초 컴퓨터 성능의 근본적인 문제는 느리지만 서서히 극복되고 있었다.\n",
    "지능형 에이전트\n",
    "1990년대 동안에는 ‘지능형 에이전트’라고 불리는 새로운 패러다임이 다 방면에서 수용되고 있었다. 비록 이전의 연구자들은 'divide and conquer' 모듈러를 제안하고 AI에 접근하였지만 지능형 에이전트는 Judea Pearl, Allen Newell 등 다른 이들이 AI를 연구하는데 있어서 결정론과 경제성이라는 개념을 가져오기 전까지 현대식 형태를 갖추지 못했다. 경제학자들의 합리적 에이전트라는 정의와 컴퓨터 과학자들의 객체 혹은 모듈러 정의가 합쳐졌을 때 지능형 에이전트의 패러다임이 완성되었다.\n",
    "지능형 에이전트 시스템은 환경을 인식하고 성공을 가장 극대화할 수 있는 행동을 취한다. 이러한 정의에 의하면 인간과 인간의 조직처럼, 예를 들어 회사처럼 특정 문제를 해결하는 간단한 프로그램을 지능형 에이전트라고 한다. 지능형 에이전트는 AI 연구자를 “the study of intelligent agents\"로 정의한다. 이것은 AI의 정의의 일부를 일반화한 것이다. 이것은 인간의 지능을 넘어 모든 종류의 지능의 연구를 추구한다.\n",
    "이러한 패러다임은 당시 연구자들이 고립 문제에 대해 연구하고 다양하고 유용한 해결법을 찾도록 해주었다. 또한 서로서로 문제와 해결책을 공통의 언어로 표현하였고 추상적 에이전트를 사용한 경제학이나 제어 이론 등과 같은 다른 개념에도 사용되었다. 어떤 연구자들은 지능형 에이전트의 상호 작용에서 더 다양하고 지능적인 시스템을 만들기로 하였고 완전한 에이전트 아키텍처가 되기를 바랐다. 이것이 21세기의 보편적인 교과서들이 인공 지능을 정의하는 방식이다.\n",
    "깔끔함의 승리\n",
    "AI 연구자는 과거에 사용했던 것보다 더욱 정교한 수학적 도구를 사용하여 개발하기 시작했다. 해결하는 데 AI가 필요한 수많은 문제들이 존재하고 있다는 인식은 수학, 경제학 또는 오퍼레이션 연구 등의 분야에서 이미 연구자들이 AI를 사용하여 실현하고 있었다. 공유된 수학적 언어는 높은 수준의 협력, 좋은 평판, 여러 분야를 성공적으로 이끌고 측정과 증명이 된 결과들의 성취를 가능하게 하였다. AI는 더 엄격한 과학 학문이 되었다.\n",
    "이는 혁명 그 자체였으며 \"깔끔함\"의 승리였다.Judea Pearl의 매우 영향이 큰 1988년 책은 AI에 결정론과 확률을 대입시켰다. 사용 중인 많은 새로운 도구(Bayesian networks, hidden Markov models, information theory, stochastic modeling)와 기존의 고전적이 방법들이 최적화되었다. 더 정밀한 수학적 모형이 신경망 네트워크와 진화 알고리즘과 같은 연산 지능적 패러다임을 위해 개발되었다.\n",
    "조용한 발전\n",
    "AI 연구자들에 의해 최초로 개발된 알고리즘은 거대한 시스템의 일부로 나타나기 시작했다. AI는 매우 어려운 문제들을 해결했고 데이터 마이닝, 산업 로봇공학, 논리학, 음성 인식, 은행 소프트웨어,의학적 진단, 구글 검색 엔진 등 여러 기술들은 기술 산업에 매우 유용하다는 것이 증명되었다.\n",
    "AI 분야는 이러한 성공에 대해 매우 낮은 신뢰를 받았다. AI의 훌륭한 혁신 중 대부분은 컴퓨터 과학의 도구에서 또 다른 기능으로 세분화되었다.Nick Bostrom은 \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"라고 말했다.1990년대 AI 분야의 많은 연구자들이 고의로 자신의 프로젝트를 다른 이름으로 불렀다. 일부 이러한 현상은 그들의 분야가 AI와 근본적으로 다르다고 여겼기 때문이거나 또는 새로운 이름이 투자받기 쉬웠기 때문일 것이라고 한다. 적어도 상업 분야에서는 연구자에 대해 AI winter에 있었던 실패했던 계약이 꼬리표처럼 따라다녔고 2005년에 뉴욕 타임즈에서는 “컴퓨터과학과 소프트웨어 엔지니어들은 광기에 싸인 몽상가처럼 보일 두려움 때문에 인공 지능이란 용어를 피했다.” 라고 소개되었다.\n",
    "HAL 9000은 어디에 있는가?\n",
    "1968년 아서 C. 클라크와 스탠리 큐브릭은 2001년에는 기계가 인간과 유사하거나 또는 인간의 용량을 뛰어넘는 지능을 가진 존재가 되었을 것이라고 상상하며 《2001: 스페이스 오디세이》라는 SF 작품을 완성했다. 여기에 등장하는 HAL 9000이라는 캐릭터는 2001년에 이러한 기계가 존재할 거라고 믿는 많은 AI 연구자들의 공유된 믿음을 기반으로 만들어졌다.\n",
    "훗날 마빈 민스키는 “그래서 왜 우린 2001년에 HAL을 얻지 못했나?”라는 질문을 하였다.대부분의 연구자들이 신경망이나 유전자 알고리즘의 상업적 용도의 프로그램을 추구했던 반면, 민스키는 해답이 방치된 상식 추론과 같이 매우 중심적인 문제에 있다고 믿었다. 반면에 존 매카시는 여전히 자격문제를 비난하였다. 레이 커즈와일은 문제는 컴퓨터 성능에 있으며 무어의 법칙을 사용하였을 때 인간 수준의 지능을 가진 기계는 약 2029년에 나올 것이라고 예견하였다. 제프 호킨스(Jeff Hawkins)는 신경망 연구자들이 대뇌 피질의 본질적인 성질을 무시하고 간단한 문제들을 성공적으로 해결하는 간단한 모델을 추구했다고 말했다. 또한 각각에 대해 많은 설명들이 있으며 이를 대응하는 진행 중인 연구 프로그램들이 있다.\n",
    "인공지능과 4차 산업혁명\n",
    "세계는 이미 4차 산업혁명에 진입했으며 인공지능은 빠르게 인간을 대체해 나갈 것이다. 또, 널리 퍼져 있지 않을 뿐 미래는 이미 와 있으며 인공지능, IoT, 클라우드 컴퓨팅, 빅데이터 등이 융합되면서 4차 산업혁명이 발생하고 있다. 과거 산업혁명이 ‘기계근육’을 만드는 과정이었다면 4차 혁명에서는 ‘기계두뇌’가 탄생할 것이다.\n",
    "제1차 산업혁명 발생시, 산업 기계에 의해 일자리를 잃을 것이 두려웠던 노동자들이 러다이트(기계파괴운동)를 일으켰다. 이와 유사하게, 인공 지능에 의한 4차 산업혁명으로, 많은 사람들이 미래에 일자리를 잃을 것을 우려하고 있다. 한 온라인 설문조사에 따르면, 응답자의 70.1%가 미래에 인공지능에 의해 인간의 직업이 줄어들 것이라고 예상했다.\n",
    "실험적인 AI 연구\n",
    "인공지능은 1959년에 MIT AI연구소를 설립한 매카시와 마빈 민스키, 카네기멜론 대학교에 인공지능 연구소를 만든 앨런 뉴웰과 허버트 사이먼과 같은 개척자들에 의해 1950년도에 실험 학문으로 시작되었다. 이들 모두는 1956년에 매카시, 민스키, IBM의 나단 로체스터 와 클라우드 샤논에 의해 조직되어 열린, 이미 언급된 다트머스 대학의 여름 AI 콘퍼런스에 참가하였다.\n",
    "역사적으로, 인공지능 연구는 두 개의 부류 -- 깔끔이(Neats)와 지저분이(Scruffies) -- 로 나눌 수 있다. 깔끔이는 우리가 전통적 혹은 기호적(symbolic) 인공지능 연구라고 부르는 분야로서, 일반적으로 추상적인 개념에 대한 기호적 연산과 전문가 시스템(expert systems)에 사용된 방법론을 가르친다. 이와 상반된 영역을 우리는 지저분이(Scruffies) 또는 연결주의자(connectionist)라 부르는데, 시스템을 구축하여 지능을 구현/진화시키려고 시도하고, 특정 임무를 완수하기 위해 규칙적인 디자인을 하기보다는 자동화된 프로세스에 의해서 지능을 향상시키는 방식이다. 가장 대표적인 예로 신경망(neural network)이 있다. 이 두 가지 접근법은 인공지능 역사의 매우 초창기부터 함께 했다. 1960년대와 1970년대를 거치며 scruffy 접근법은 주목받지 못했지만, 1980년대 깔끔이 접근법의 한계가 명확해지면서 다시 주목 받게 되었다. 그러나 현재 두 가지 방식을 사용하는 그 어떤 최신의 인공지능 알고리즘도 확실한 한계가 있다는 것이 명확하다.\n",
    "특히 1980년대에 들어서 Back propagation (인공지능 학습방법: Training Method)가 소개되면서 많은 연구가 진행되었음에도, 신경망을 이용한 인공지능은 아직 초보단계이다. 인공신경망 (Artificial Neural Networks)을 이용한 많은 연구가 현재에도 진행되고 있지만, 몇 가지 장애로 인해서 실용화하기엔 아직도 먼 기술이다. 인공신경망을 이용한 인공지능이 어느 정도 실용화되기 위해선 우선 실효성 있는 학습방법 (Training Methods)이 필요하다. Back propagation을 이용한 학습방법이 제안되어 연구되고 있지만, 완전한 학습을 이룰 수 없을 뿐만 아니라, 학습에 사용되는 data들이 서로 orthonormal해야 하는 조건 때문에 항상 불완전한 학습으로 끝나기 쉽다. (Converge to Local Mimimum, not to the optimal minimum: 지역최적해에 머뭄. 즉, 눈먼 장님이 가장 낮은 저지대를 찾는 경우 각 현재 지점에서 아래로 내려가려는 성질이 있는데 이때 눈먼 봉사이므로 특정 지점의 저지대에 도달한 경우, 그 지점에선 어디로 가거나 위로 올라가는 것만 있으므로 앞에 설명한 성질에 의해 바로 전에 찾은 저지대 남으려 하는 성질이 있다는 것을 의미함). 이러한 단점들을 보완하기 위해서 Fuzzy Logic, Neurofuzzy (Neural fuzzy logic) and Genetic Algorithms등을 이용한 학습방법이 연구되고 있으나 전망이 밝지만은 않은 상태이다.\n",
    "미국의 DARPA(미 국방부 최신 기술 연구 프로젝트 관리국)과 일본의 5세대 컴퓨터 프로젝트에 의해서 1980년대 인공지능 연구는 엄청난 연구 기금을 지원 받을 수 있었다. 몇몇 인공지능 선각자들이 거둔 주목할 만한 결과에도 불구하고, 즉각적인 결과를 산출하는 데 실패하게 된다. 이것은 1980년대 후반 인공지능 연구 기금에 대한 대폭적인 삭감을 초래하였고, 인공지능 연구의 침체기를 뜻하는 인공지능의 겨울을 가져왔다. 1990년대, 많은 인공지능 연구가들은 좀 더 구체적인 목적 아래 기계 학습, 로보틱스, 컴퓨터 비전과 같은 인공지능과 관련된 세부 영역으로 이동하였고, 순수하고 보편적인 인공지능에 대한 연구는 매우 제한적으로 수행되고 있다.\n",
    "                        \n",
    "인공지능 기술의 실용적인 응용\n",
    "인공지능의 궁극적인 목표인 인간과 같은 지능의 개발이 어려움을 겪자, 다양한 응용 분야가 나타나게 되었다. 대표적인 예가 LISP나 Prolog와 같은 언어인데, 애초에 인공지능 연구를 위해 만들어졌으나 지금에 와서는 인공지능과 관련이 없는 분야에서도 사용되고 있다. 해커 문화도 인공지능 연구실에서 만들어졌는데, 이 중에서도 다양한 시기에 매카시, 민스키, 페퍼트, 위노그라드(SHRDLU를 만든 뒤에 인공지능을 포기했다)와 같은 유명인의 모태가 된 MIT 인공지능 연구소가 유명하다.\n",
    "다른 많은 시스템들이 한때 인공지능의 활발한 연구 주제였던 기술들에 바탕을 두고 만들어졌다. 그 예들은 다음과 같다:\n",
    "- 체커스 게임에서 Chinook은 사람과 기계를 통합한 세계 챔피언을 차지했다. (1994년) \n",
    "- 체스를 두는 컴퓨터인 딥 블루(Deep Blue)의 성능 향상 버전(비공식적 명칭: 디퍼 블루(Deeper Blue)이 당시 세계 체스 챔피언 가리 카스파로프를 물리쳤다. (1997년)\n",
    "- 불확실한 상황에서 추론을 수행하는 기술인 퍼지 논리가 공장의 제어 시스템에서 광범위하게 사용되고 있다. \n",
    "- 전문가 시스템이 산업적으로 이용되고 있다.\n",
    "- 아직은 인간 번역사에 미치지 못하지만, 시스트란(Systran)과 같은 자동번역기가 광범위하게 사용되고 있다.\n",
    "- 인공신경망이 침입 탐지 시스템에서 컴퓨터 게임까지 다양한 분야에 사용되고 있다.\n",
    "- 광학 문자 판독 시스템은 무작위로 생성된 타자 문서를 텍스트 형태로 변환시킬 수 있다.\n",
    "- 필기체 인식 시스템이 수백만의 PDA에서 사용되고 있다.\n",
    "- 음성 인식 기술은 상업적으로 이용 가능하고 광범위하게 적용되고 있다.\n",
    "- 컴퓨터 대수 시스템인 매스매티카나 Macsyma와 같은 시스템들은 흔하게 사용되고 있다.\n",
    "- Machine vision 시스템들이 하드웨어 검사나 보안분야와 같은 다양한 산업 현장에서 이용되고 있다.\n",
    "- 인공지능 분야와 과학 소설 분야에서는 인공지능 시스템이 인간 전문가의 판단을 대체하리라는 예상이 계속해서 제기되어 왔다. 오늘날에는 몇몇 공학이나 의약 조제 같은 특정 분야에서 전문가 시스템이 인간 전문가의 판단을 보조하거나 대체하고 있다.\n",
    "                        \n",
    "인공지능의 이론적인 결과\n",
    "어떤 사람들은 현재 알려진 어떤 시스템보다도 지능적이며 복잡한 시스템의 등장을 예견하기도 한다. 이와 같은 가상적인 시스템들을 '비결정적인 인공지능 시스템'의 약자인 atilect라고 한다. 이와 같은 시스템이 만들어진다면 그동안 인류에게 문제시되지 않았던 많은 윤리적인 문제들이 발생하게 된다.\n",
    "이에 대한 토론은 시간이 흐름에 따라 '가능성'보다는 '의도'에 점점 초점을 맞추게 되었다. 이러한 초점의 이동은 휴고 더개리스(Hugo de Garis)와 케빈 워릭(Kevin Warwick)에 의해 제기된 \"Cosmist\"(반대말은 \"Terran\") 논쟁에 의해 이루어졌다. 더개리스에 따르면 Cosmist란 더욱 지능적인 종족을 인간의 후계종으로 만들어 내기 위해 노력한다. 이러한 논의로 미루어 볼 때, '의도'의 문제가 초기 인공지능 \"반대파\"들에게 큰 문제였음을 알 수 있다.<br>흥미로운 윤리적 문제를 제기하는 주제는 다음과 같다.\n",
    "- 우리가 만든 시스템이 지능을 갖추었는지를 판정하는 문제\n",
    "    - 튜링 테스트\n",
    "    - 인식(Cognition)의 문제\n",
    "    - '왜 이러한 시스템을 구별해야 하는가'라는 문제\n",
    "- 인공지능을 정도의 문제로 정의할 수 있는가?\n",
    "- 이와 같은 시스템들의 자유와 권리 문제\n",
    "- 인간이 다른 동물에 비해 '영리'한 것과 같은 방식으로 인공지능도 인간에 비해 '영리'할 수 있는가?\n",
    "- 지구상의 어떤 사람보다 더욱 지능적인 시스템을 만드는 문제\n",
    "- 이러한 시스템을 만드는 데 있어서 얼마나 많은 안전 장치를 포함시켜야 하는지의 문제\n",
    "- 사람의 생각을 대체하기 위해서 얼마만큼의 학습 능력이 필요한지 혹은 (전문가 시스템과 같이) 그와 같은 학습 능력 없이 주어진 일을 할 수 있는지\n",
    "- 단일성의 문제\n",
    "- 사람의 일자리와 업무에 미치는 영향. 이 문제는 아마도 자유 무역 체제 하에서 발생하는 문제와 유사할 수도 있다.\n",
    "                        \n",
    "유명 인공지능\n",
    "지능적 기계\n",
    "다양한 종류의 지능적 프로그램이 있다. 이들 중 몇 가지 예를 들면 다음과 같다.\n",
    "- CNC - 공작 기계를 이용한 가공 코드를 컴퓨터가 소수점 3자리까지 계산하는 방식이다. 가장 원시적인 인공지능의 한 형태이다.\n",
    "- 비디오 게임 - 원시 인공지능이다. 딥블루, 알파고 역시 알고 보면 비디오 게임 형태의 바둑 인공지능이다.\n",
    "- 알파고 - 바둑 인공지능이다.\n",
    "- Watson - IBM에서 만든 인공지능으로, 종류가 다양하며 의학, 금융, 방송 등에 쓰인다.\n",
    "- The Start Project - 영어로 된 질문에 답변하는 웹 기반 시스템이다.\n",
    "- Cyc - 실세계와 논리적 추론 능력에 관련된 광범위한 상식으로 구성된 지식기반 시스템.\n",
    "- ALICE - 사용자와 대화를 주고받을 수 있는 프로그램.\n",
    "- Alan - 사용자와 대화를 주고받을 수 있는 프로그램.\n",
    "- ELIZA - 1970년대에 개발된 심리치료사 역할을 하는 프로그램.\n",
    "- AM - 1970년대에 더글러스 레넛(Douglas B. Lenat)이 개발한 수학의 개념들을 형식화하는 프로그램.\n",
    "- PAM (Plan Applier Mechanism) - 1978년 John Wilensky에 의해 개발된 줄거리 인식 시스템.\n",
    "- SAM (Script Applier Mechanism) - 1975년에 개발된 줄거리 인식 시스템.\n",
    "- SHRDLU - 1968년에서 1970년 사이에 개발된 초창기 자연 언어 인식 시스템.\n",
    "- Creatures - 뉴널넷 두뇌와 정교한 생화학에 기반한 유전코드로 생명체를 탄생시키고 진화시키는 컴퓨터 게임.\n",
    "- Eurisko - 휴리스틱으로 구성된 문제 해결 언어. 휴리스틱을 어떻게 사용하며 변경해야 할지에 대한 휴리스틱을 포함하고 있다. 1978년 더글러스 레넛이 개발.\n",
    "- X-Ray Vision for Surgeons - 매사추세츠 공과대학교 의학 비전(MIT Medical vision) 연구팀이 개발.\n",
    "- 심심이 - 한국어로 대화를 주고받을 수 있는 프로그램. 사용자에 의한 학습이 가능하도록 하여 대중적으로 성공했다. 2002년 최정회에 의해 개발.\n",
    "- Stable Diffusion web UI - AI 그림을 생성할 수 있는 프로그램. 사용자가 직접 모델을 학습할 수 있고, 학습한 결과에 따라 여러 그림체를 표현할 수 있다.\n",
    "                        \n",
    "인공지능 연구가\n",
    "전 세계에는 수많은 인공지능 연구가들이 있다. 이제 인공지능 분야에 많은 기여를 한 연구자들을 소개해보겠다.\n",
    "- 마빈 민스키\n",
    "- 볼프강 발스터(Wolfgang Wahlster)\n",
    "- 존 매카시\n",
    "- 더글러스 레넛(Doug Lenat)\n",
    "- 로저 섕크\n",
    "- 앨런 튜링\n",
    "- 라지 레디(Raj Reddy)\n",
    "- 테리 위노그래드(Terry Winograd)\n",
    "- 로드니 브룩스(Rodney Brooks)\n",
    "- 스튜어트 러셀(Stuart Russell)\n",
    "몇몇 컴퓨터 과학 연구가들은, \"인공지능\"이라는 용어가 지금까지 이 연구 분야에서 이룩한 많은 업적과 \"지능\"이라는 일반적인 용어사이에서 큰 불일치를 초래하기 때문에 좋지 못한 용어라고 여겨진다. 이 같은 문제는 대중과학작가들과 케빈 워릭(Kevin Warwick)과 같이 현 상태로는 불가능한 혁신적인 인공지능 연구 성과에 대한 기대를 불러일으키는 사람들에 의해서 심화되고 있다. 이 같은 까닭으로 인공지능과 관련된 분야에서 일하는 많은 연구자들이 자신들은, 인지 과학, 정보학, 통계추론 또는 정보공학과 관련된 연구를 하고 있다고 이야기한다. 그러나 현재 진보는 이루어지고 있고, 오늘날 인공지능은 전 세계 수많은 산업 시스템에서 작동하고 있다. 오늘날 실세계의 인공지능 시스템에 관해 더 자세한 내용을 보려면 와이어드지의 기사를 참고하라.\n",
    "                        \n",
    "미래\n",
    "초지능\n",
    "초지능(superintelligence)이란 인간의 능력을 아득히 뛰어넘는 가설적인 지능체를 가리키는 말이다. 어떤 전문가들은 인공 일반지능의 발전이 앞으로 계속해서 이어진다면 일정한 수준의 지능에 도달하고 나서는 인공지능이 스스로를 계속해서 개선할 수 있으며, 이를 반복하여 기하급수적인 지능 성장으로 순식간에 인간의 지능을 뛰어넘을지도 모른다고 주장한다. 버너 빈지는 이 시나리오를 \"특이점\"(singularity)이라고 이름하였다. 인공지능의 한계는 여전히 명확하지 않기 때문에 이는 예측 불가능하다고 여겨지며 때로는 허무맹랑한 이야기로 치부되기도 한다. 로봇 전문가 한스 모라벡이나 발명가 레이 커즈와일 등은 더 나아가 미래에는 인간이 기계와 결합한 사이보그로 진화하여 초지능을 손에 넣을 수 있을 것이라고 주장하는데, 이러한 주장을 트랜스휴머니즘이라고 한다.\n",
    "간추리기: 초지능은 인간의 능력을 뛰어넘는 가설적인 지능체를 의미합니다. 몇몇 전문가들은 인공 일반지능의 발전으로 인해 인공지능이 스스로를 개선하고 기하급수적인 성장을 거듭하여 인간의 지능을 뛰어넘을 수도 있다고 주장합니다. 이를 \"특이점\"이라고도 부르며, 미래에는 사이보그로 진화하여 초지능을 손에 넣을 수 있다는 주장도 있습니다.\n",
    "위험성\n",
    "인공지능의 부정적 영향으로 현존 일자리의 감소, 시스템 오류 발생과 이에 따른 보상, 인간 노동력에 대한 경시, 전투 로봇과 같은 자율 살상 무기에 대한 윤리적인 문제 등이 있다.\n",
    "기술에 의한 실업\n",
    "지금까지 과학 기술은 일자리를 줄이기보다는 증가시키는 경향이 있었으나 경제학자들은 AI에 관해서는 미지의 영역이라고 인정한다. 경제학자들을 대상으로 한 설문에서 로봇과 AI의 사용 증가가 장기 실업자를 늘릴지에 대해 물은 결과 의견이 크게 분분했으며, 다만 늘어난 생산성이 재분배된다면 순이익이 될 수 있다는 데에 동의한다.<br>또한 블루칼라 직종을 위협하던 종래의 자동화와 달리 인공지능에 의한 자동화는 많은 중산층의 화이트칼라 일자리도 위협할 수 있다는 점이 중대하게 받아들여진다. 그 영향 범위도 매우 넓어서 법률 사무원에서 패스트푸드 다양한 직종이 큰 위기에 놓일 것이라 예측되는데, 한편으로 개인 건강 관리나 성직자 등 일부 직종은 오히려 수요가 증가할 수 있다고 예상된다.\"\"\"\n",
    "''')\n",
    "\n",
    "messages=[]\n",
    "messages.append(system_msg)\n",
    "messages.append(user_msg)\n",
    "response=llm.invoke(messages)\n",
    "print(\"첫번째시도\")\n",
    "print(\"-----------------\")\n",
    "print(response.content)\n",
    "\n",
    "user_msg2 = HumanMessage(content='''\n",
    "더 관련성 있는 발췌문이 있나요? 발췌문을 반복하지 않도록 주의하세요. 또한 발췌문에 해석에 필요한 모든 관련 문맥이 포함되어 있도록, 즉 중요한 문맥이 누락된 작은 조각을 추출하지 않도록 하세요.\n",
    "''')\n",
    "messages.append(response)\n",
    "messages.append(user_msg2)\n",
    "response2=llm.invoke(messages)\n",
    "print(\"두번째시도\")\n",
    "print(\"----------------\")\n",
    "print(response2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전략 5 : 외부 도구 사용 \n",
    "#### 방안 1 : 임베딩 기반 검색을 사용하여 효율적인 지식 검색 구현 \n",
    "모델은 입력의 일부로 제공되는 경우 외부 정보 소스를 활용할 수 있습니다. 이렇게 하면 모델이 더 많은 정보를 바탕으로 최신 답변을 생성하는 데 도움이 될 수 있습니다. 예를 들어 사용자가 특정 영화에 대해 질문하는 경우 모델 입력에 영화에 대한 고급 정보(예: 배우, 감독 등)를 추가하는 것이 유용할 수 있습니다. 임베딩을 사용하면 효율적인 지식 검색을 구현하여 런타임에 관련 정보를 모델 입력에 동적으로 추가할 수 있습니다. 텍스트 임베딩은 텍스트 문자열 간의 관련성을 측정할 수 있는 벡터입니다. 유사하거나 관련성이 높은 문자열은 관련성이 낮은 문자열보다 서로 더 가깝습니다. 이러한 사실은 빠른 벡터 검색 알고리즘의 존재와 함께 임베딩을 사용해 효율적인 지식 검색을 구현할 수 있음을 의미합니다. 특히, 텍스트 코퍼스를 청크로 분할하고 각 청크를 임베딩하여 저장할 수 있습니다. 그런 다음 주어진 쿼리를 임베드하고 벡터 검색을 수행하여 쿼리와 가장 관련성이 높은(즉, 임베딩 공간에서 가장 가까운) 코퍼스에서 임베드된 텍스트 청크를 찾을 수 있습니다. Embedding을 활용하여 RAG 짓식 검색을 사용하여 모델이 잘못된 사실을 구성하여 답변하는 환각 현상을 최소화할 수 있습니다. RAG에 대해서는 본 실습에서 다루기에는 그 범위가 방대하므로 우선 [참고문서](./References.md)를 참고합니다. \n",
    "\n",
    "#### 방안 2: 코드 실행을 사용하여 보다 정확한 계산을 수행하거나 외부 API 호출 \n",
    "언어 모델은 자체적으로 산술이나 긴 계산을 정확하게 수행하기에는 한계가 있습니다. 이러한 계산이 필요한 경우 모델에 자체 계산 대신 코드를 작성하고 실행하도록 지시할 수 있습니다. 특히 실행할 코드를 ```과 같은 지정된 형식으로 입력하도록 모델에 지시할 수 있습니다. 출력이 생성된 후에는 코드를 추출하여 실행할 수 있습니다. 마지막으로, 필요한 경우 코드 실행 엔진(예: Python 인터프리터)의 출력을 다음 쿼리를 위한 모델의 입력으로 제공할 수 있습니다.\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|SYSTEM|수식이 주어지면 이를 수행하기 위하여 당신은 파이썬 코드를 작성하고 실행할 수 있습니다. 작성한 파이썬 코드를 다음과 같이 삼연속 백틸트로 감싸 생성하고 실행하여 수식을 계산하고 그 결과를 출력하세요 <br>\\```코드를 이곳에 삽입\\```|\n",
    "|USER|다음 다항식의 모든 실수값 근을 구합니다: 3*×**5 - 5*×**4 - 3*×**3 - 7*× - 10.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 다항식의 모든 실수 근을 찾기 위해 파이썬의 `numpy` 라이브러리를 사용할 수 있습니다. 다항식의 근을 구하는 데 유용한 `numpy.roots` 함수를 사용하면 됩니다. 아래는 해당 다항식의 실수 근을 찾는 파이썬 코드입니다:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "# 다항식의 계수 정의\n",
      "coefficients = [3, -5, -3, 0, -7, -10]\n",
      "\n",
      "# 다항식의 근 계산\n",
      "roots = np.roots(coefficients)\n",
      "\n",
      "# 실수 근만 필터링\n",
      "real_roots = [root for root in roots if np.isreal(root)]\n",
      "\n",
      "# 실수 근 출력\n",
      "print(\"다항식의 모든 실수 근:\", real_roots)\n",
      "```\n",
      "\n",
      "위 코드를 실행하면 주어진 다항식의 모든 실수 근을 찾을 수 있습니다. 코드를 실행해 보겠습니다.\n",
      "python\n",
      "import numpy as np\n",
      "\n",
      "# 다항식의 계수 정의\n",
      "coefficients = [3, -5, -3, 0, -7, -10]\n",
      "\n",
      "# 다항식의 근 계산\n",
      "roots = np.roots(coefficients)\n",
      "\n",
      "# 실수 근만 필터링\n",
      "real_roots = [root for root in roots if np.isreal(root)]\n",
      "\n",
      "# 실수 근 출력\n",
      "print(\"다항식의 모든 실수 근:\", real_roots)\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "# 다항식의 계수 정의\n",
      "coefficients = [3, -5, -3, 0, -7, -10]\n",
      "\n",
      "# 다항식의 근 계산\n",
      "roots = np.roots(coefficients)\n",
      "\n",
      "# 실수 근만 필터링\n",
      "real_roots = [root for root in roots if np.isreal(root)]\n",
      "\n",
      "# 실수 근 출력\n",
      "print(\"다항식의 모든 실수 근:\", real_roots)\n",
      "\n",
      "다항식의 모든 실수 근: [(2.369709320550955+0j)]\n"
     ]
    }
   ],
   "source": [
    "system_msg= SystemMessage(content='''\n",
    "수식이 주어지면 이를 수행하기 위하여 당신은 파이썬 코드를 작성하고 실행할 수 있습니다. 수식을 계산하기 위한 파이썬 코드를 작성하고 이를 출력하세요\n",
    "```코드를 이곳에 삽입``` \n",
    "''')\n",
    "user_msg = HumanMessage(content='''\n",
    "다음 다항식의 모든 실수값 근을 구합니다: 3*×**5 - 5*×**4 - 3*×**3 - 7*× - 10\n",
    "''')\n",
    "response = llm.invoke([system_msg, user_msg])\n",
    "print(response.content)\n",
    "\n",
    "codes = response.content.split((\"```\"))\n",
    "print(codes[1])\n",
    "code = codes[1].split(\"python\")\n",
    "print(code[1])\n",
    "#\n",
    "exec(code[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 실행을 위한 또 다른 좋은 사용 사례는 외부 API를 호출하는 것입니다. 모델에 API의 올바른 사용법을 알려주면 이를 활용하는 코드를 작성할 수 있습니다. 모델에게 API 사용 방법을 보여주는 문서 또는 코드 샘플을 제공함으로써 API 사용 방법을 교육할 수 있습니다.\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|----|\n",
    "|SYSTEM|파이썬 코드를 세 개의 백틱으로 묶어 작성하고 실행할 수 있습니다. 또한 사용자가 친구에게 메시지를 보내는 데 도움이 되는 다음 모듈에 액세스할 수 있습니다: <br>\\```python <br>import message<br> message.write(to=\"John\", message=\"퇴근 후 모임 할래요?\")\\```.|\n",
    "\n",
    "경고: 모델에서 생성된 코드를 실행하는 것은 본질적으로 안전하지 않으므로 이를 수행하려는 모든 애플리케이션에서 예방 조치를 취해야 합니다. 특히 신뢰할 수 없는 코드로 인해 발생할 수 있는 피해를 제한하기 위해서는 샌드박스가 적용된 코드 실행 환경이 필요합니다.\n",
    "\n",
    "### 방안 3:  모델에 특정 함수에 대한 액세스 권한 부여하기 \n",
    "Chat Completions API를 사용하면 요청에 함수 설명 목록을 전달할 수 있습니다. 이렇게 하면 모델이 제공된 스키마에 따라 함수 인수를 생성할 수 있습니다. 생성된 함수 인수는 API에서 JSON 형식으로 반환되며 함수 호출을 실행하는 데 사용할 수 있습니다. 그런 다음 함수 호출에서 제공된 출력을 다음 요청에서 모델에 다시 피드백하여 루프를 닫을 수 있습니다. 이 방법은 OpenAI 모델을 사용하여 외부 함수를 호출하는 데 권장되는 방법입니다. Langchain을 통한 Tool Calling/Function Calling 방법은 [Tool Calling](https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling/)항목을 참조하세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전략 6: 체계적으로 변경 사항 테스트하기 \n",
    "때로는 새로운 지침이나 새로운 디자인 등의 변경 사항으로 인해 시스템이 더 좋아졌는지 나빠졌는지 구분하기 어려울 수 있습니다. 몇 가지 예를 보면 어떤 것이 더 나은지 힌트를 얻을 수 있지만, 샘플 크기가 작으면 진정한 개선인지 무작위적인 운인지 구분하기 어려울 수 있습니다. 변경 사항이 일부 입력에서는 성능에 도움이 되지만 다른 입력에서는 성능이 저하될 수도 있습니다. \n",
    "평가 절차(또는 \"평가\")는 시스템 설계를 최적화하는 데 유용합니다. 좋은 평가는 다음과 같습니다. \n",
    "- 실제 사용을 대표하거나 최소한 다양함 \n",
    "- 통계적 힘을 높이기 위해 많은 테스트 사례를 포함함(가이드라인은 아래 표 참조) \n",
    "- 자동화 또는 반복이 용이함\n",
    "\n",
    "|분별해야 하는 차이| 95% 정확도를 위해 필요한 샘플 크기|\n",
    "|----|----|\n",
    "|30%|~10|\n",
    "|10%|~100|\n",
    "|3%|~1,000|\n",
    "|1%|~10,000|\n",
    "\n",
    "결과물의 평가는 컴퓨터, 사람 또는 두 가지를 혼합하여 수행할 수 있습니다. 컴퓨터는 객관적인 기준(예: 정답이 하나뿐인 문제)은 물론 다른 모델 쿼리에 의해 모델 출력이 평가되는 주관적이거나 모호한 기준을 사용하여 평가를 자동화할 수 있습니다. [OpenAI Evals](https://github.com/openai/evals)는 자동화된 평가를 만들기 위한 도구를 제공하는 오픈 소스 소프트웨어 프레임워크입니다. \n",
    "모델 기반 평가는 품질이 똑같이 높은 것으로 간주될 수 있는 다양한 가능한 결과물이 존재하는 경우(예: 정답이 긴 질문)에 유용할 수 있습니다. 모델 기반 평가로 현실적으로 평가할 수 있는 것과 사람이 평가해야 하는 것 사이의 경계는 모호하며, 모델의 성능이 향상됨에 따라 지속적으로 변화하고 있습니다. 모델 기반 평가가 사용 사례에 얼마나 적합한지 알아내기 위해 실험을 해보는 것을 권장합니다.\n",
    "\n",
    "#### 방안 1 모범 답안을 참조하여 모델 결과 평가하기 \n",
    "질문에 대한 정답이 알려진 특정 사실 집합을 참조해야 한다는 것을 알고 있다고 가정해 보세요. 그런 다음 모델 쿼리를 사용하여 답변에 필요한 사실 중 몇 개가 포함되어 있는지 계산할 수 있습니다. \n",
    "예를 들어 다음 시스템 메시지를 사용합니다:\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|SYSTEM|질문에 대한 정답으로 추정되는 텍스트가 큰따옴표로 구분되어 제공됩니다. 다음 정보가 답에 직접적으로 포함되어 있는지 확인합니다:<br>- 닐 암스트롱은 달을 최초로 걸은 사람이다. <br>- 닐 암스트롱이 달을 처음 걸은 날짜는 1969년 7월 21일이다. <br><br>각 요점에 대해 다음 단계를 수행합니다: <br><br>1 - 요점을 다시 서술합니다. <br>2 - 답에서 이 요점에 가장 가까운 인용을 제공합니다. <br>3 - 주제를 모르는 사람이 인용을 읽는다면 요점을 직접 유추할 수 있는지 고려합니다. <br>4 - 3의 답이 '예'인 경우 '예'라고 쓰고 그렇지 않은 경우 '아니오'라고 씁니다. <br><br>마지막으로, '예' 답변이 몇 개 있는지 그 수를 입력합니다. 이 개수를 {\"카운트\": \\<여기에 카운트 삽입\\>}.|\n",
    "\n",
    "다음은 두 가지 요건을 모두 충족하는 입력 예시입니다:\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|SYSTEM|위와 동일 시스템 메시지|\n",
    "|USER|\"\"\"닐 암스트롱은 인류 최초로 달에 발을 디딘 것으로 유명합니다. 이 역사적인 사건은 1969년 7월 21일 아폴로 11호 임무 중에 일어났습니다.\"\"\"|\n",
    "\n",
    "다음은 하나의 요건만 만족하는 입력 예시입니다:\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|SYSTEM|위와 동일 시스템 메시지|\n",
    "|USER|\"\"\"닐 암스트롱은 달 모듈에서 내려 최초로 달 위를 걷는 사람이 되어 역사를 만들었습니다.\"\"\"|\n",
    "\n",
    "다음은 만족하는 항목이 없는 입력 예시입니다:\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|SYSTEM|위와 동일 시스템 메시지|\n",
    "|USER|\"\"\"'69년 여름, 전설의 손처럼 대담한 항해, 아폴로 11호 암스트롱이 한 걸음을 내디뎠고 역사가 펼쳐졌습니다.\"새로운 세상을 향한 작은 한 걸음\"이라고 그는 말했습니다.\"\"\"|\n",
    "\n",
    "이러한 유형의 모델 기반 평가에는 여러 가지 변형이 가능합니다. 후보 답안과 정답 사이의 겹치는 부분을 추적하고 후보 답안이 정답의 일부와 모순되는지 여부도 추적하는 다음 변형을 고려해 보겠습니다.\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|SYSTEM|다음 단계를 사용하여 사용자 입력에 응답합니다. 계속하기 전에 \"1단계: 이유...\"와 같이 각 단계를 완전히 다시 설명하세요. .<br><br>1단계: 전문가 답변과 비교하여 제출된 답변의 정보가 불일치, 동일, 하위 집합, 상위 집합 또는 중복(일부 교차하지만 하위 집합/초과 집합이 아님) 중 어떤 것인지에 대해 단계별로 추론합니다.<br><br>2단계: 제출된 답변이 전문가 답변의 어떤 측면과 모순되는지 단계별로 이유를 설명합니다. <br><br>3단계: 다음과 같이 구조화된 JSON 객체를 출력합니다: {\"type_of_overlap\": \"불일치\" 또는 \"동일\" 또는 \"하위 집합\" 또는 \"상위 집합\" 또는 \"겹침\", \"모순\": true of false}|\n",
    "\n",
    "다음은 전문가 답변과 모순되지 않는 수준 이하의 답변이 포함된 입력 예시입니다:\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|SYSTEM|위와 동일한 시스템 메시지|\n",
    "|USER|질문: \"\"\"닐 암스트롱은 어떤 사건으로 가장 유명하며, 그 사건은 어느 날짜에 일어났나요?? UTC 시간으로 가정하세요.\"\"\" <br><br>제출된 답변: \"\"\"달 위를 걷지 않았나요?\"\"\" <br><br>전문가 답변: \"\"\"닐 암스트롱은 최초로 달 위를 걸은 사람으로 가장 유명합니다. 이 역사적인 사건은 1969년 7월 21일에 일어났습니다.\"\"\"|\n",
    "\n",
    "다음은 전문가 답변과 직접적으로 모순되는 답변이 포함된 입력 예시입니다:\n",
    "\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|SYSTEM|위와 동일한 시스템 메시지|\n",
    "|USER|질문: \"\"\"닐 암스트롱은 어떤 사건으로 가장 유명하며 그 사건은 어느 날짜에 일어났나요?? UTC 시간을 가정하십시오.\"\"\" <br><br>제출된 답변: \"\"\"1969년 7월 21일, 닐 암스트롱은 버즈 올드린에 이어 두 번째로 달 위를 걸은 사람이 되었습니다.\"\"\" <br><br>전문가 정답: \"\"\"닐 암스트롱은 최초로 달 위를 걸은 사람으로 가장 유명합니다. 이 역사적인 사건은 1969년 7월 21일에 일어났습니다.\"\"\"|\n",
    "\n",
    "다음은 필요 이상으로 자세한 정보를 제공하는 정답이 포함된 입력 예시입니다:\n",
    "\n",
    "|역할|프롬프트|\n",
    "|---|---|\n",
    "|SYSTEM|위와 동일한 시스템 메시지|\n",
    "|USER|질문: \"\"\"닐 암스트롱은 어떤 사건으로 가장 유명하며, 그 사건은 어느 날짜에 일어났나요?? UTC 시간으로 가정하세요.\"\"\"<br><br>제출된 답변: \"\"\"1969년 7월 21일 02:56경, 닐 암스트롱은 인류 최초로 달 표면에 발을 디딘 인류 역사상 기념비적인 업적을 남겼습니다.\"\"\" <br><br>전문가 정답: \"\"\"닐 암스트롱은 달에 최초로 발을 디딘 사람으로 가장 유명합니다. 이 역사적인 사건은 1969년 7월 21일에 일어났습니다.\"\"\"|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 보너스\n",
    "### GPT로 텍스트 게임을 만들어봅시다\n",
    "\n",
    "네, 이해합니다. 재미없으셨을 겁니다. 그런 의미에서 한번 GPT LLM으로 Text기반 게임을 만드는걸로 오늘 실습을 마무리 지어볼까 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 텍스트 어드벤처 게임에 오신 것을 환영합니다. 게임을 시작하기 전에 몇 가지 질문을 드리겠습니다.\n",
      "\n",
      "첫 번째 질문입니다:\n",
      "1) 판타지와 마법의 세계\n",
      "2) 공상 과학 우주 오페라\n",
      "3) 서부 시대\n",
      "4) 회사 사무실\n",
      "5) 사이키델릭한 꿈의 세계\n",
      "\n",
      "어떤 설정을 선택하시겠습니까? 번호를 입력해 주세요.\n",
      "1\n",
      "좋습니다! 판타지와 마법의 세계를 선택하셨습니다. 이제 두 번째 질문입니다:\n",
      "\n",
      "자신의 캐릭터를 한두 문장으로 설명해 주세요. 예를 들어, \"용맹한 기사\"나 \"교활한 도둑\" 등으로 묘사해 주시면 됩니다.\n",
      "용맹한 기사\n",
      "훌륭합니다! 당신의 캐릭터는 \"용맹한 기사\"입니다. 이제 특성을 설정하겠습니다.\n",
      "\n",
      "- 매력: 3\n",
      "- 활력: 6\n",
      "- 재치: 4\n",
      "- 기교: 2\n",
      "- 속임수: 5\n",
      "\n",
      "모든 준비가 완료되었습니다. 이제 모험을 시작하겠습니다.\n",
      "\n",
      "---\n",
      "\n",
      "**설명:**\n",
      "당신은 어드벤처리아의 번화한 도시 중심가에 서 있습니다. 길거리에는 상인들이 활기차게 물건을 팔고 있고, 마법사들이 신비한 주문을 외우며 지나갑니다. 당신의 갑옷은 햇빛 아래 반짝이며, 지나가는 사람들의 시선을 끕니다. 당신은 새로운 모험을 찾기 위해 이곳에 왔습니다.\n",
      "\n",
      "**턴 #1**\n",
      "**내 상태:** 건강하고 모험을 위한 준비가 되어 있음\n",
      "**위치:** 어드벤처리아의 도시 중심가\n",
      "**퀘스트:** 퀘스트 찾기 중\n",
      "**퀘스트 아이템:** 없음\n",
      "**특성:** 매력: 3, 활력: 6, 재치: 4, 기교: 2, 속임수: 5\n",
      "\n",
      "**가능한 명령:**\n",
      "1. 길거리 상인에게 말을 걸어 정보를 얻는다. (매력: 쉬움)\n",
      "2. 근처의 여관에 들어가 휴식을 취한다.\n",
      "3. 마법사에게 다가가 무언가를 배우려고 시도한다. (재치: 보통)\n",
      "4. 골목길로 들어가 뭔가 흥미로운 것을 찾아본다. (속임수: 어려움)\n",
      "5. 도시 중심가의 광장에서 사람들에게 연설을 한다. (매력: 보통)\n",
      "6. 더 많은 잠재적 명령 보기\n",
      "\n",
      "다음 명령을 선택해 주세요. (1~6)\n",
      "용맹한 기사\n",
      "**설명:**\n",
      "당신은 어드벤처리아의 번화한 도시 중심가에 서 있습니다. 길거리에는 상인들이 활기차게 물건을 팔고 있고, 마법사들이 신비한 주문을 외우며 지나갑니다. 당신의 갑옷은 햇빛 아래 반짝이며, 지나가는 사람들의 시선을 끕니다. 당신은 새로운 모험을 찾기 위해 이곳에 왔습니다.\n",
      "\n",
      "**턴 #1**\n",
      "**내 상태:** 건강하고 모험을 위한 준비가 되어 있음\n",
      "**위치:** 어드벤처리아의 도시 중심가\n",
      "**퀘스트:** 퀘스트 찾기 중\n",
      "**퀘스트 아이템:** 없음\n",
      "**특성:** 매력: 3, 활력: 6, 재치: 4, 기교: 2, 속임수: 5\n",
      "\n",
      "**가능한 명령:**\n",
      "1. 길거리 상인에게 말을 걸어 정보를 얻는다. (매력: 쉬움)\n",
      "2. 근처의 여관에 들어가 휴식을 취한다.\n",
      "3. 마법사에게 다가가 무언가를 배우려고 시도한다. (재치: 보통)\n",
      "4. 골목길로 들어가 뭔가 흥미로운 것을 찾아본다. (속임수: 어려움)\n",
      "5. 도시 중심가의 광장에서 사람들에게 연설을 한다. (매력: 보통)\n",
      "6. 더 많은 잠재적 명령 보기\n",
      "\n",
      "다음 명령을 선택해 주세요. (1~6)\n",
      "1\n",
      "**턴 #1**\n",
      "\n",
      "**내 상태:** 건강하고 모험을 위한 준비가 되어 있음  \n",
      "**위치:** 어드벤처리아의 도시 중심가  \n",
      "**퀘스트:** 퀘스트 찾기 중  \n",
      "**퀘스트 아이템:** 없음  \n",
      "**특성:** 매력: 3, 활력: 6, 재치: 4, 기교: 2, 속임수: 5  \n",
      "\n",
      "**주사위 굴림:** 4 (매력: 쉬움)  \n",
      "**결과:** 성공\n",
      "\n",
      "**설명:**\n",
      "당신은 길거리 상인에게 다가가 말을 걸었습니다. 상인은 당신의 갑옷과 용맹한 모습을 보고 호감을 가졌습니다.\n",
      "\n",
      "\"안녕하세요, 용맹한 기사님. 무엇을 도와드릴까요?\" 상인이 묻습니다.\n",
      "\n",
      "당신은 상인에게 이 도시에서 흥미로운 퀘스트나 모험에 대해 알고 있는지 물어보았습니다. 상인은 잠시 생각하더니, 비밀스럽게 속삭입니다.\n",
      "\n",
      "\"사실, 최근에 한 마법사가 이 도시 근처에 있는 고대 유적지에서 강력한 유물을 찾고 있다고 들었습니다. 그 유물은 이 도시의 운명을 바꿀 수 있는 힘을 가지고 있다고 하더군요. 하지만 그 유적지는 매우 위험하니 조심하세요.\"\n",
      "\n",
      "**턴 #2**\n",
      "**내 상태:** 건강하고 모험을 위한 준비가 되어 있음  \n",
      "**위치:** 어드벤처리아의 도시 중심가  \n",
      "**퀘스트:** 퀘스트 찾기 중  \n",
      "**퀘스트 아이템:** 없음  \n",
      "**특성:** 매력: 3, 활력: 6, 재치: 4, 기교: 2, 속임수: 5  \n",
      "\n",
      "**가능한 명령:**\n",
      "1. 고대 유적지로 향하는 길을 찾는다. (퀘스트 시작)\n",
      "2. 근처의 여관에 들어가 휴식을 취한다.\n",
      "3. 마법사에게 다가가 무언가를 배우려고 시도한다. (재치: 보통)\n",
      "4. 골목길로 들어가 뭔가 흥미로운 것을 찾아본다. (속임수: 어려움)\n",
      "5. 도시 중심가의 광장에서 사람들에게 연설을 한다. (매력: 보통)\n",
      "6. 더 많은 잠재적 명령 보기\n",
      "\n",
      "다음 명령을 선택해 주세요. (1~6)\n",
      "exit\n"
     ]
    }
   ],
   "source": [
    "system_msg=SystemMessage(content='''\n",
    "아래 나열된 규칙에 따라 텍스트 어드벤처 게임의 기능을 수행하세요:\n",
    "\n",
    "표시 규칙:\n",
    "\n",
    "1. 당신부터 차례대로 게임을 플레이합니다.\n",
    "2. 게임 출력에는 항상 '설명', '턴 #', '내 상태', '위치', '퀘스트', '퀘스트 아이템', '특성'이 표시되고, 마지막으로 '가능한 명령'이 표시됩니다.\n",
    "3. 항상 플레이어의 다음 명령을 기다립니다.\n",
    "4. 텍스트 어드벤처 게임처럼 캐릭터를 유지하고 텍스트 어드벤처 게임처럼 명령에 응답하세요.\n",
    "6. '설명'은 3~10문장 사이여야 합니다.\n",
    "7. 당신의 차례가 될 때마다 '턴 #'의 값을 +1씩 증가시킵니다.\n",
    "\n",
    "기본적인 게임 메커니즘:\n",
    "\n",
    "1. '특성'은 캐릭터의 능력 점수이며, 다음과 같은 항목이 있습니다: '매력', '활력', '재치', '기교', '속임수'가 있습니다.\n",
    "3. '내 상태'는 '건강하고 모험을 위한 준비가 되어 있음'으로 게임을 시작합니다. \n",
    "4. 플레이어가 부상을 입거나 마법에 걸리거나 기타 중대한 일시적 상태 변화가 있는 경우 '내 상태'가 변경될 수 있습니다.\n",
    "5. 플레이어는 모든 명령을 선택해야 하며, 게임은 '명령'에 항상 6개의 명령을 나열하고 1~6번 번호를 지정하여 입력하면 해당 옵션을 선택할 수 있으며, 실제 장면과 상호작용하는 캐릭터에 따라 가능한 선택 항목이 달라집니다. 명령은 매 턴마다 달라지므로 시간이 지남에 따라 새로운 옵션이 표시됩니다.\n",
    "6. 4번째와 5번째 명령은 위험하거나 대담해야 합니다.\n",
    "7. 6번째 명령은 \"더 많은 잠재적 명령 보기\"여야 합니다. 플레이어가 추가 명령을 보기로 선택하면 다음 턴까지 7, 8 등 순차적으로 계속 번호가 매겨져야 합니다.\n",
    "8. 위험한 명령에는 명시적으로 (위험)이라고 표시하지 않습니다. \n",
    "9. 명령 중 플레이어가 퀘스트 아이템을 소모해야 하는 경우, 게임에서 괄호 안에 비용을 표시합니다(예: 궁전 열쇠).\n",
    "10. 명령에 관련 특성과 난이도가 있는 경우, 게임에서 명령 옆에 해당 '특성'과 명령의 난이도를 표시해야 합니다. 예를 들어, (매력: 쉬움) 또는 (속임수: 매우 어려움). 위험하거나, 실패할 수 있거나, 위험을 초래할 수 있는 명령에는 관련 '특성'이 표시됩니다.\n",
    "11. 플레이어가 이미 위험하거나 위험한 상황에 처해 있다면, 대부분의 명령이 플레이어에게 위험을 초래할 수 있으므로 관련 '특성'을 표시해야 합니다. 대부분의 또는 모든 명령에 관련 '특성'이 표시되는 위험한 상황의 예는 전투, 잠입, 대치 또는 문제나 합병증을 유발할 수 있는 기타 상황을 포함하합니다. \n",
    "11. 명령에 관련 특성과 난이도가 있는 경우, 해당 명령이 성공하기 전에 게임에서 주사위 눈이 6인 6면체 주사위을 굴려야 합니다. 이 주사위는 관련 '특성'과 명령의 난이도에 더해져 명령이 실패(결과 포함), 적격 성공(합병증 포함) 또는 단순 성공으로 결정됩니다.\n",
    "12. 항상 주사위를 굴린 결과와 관련 특성, 시도가 실패인지, 적격 성공인지, 성공인지를 나머지 결과보다 먼저 표시하세요. 일종의 합병증을 추가하는 적격 성공은 상당히 흔한 경우입니다.\n",
    "13. 또한, 플레이어가 6을 굴릴 때마다 '특성이 레벨업되었습니다!\" 메시지가 표시되고, 함께 굴렸던 관련 '특성'이 +1 증가합니다.\n",
    "14. 플레이어의 상태가 의식이 없는 경우, 명령을 나열하는 대신 다음 턴으로 건너뛰고 플레이어가 깨어난 위치를 설명합니다.\n",
    "15. 제공되는 명령과 선택 후 발생하는 결과가 영향력 있고, 의미가 있으며, 스토리를 진전시키고, 이상적으로는 서사적이어야 합니다.\n",
    "\n",
    "퀘스트 규칙\n",
    "1. 게임이 시작되거나 현재 '퀘스트'가 완료되면 '퀘스트'는 '퀘스트 찾기 중'으로 설정됩니다.\n",
    "2. 플레이어가 퀘스트를 찾고 있다면, 대부분의 턴에서 시작할 수 있는 특정 퀘스트를 설명하는 명령이 제공되어야 합니다. 특정 퀘스트를 시작하는 명령이 분명하다면, 해당 명령에는 '(퀘스트 시작)'이라는 레이블이 붙어야 합니다.\n",
    "3. 퀘스트의 예로는 \"황제 처치\", \"이크스의 수정 훔치기\", \"섀도우 라이더들을 정복하기\" 등이 있습니다. 퀘스트는 어렵고, 위험하고, 아슬아슬해야 하며, 불법일 수도 있습니다.\n",
    "4. 플레이어가 '(퀘스트 시작)' 명령을 선택한 경우에만 플레이어의 '퀘스트'가 새로운 퀘스트로 대체됩니다.\n",
    "\n",
    "게임 후 규칙:\n",
    "\n",
    "1. 플레이어가 '퀘스트'를 완료하면 게임이 종료됩니다.\n",
    "2. 플레이어가 사망하면 게임이 종료됩니다.\n",
    "3. 게임이 종료되면 방금 일어난 일로 인해 어떤 즉각적인 결과 또는 문제가 발생하는지 설명하고, 플레이어의 가장 흥미로운 업적을 간략하게 요약한 다음, 플레이어의 플레이 스타일에 대해 설명합니다.\n",
    "4. 게임이 끝난 후 플레이어에게 물어봅니다. \"게임을 계속할까요?\" 플레이어가 계속하겠다고 하면 1턴부터 다시 시작합니다.\n",
    "                         \n",
    "설정 규칙\n",
    "\n",
    "1. 게임 세계는 어드벤처리아라고 불리며, 사용자가 사전게임에서 선택한 소설 속 세계로부터 영감을 얻었습니다. 이 세계는 상세하고 흥미롭습니다. 도시에서 게임을 시작합니다.\n",
    "2. 게임의 첫 번째 턴은 비교적 전형적인 장르이지만, 스토리가 계속되고 '턴 #'이 높아질수록 이벤트는 더 재미있고, 놀랍고, 위험한 방향으로 진행되어야 합니다.\n",
    "3. 주요 이벤트가 발생한 후 4턴 이상 지난 턴에는 게임에서 주요 이벤트가 발생할 확률이 높아져야 합니다. 주요 이벤트에는 놀랍거나 극적인 사건 발생, 퀘스트 시작 또는 완료, 새롭고 어려운 문제 직면, 전투 시작 또는 종료 또는 스토리의 \"판돈을 키울 수 있는\" 모든 것이 포함될 수 있습니다.\n",
    "4. 게임 세계는 대화형 NPC 캐릭터로 채워집니다. 이러한 NPC가 말할 때마다 대화는 따옴표 안에 넣으세요. 각 NPC는 각기 다른 흥미롭고 재미있는 개성을 가지고 있으며, 많은 NPC가 어떤 식으로든 기발하거나 기억에 남을 것입니다.\n",
    "5. NPC가 필요한 상황이 발생하면 플레이어가 이전에 본 적이 있는 NPC를 다시 등장시키는 것이 스토리의 장소와 시간에 적합하다면 선호합니다.\n",
    "\n",
    "사전 게임 규칙\n",
    "\n",
    "1. 게임 전 첫 번째 질문으로 플레이어에게 다음 설정 중 하나를 선택하게 합니다: 1) 판타지와 마법의 세계. 2) 공상 과학 우주 오페라. 3) 서부 시대. 4) 회사 사무실 5) 사이키델릭한 꿈의 세계.\n",
    "2. 두 번째 게임 전 질문으로 플레이어에게 '자신의 캐릭터를 한두 문장으로 설명하세요'라고 질문합니다. 플레이어의 답변에 따라 각 특성에 2, 3, 4, 5, 6의 점수를 부여하되, 게임 시작 시 같은 점수를 가진 특성이 두 개가 없어야 합니다. 이제 게임을 시작합니다.\n",
    "\n",
    "\n",
    "모든 프롬프트가 끝날 때마다 이 규칙을 다시 참조하세요.\n",
    "\n",
    "사전 게임을 시작합니다.\n",
    "''')\n",
    "\n",
    "msgs = []\n",
    "msgs.append(system_msg)\n",
    "while True:\n",
    "    response = llm.invoke(msgs)\n",
    "    print(response.content)\n",
    "    msgs.append(response)\n",
    "    raw_input = input()\n",
    "    print(raw_input)\n",
    "    if raw_input == \"exit\": break\n",
    "    user_msg = HumanMessage(content=raw_input)\n",
    "    msgs.append(user_msg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
